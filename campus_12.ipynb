{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1c4102d5-9122-4c6c-8899-cf867dfeee61",
   "metadata": {},
   "source": [
    "# Morning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6accc3e9-f772-44ca-bbcb-2c95a91e75e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 320x640 11 persons, 2 cars, 1 motorcycle, 2 buss, 324.8ms\n",
      "Speed: 8.8ms preprocess, 324.8ms inference, 3.4ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 6 persons, 1 car, 1 motorcycle, 2 buss, 274.7ms\n",
      "Speed: 5.7ms preprocess, 274.7ms inference, 3.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 6 persons, 1 car, 2 motorcycles, 1 bus, 256.8ms\n",
      "Speed: 5.1ms preprocess, 256.8ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 5 persons, 1 car, 2 motorcycles, 1 bus, 247.9ms\n",
      "Speed: 4.8ms preprocess, 247.9ms inference, 2.4ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 6 persons, 1 car, 2 motorcycles, 1 bus, 231.3ms\n",
      "Speed: 4.9ms preprocess, 231.3ms inference, 2.3ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 7 persons, 1 car, 1 motorcycle, 1 bus, 227.2ms\n",
      "Speed: 3.8ms preprocess, 227.2ms inference, 2.4ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 7 persons, 2 cars, 1 motorcycle, 1 bus, 346.1ms\n",
      "Speed: 4.8ms preprocess, 346.1ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 7 persons, 3 cars, 1 motorcycle, 1 bus, 1 handbag, 222.1ms\n",
      "Speed: 2.7ms preprocess, 222.1ms inference, 1.6ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 7 persons, 2 cars, 1 motorcycle, 1 bus, 236.7ms\n",
      "Speed: 3.1ms preprocess, 236.7ms inference, 2.4ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 7 persons, 1 car, 1 motorcycle, 2 buss, 226.3ms\n",
      "Speed: 3.4ms preprocess, 226.3ms inference, 1.2ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 7 persons, 2 cars, 1 motorcycle, 2 buss, 1 umbrella, 256.2ms\n",
      "Speed: 4.3ms preprocess, 256.2ms inference, 2.9ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 9 persons, 1 car, 1 motorcycle, 2 buss, 1 traffic light, 1 umbrella, 224.9ms\n",
      "Speed: 3.8ms preprocess, 224.9ms inference, 2.4ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 8 persons, 2 cars, 1 motorcycle, 1 bus, 224.5ms\n",
      "Speed: 4.3ms preprocess, 224.5ms inference, 1.9ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 11 persons, 1 car, 1 motorcycle, 1 bus, 1 umbrella, 1 handbag, 214.7ms\n",
      "Speed: 4.7ms preprocess, 214.7ms inference, 2.4ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 8 persons, 1 car, 2 motorcycles, 1 bus, 233.1ms\n",
      "Speed: 4.8ms preprocess, 233.1ms inference, 2.4ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 7 persons, 1 car, 2 motorcycles, 2 buss, 233.2ms\n",
      "Speed: 3.0ms preprocess, 233.2ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 7 persons, 2 cars, 2 motorcycles, 2 buss, 1 umbrella, 241.3ms\n",
      "Speed: 3.1ms preprocess, 241.3ms inference, 2.4ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 7 persons, 1 car, 3 motorcycles, 2 buss, 1 umbrella, 229.5ms\n",
      "Speed: 3.1ms preprocess, 229.5ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 5 persons, 1 car, 2 motorcycles, 1 bus, 1 umbrella, 219.1ms\n",
      "Speed: 2.7ms preprocess, 219.1ms inference, 2.3ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 7 persons, 2 cars, 4 motorcycles, 1 bus, 1 umbrella, 161.6ms\n",
      "Speed: 3.5ms preprocess, 161.6ms inference, 1.2ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 8 persons, 2 cars, 4 motorcycles, 3 buss, 162.4ms\n",
      "Speed: 2.8ms preprocess, 162.4ms inference, 1.5ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 6 persons, 1 car, 4 motorcycles, 2 buss, 156.5ms\n",
      "Speed: 2.6ms preprocess, 156.5ms inference, 1.3ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 7 persons, 1 car, 3 motorcycles, 2 buss, 159.7ms\n",
      "Speed: 3.5ms preprocess, 159.7ms inference, 1.3ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 8 persons, 1 car, 4 motorcycles, 1 bus, 154.7ms\n",
      "Speed: 2.6ms preprocess, 154.7ms inference, 1.2ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 8 persons, 1 car, 3 motorcycles, 1 truck, 1 umbrella, 1 potted plant, 157.9ms\n",
      "Speed: 2.8ms preprocess, 157.9ms inference, 1.2ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 9 persons, 1 car, 3 motorcycles, 1 truck, 1 umbrella, 157.9ms\n",
      "Speed: 3.9ms preprocess, 157.9ms inference, 1.2ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 6 persons, 3 cars, 3 motorcycles, 1 truck, 1 umbrella, 164.9ms\n",
      "Speed: 5.5ms preprocess, 164.9ms inference, 1.2ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 6 persons, 3 cars, 3 motorcycles, 1 truck, 157.5ms\n",
      "Speed: 3.7ms preprocess, 157.5ms inference, 1.3ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 6 persons, 2 cars, 4 motorcycles, 1 truck, 1 umbrella, 159.7ms\n",
      "Speed: 2.6ms preprocess, 159.7ms inference, 1.2ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 5 persons, 1 car, 3 motorcycles, 1 truck, 1 umbrella, 153.4ms\n",
      "Speed: 2.7ms preprocess, 153.4ms inference, 1.2ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 5 persons, 2 cars, 3 motorcycles, 1 truck, 1 umbrella, 148.7ms\n",
      "Speed: 2.8ms preprocess, 148.7ms inference, 1.4ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 6 persons, 2 cars, 2 motorcycles, 1 truck, 1 umbrella, 159.7ms\n",
      "Speed: 3.2ms preprocess, 159.7ms inference, 1.1ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 7 persons, 1 car, 2 motorcycles, 1 truck, 1 umbrella, 155.1ms\n",
      "Speed: 2.6ms preprocess, 155.1ms inference, 1.4ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 5 persons, 2 cars, 2 motorcycles, 1 truck, 1 umbrella, 139.9ms\n",
      "Speed: 2.8ms preprocess, 139.9ms inference, 1.3ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 4 persons, 1 car, 2 motorcycles, 1 truck, 149.7ms\n",
      "Speed: 6.8ms preprocess, 149.7ms inference, 1.1ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 7 persons, 1 car, 3 motorcycles, 1 truck, 144.6ms\n",
      "Speed: 2.8ms preprocess, 144.6ms inference, 1.3ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 8 persons, 1 car, 2 motorcycles, 1 truck, 154.1ms\n",
      "Speed: 2.5ms preprocess, 154.1ms inference, 1.2ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 6 persons, 1 car, 1 motorcycle, 1 truck, 1 umbrella, 144.6ms\n",
      "Speed: 4.3ms preprocess, 144.6ms inference, 1.3ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 6 persons, 1 car, 1 motorcycle, 1 truck, 1 umbrella, 161.9ms\n",
      "Speed: 3.2ms preprocess, 161.9ms inference, 1.4ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 5 persons, 1 car, 2 motorcycles, 1 truck, 1 umbrella, 161.9ms\n",
      "Speed: 5.0ms preprocess, 161.9ms inference, 1.3ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 4 persons, 1 car, 2 motorcycles, 1 truck, 1 umbrella, 136.8ms\n",
      "Speed: 3.6ms preprocess, 136.8ms inference, 1.1ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 4 persons, 2 cars, 3 motorcycles, 2 trucks, 1 umbrella, 137.6ms\n",
      "Speed: 2.9ms preprocess, 137.6ms inference, 1.3ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 5 persons, 1 car, 3 motorcycles, 2 trucks, 151.6ms\n",
      "Speed: 3.9ms preprocess, 151.6ms inference, 1.5ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 4 persons, 2 cars, 3 motorcycles, 2 trucks, 1 umbrella, 173.4ms\n",
      "Speed: 5.3ms preprocess, 173.4ms inference, 2.4ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 4 persons, 1 car, 4 motorcycles, 1 truck, 1 umbrella, 200.0ms\n",
      "Speed: 4.7ms preprocess, 200.0ms inference, 2.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 6 persons, 1 car, 3 motorcycles, 1 bus, 1 truck, 1 umbrella, 231.4ms\n",
      "Speed: 4.6ms preprocess, 231.4ms inference, 2.4ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 7 persons, 4 motorcycles, 1 bus, 1 truck, 1 umbrella, 252.5ms\n",
      "Speed: 6.1ms preprocess, 252.5ms inference, 3.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 2 persons, 1 car, 4 motorcycles, 2 buss, 1 truck, 266.3ms\n",
      "Speed: 5.7ms preprocess, 266.3ms inference, 3.1ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 2 persons, 1 car, 5 motorcycles, 1 bus, 1 truck, 276.7ms\n",
      "Speed: 11.1ms preprocess, 276.7ms inference, 2.9ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 2 persons, 2 cars, 4 motorcycles, 1 bus, 1 truck, 253.6ms\n",
      "Speed: 8.9ms preprocess, 253.6ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 2 persons, 2 cars, 3 motorcycles, 1 bus, 1 truck, 277.9ms\n",
      "Speed: 5.7ms preprocess, 277.9ms inference, 2.8ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 2 persons, 1 car, 3 motorcycles, 1 bus, 1 truck, 256.6ms\n",
      "Speed: 7.0ms preprocess, 256.6ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 person, 3 cars, 3 motorcycles, 1 bus, 1 truck, 249.1ms\n",
      "Speed: 8.8ms preprocess, 249.1ms inference, 3.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 person, 1 car, 3 motorcycles, 1 bus, 1 truck, 268.2ms\n",
      "Speed: 6.8ms preprocess, 268.2ms inference, 3.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 person, 2 cars, 3 motorcycles, 1 bus, 1 truck, 337.2ms\n",
      "Speed: 7.0ms preprocess, 337.2ms inference, 3.1ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 person, 2 cars, 3 motorcycles, 1 truck, 285.5ms\n",
      "Speed: 6.6ms preprocess, 285.5ms inference, 3.1ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 2 persons, 2 cars, 3 motorcycles, 1 truck, 309.5ms\n",
      "Speed: 8.6ms preprocess, 309.5ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 person, 2 cars, 3 motorcycles, 1 truck, 257.4ms\n",
      "Speed: 6.6ms preprocess, 257.4ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 2 persons, 1 car, 4 motorcycles, 1 bus, 1 truck, 269.8ms\n",
      "Speed: 8.6ms preprocess, 269.8ms inference, 2.4ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 2 persons, 2 cars, 3 motorcycles, 1 bus, 1 truck, 254.7ms\n",
      "Speed: 6.6ms preprocess, 254.7ms inference, 2.4ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 61\u001b[0m\n\u001b[0;32m     58\u001b[0m frame \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mresize(frame, (\u001b[38;5;241m1020\u001b[39m, \u001b[38;5;241m500\u001b[39m))\n\u001b[0;32m     60\u001b[0m \u001b[38;5;66;03m# ✅ YOLO Detection\u001b[39;00m\n\u001b[1;32m---> 61\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     62\u001b[0m a \u001b[38;5;241m=\u001b[39m results[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mboxes\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[0;32m     63\u001b[0m px \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(a)\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfloat\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\ultralytics\\engine\\model.py:560\u001b[0m, in \u001b[0;36mModel.predict\u001b[1;34m(self, source, stream, predictor, **kwargs)\u001b[0m\n\u001b[0;32m    558\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m prompts \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictor, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mset_prompts\u001b[39m\u001b[38;5;124m\"\u001b[39m):  \u001b[38;5;66;03m# for SAM-type models\u001b[39;00m\n\u001b[0;32m    559\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictor\u001b[38;5;241m.\u001b[39mset_prompts(prompts)\n\u001b[1;32m--> 560\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictor\u001b[38;5;241m.\u001b[39mpredict_cli(source\u001b[38;5;241m=\u001b[39msource) \u001b[38;5;28;01mif\u001b[39;00m is_cli \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredictor\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\ultralytics\\engine\\predictor.py:175\u001b[0m, in \u001b[0;36mBasePredictor.__call__\u001b[1;34m(self, source, model, stream, *args, **kwargs)\u001b[0m\n\u001b[0;32m    173\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream_inference(source, model, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    174\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 175\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstream_inference\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\utils\\_contextlib.py:36\u001b[0m, in \u001b[0;36m_wrap_generator.<locals>.generator_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     34\u001b[0m     \u001b[38;5;66;03m# Issuing `None` to a generator fires it up\u001b[39;00m\n\u001b[0;32m     35\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[1;32m---> 36\u001b[0m         response \u001b[38;5;241m=\u001b[39m \u001b[43mgen\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     38\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m     39\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     40\u001b[0m             \u001b[38;5;66;03m# Forward the response to our caller and get its next request\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\ultralytics\\engine\\predictor.py:261\u001b[0m, in \u001b[0;36mBasePredictor.stream_inference\u001b[1;34m(self, source, model, *args, **kwargs)\u001b[0m\n\u001b[0;32m    259\u001b[0m \u001b[38;5;66;03m# Inference\u001b[39;00m\n\u001b[0;32m    260\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m profilers[\u001b[38;5;241m1\u001b[39m]:\n\u001b[1;32m--> 261\u001b[0m     preds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minference\u001b[49m\u001b[43m(\u001b[49m\u001b[43mim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    262\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39membed:\n\u001b[0;32m    263\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m [preds] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(preds, torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;28;01melse\u001b[39;00m preds  \u001b[38;5;66;03m# yield embedding tensors\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\ultralytics\\engine\\predictor.py:145\u001b[0m, in \u001b[0;36mBasePredictor.inference\u001b[1;34m(self, im, *args, **kwargs)\u001b[0m\n\u001b[0;32m    139\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Runs inference on a given image using the specified model and arguments.\"\"\"\u001b[39;00m\n\u001b[0;32m    140\u001b[0m visualize \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    141\u001b[0m     increment_path(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave_dir \u001b[38;5;241m/\u001b[39m Path(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m])\u001b[38;5;241m.\u001b[39mstem, mkdir\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    142\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mvisualize \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msource_type\u001b[38;5;241m.\u001b[39mtensor)\n\u001b[0;32m    143\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    144\u001b[0m )\n\u001b[1;32m--> 145\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maugment\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maugment\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvisualize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvisualize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\ultralytics\\nn\\autobackend.py:557\u001b[0m, in \u001b[0;36mAutoBackend.forward\u001b[1;34m(self, im, augment, visualize, embed)\u001b[0m\n\u001b[0;32m    555\u001b[0m \u001b[38;5;66;03m# PyTorch\u001b[39;00m\n\u001b[0;32m    556\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpt \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnn_module:\n\u001b[1;32m--> 557\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maugment\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maugment\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvisualize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvisualize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43membed\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    559\u001b[0m \u001b[38;5;66;03m# TorchScript\u001b[39;00m\n\u001b[0;32m    560\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjit:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\ultralytics\\nn\\tasks.py:114\u001b[0m, in \u001b[0;36mBaseModel.forward\u001b[1;34m(self, x, *args, **kwargs)\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mdict\u001b[39m):  \u001b[38;5;66;03m# for cases of training and validating while training.\u001b[39;00m\n\u001b[0;32m    113\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss(x, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m--> 114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\ultralytics\\nn\\tasks.py:132\u001b[0m, in \u001b[0;36mBaseModel.predict\u001b[1;34m(self, x, profile, visualize, augment, embed)\u001b[0m\n\u001b[0;32m    130\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m augment:\n\u001b[0;32m    131\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_predict_augment(x)\n\u001b[1;32m--> 132\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_predict_once\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprofile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvisualize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membed\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\ultralytics\\nn\\tasks.py:153\u001b[0m, in \u001b[0;36mBaseModel._predict_once\u001b[1;34m(self, x, profile, visualize, embed)\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m profile:\n\u001b[0;32m    152\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_profile_one_layer(m, x, dt)\n\u001b[1;32m--> 153\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# run\u001b[39;00m\n\u001b[0;32m    154\u001b[0m y\u001b[38;5;241m.\u001b[39mappend(x \u001b[38;5;28;01mif\u001b[39;00m m\u001b[38;5;241m.\u001b[39mi \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)  \u001b[38;5;66;03m# save output\u001b[39;00m\n\u001b[0;32m    155\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m visualize:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\ultralytics\\nn\\modules\\block.py:238\u001b[0m, in \u001b[0;36mC2f.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    236\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m    237\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Forward pass through C2f layer.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 238\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcv1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mchunk(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m    239\u001b[0m     y\u001b[38;5;241m.\u001b[39mextend(m(y[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]) \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mm)\n\u001b[0;32m    240\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcv2(torch\u001b[38;5;241m.\u001b[39mcat(y, \u001b[38;5;241m1\u001b[39m))\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\ultralytics\\nn\\modules\\conv.py:55\u001b[0m, in \u001b[0;36mConv.forward_fuse\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward_fuse\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m     54\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Apply convolution and activation without batch normalization.\"\"\"\u001b[39;00m\n\u001b[1;32m---> 55\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mact(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:554\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    553\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 554\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:549\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    537\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    538\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(\n\u001b[0;32m    539\u001b[0m         F\u001b[38;5;241m.\u001b[39mpad(\n\u001b[0;32m    540\u001b[0m             \u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    547\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups,\n\u001b[0;32m    548\u001b[0m     )\n\u001b[1;32m--> 549\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    550\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\n\u001b[0;32m    551\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import pandas as pd\n",
    "from ultralytics import YOLO\n",
    "from tracker import *\n",
    "import numpy as np\n",
    "import csv\n",
    "import os\n",
    "import time\n",
    "\n",
    "# ✅ Load YOLO model\n",
    "model = YOLO('yolov8s.pt')\n",
    "\n",
    "# ✅ Object classes\n",
    "class_list = [\n",
    "    \"person\", \"bicycle\", \"car\", \"motorcycle\", \"airplane\", \"bus\", \"train\", \"truck\", \"boat\",\n",
    "    \"traffic light\", \"fire hydrant\", \"stop sign\", \"parking meter\", \"bench\", \"bird\", \"cat\",\n",
    "    \"dog\", \"horse\", \"sheep\", \"cow\", \"elephant\", \"bear\", \"zebra\", \"giraffe\", \"backpack\",\n",
    "    \"umbrella\", \"handbag\", \"tie\", \"suitcase\", \"frisbee\", \"skis\", \"snowboard\", \"sports ball\",\n",
    "    \"kite\", \"baseball bat\", \"baseball glove\", \"skateboard\", \"surfboard\", \"tennis racket\",\n",
    "    \"bottle\", \"wine glass\", \"cup\", \"fork\", \"knife\", \"spoon\", \"bowl\", \"banana\", \"apple\",\n",
    "    \"sandwich\", \"orange\", \"broccoli\", \"carrot\", \"hot dog\", \"pizza\", \"donut\", \"cake\",\n",
    "    \"chair\", \"couch\", \"potted plant\", \"bed\", \"dining table\", \"toilet\", \"TV\", \"laptop\",\n",
    "    \"mouse\", \"remote\", \"keyboard\", \"cell phone\", \"microwave\", \"oven\", \"toaster\", \"sink\",\n",
    "    \"refrigerator\", \"book\", \"clock\", \"vase\", \"scissors\", \"teddy bear\", \"hair drier\", \"toothbrush\"\n",
    "]\n",
    "\n",
    "# ✅ Initialize tracker\n",
    "tracker = Tracker()\n",
    "cap = cv2.VideoCapture('camp12_morning.MOV')\n",
    "\n",
    "# ✅ CSV File Setup\n",
    "csv_filename = \"vehicles_summary.csv\"\n",
    "\n",
    "# ✅ Create CSV file if it doesn't exist\n",
    "if not os.path.exists(csv_filename):\n",
    "    with open(csv_filename, mode=\"w\", newline=\"\") as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow([\"Timestamp\", \"Cars\", \"Buses\", \"Trucks\", \"Motorcycles\"])\n",
    "\n",
    "# ✅ Define reference lines\n",
    "red_line_y = 360\n",
    "blue_line_y = 400\n",
    "offset = 7  # Allow slight variation due to tracking jitter\n",
    "\n",
    "# ✅ Define vehicle classes to track\n",
    "vehicle_classes = [\"car\", \"bus\", \"truck\", \"motorcycle\"]\n",
    "vehicle_counts = {\"car\": 0, \"bus\": 0, \"truck\": 0, \"motorcycle\": 0}\n",
    "\n",
    "# ✅ Store vehicle IDs that crossed the red line first\n",
    "crossed_red = {}\n",
    "counter_down = []\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    frame = cv2.resize(frame, (1020, 500))\n",
    "\n",
    "    # ✅ YOLO Detection\n",
    "    results = model.predict(frame)\n",
    "    a = results[0].boxes.data.detach().cpu().numpy()\n",
    "    px = pd.DataFrame(a).astype(\"float\")\n",
    "\n",
    "    # ✅ Store detections\n",
    "    detections = []\n",
    "    detected_vehicles = {}\n",
    "\n",
    "    for _, row in px.iterrows():\n",
    "        x1, y1, x2, y2 = int(row[0]), int(row[1]), int(row[2]), int(row[3])\n",
    "        d = int(row[5])\n",
    "        vehicle_type = class_list[d]\n",
    "\n",
    "        if vehicle_type in vehicle_classes:\n",
    "            detections.append([x1, y1, x2, y2])\n",
    "            detected_vehicles[(x1, y1, x2, y2)] = vehicle_type\n",
    "\n",
    "    # ✅ Ensure 'detections' is not empty\n",
    "    bbox_id = tracker.update(np.array(detections)) if detections else []\n",
    "\n",
    "    # ✅ Process ALL detected vehicles\n",
    "    for bbox in bbox_id:\n",
    "        x3, y3, x4, y4, vehicle_id = bbox\n",
    "        cx, cy = (x3 + x4) // 2, (y3 + y4) // 2\n",
    "\n",
    "        vehicle_type = detected_vehicles.get((x3, y3, x4, y4), \"unknown\")\n",
    "\n",
    "        # ✅ Check if the vehicle crosses the RED line first\n",
    "        if red_line_y - offset < cy < red_line_y + offset:\n",
    "            crossed_red[vehicle_id] = (cy, vehicle_type)\n",
    "\n",
    "        # ✅ Only consider vehicles that crossed red before reaching blue\n",
    "        if vehicle_id in crossed_red and blue_line_y - offset < cy < blue_line_y + offset:\n",
    "            _, v_type = crossed_red[vehicle_id]\n",
    "\n",
    "            # ✅ Draw circle at the blue line for valid vehicles\n",
    "            cv2.circle(frame, (cx, cy), 4, (0, 0, 255), -1)\n",
    "            cv2.putText(frame, f\"{v_type}-{vehicle_id}\", (cx, cy), cv2.FONT_HERSHEY_COMPLEX, 0.8, (0, 255, 255), 2)\n",
    "\n",
    "            # ✅ Add to counter only once\n",
    "            if vehicle_id not in counter_down:\n",
    "                counter_down.append(vehicle_id)\n",
    "                vehicle_counts[v_type] += 1\n",
    "\n",
    "    # ✅ Draw reference lines\n",
    "    cv2.line(frame, (260, red_line_y), (724, red_line_y), (0, 0, 255), 3)\n",
    "    cv2.putText(frame, 'red line', (260, red_line_y), cv2.FONT_HERSHEY_COMPLEX, 0.5, (255, 255, 255), 1, cv2.LINE_AA)\n",
    "\n",
    "    cv2.line(frame, (200, blue_line_y), (779, blue_line_y), (255, 0, 0), 3)\n",
    "    cv2.putText(frame, 'blue line', (200, blue_line_y), cv2.FONT_HERSHEY_COMPLEX, 0.5, (255, 255, 255), 1, cv2.LINE_AA)\n",
    "\n",
    "    # ✅ Display vehicle count\n",
    "    cv2.putText(frame, f\"Cars: {vehicle_counts['car']}  Buses: {vehicle_counts['bus']}  Trucks: {vehicle_counts['truck']}  Motorcycles: {vehicle_counts['motorcycle']}\",\n",
    "                (60, 40), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 1, cv2.LINE_AA)\n",
    "\n",
    "    cv2.imshow(\"frames\", frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == 27:\n",
    "        break\n",
    "\n",
    "# ✅ Log the final vehicle count when the video ends\n",
    "timestamp = time.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "number_of_lanes=2\n",
    "# ✅ Calculate light duration using the given formula\n",
    "light_duration = ((vehicle_counts[\"car\"] * 2) + \n",
    "                  (vehicle_counts[\"motorcycle\"] * 1.8) + \n",
    "                  ((vehicle_counts[\"bus\"] + vehicle_counts[\"truck\"]) * 3.5)) / number_of_lanes\n",
    "with open(csv_filename, mode=\"a\", newline=\"\") as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow([timestamp, vehicle_counts[\"car\"], vehicle_counts[\"bus\"], vehicle_counts[\"truck\"], vehicle_counts[\"motorcycle\"], round(light_duration, 2)])\n",
    "\n",
    "print(f\"✅ Final vehicle count saved to CSV: {vehicle_counts}, Light Duration: {round(light_duration, 2)} sec\")\n",
    "\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6e31b0b-8026-4de4-8cf7-3a80fb89f473",
   "metadata": {},
   "source": [
    "# Rain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a95947a-bc95-41c1-b920-e8d9b8d03011",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 320x640 3 persons, 1 car, 2 motorcycles, 2 trucks, 2 umbrellas, 274.9ms\n",
      "Speed: 5.2ms preprocess, 274.9ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 3 persons, 3 cars, 2 motorcycles, 3 trucks, 2 umbrellas, 272.7ms\n",
      "Speed: 4.4ms preprocess, 272.7ms inference, 3.3ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 3 persons, 1 car, 2 motorcycles, 3 trucks, 2 umbrellas, 307.4ms\n",
      "Speed: 6.2ms preprocess, 307.4ms inference, 2.4ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 3 persons, 3 motorcycles, 3 trucks, 2 umbrellas, 302.0ms\n",
      "Speed: 11.6ms preprocess, 302.0ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 3 persons, 2 cars, 3 motorcycles, 2 trucks, 2 umbrellas, 253.4ms\n",
      "Speed: 6.4ms preprocess, 253.4ms inference, 2.4ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 3 persons, 2 cars, 3 motorcycles, 2 trucks, 2 umbrellas, 260.0ms\n",
      "Speed: 4.7ms preprocess, 260.0ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 2 persons, 2 cars, 3 motorcycles, 2 trucks, 2 umbrellas, 257.7ms\n",
      "Speed: 5.9ms preprocess, 257.7ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 person, 2 cars, 2 motorcycles, 2 trucks, 2 umbrellas, 233.7ms\n",
      "Speed: 6.2ms preprocess, 233.7ms inference, 2.4ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 2 persons, 3 cars, 2 motorcycles, 2 trucks, 1 umbrella, 233.1ms\n",
      "Speed: 5.4ms preprocess, 233.1ms inference, 2.4ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 2 cars, 2 motorcycles, 1 bus, 3 trucks, 233.2ms\n",
      "Speed: 7.3ms preprocess, 233.2ms inference, 4.1ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 2 cars, 2 motorcycles, 1 bus, 2 trucks, 308.8ms\n",
      "Speed: 15.1ms preprocess, 308.8ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 person, 6 cars, 2 motorcycles, 1 bus, 1 truck, 1 umbrella, 229.9ms\n",
      "Speed: 6.5ms preprocess, 229.9ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 person, 7 cars, 2 motorcycles, 1 bus, 2 trucks, 1 umbrella, 226.0ms\n",
      "Speed: 5.4ms preprocess, 226.0ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 8 cars, 3 motorcycles, 1 umbrella, 227.0ms\n",
      "Speed: 7.4ms preprocess, 227.0ms inference, 3.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 5 cars, 2 motorcycles, 1 bus, 2 trucks, 1 umbrella, 232.3ms\n",
      "Speed: 5.4ms preprocess, 232.3ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 5 cars, 2 motorcycles, 2 buss, 226.2ms\n",
      "Speed: 7.2ms preprocess, 226.2ms inference, 2.4ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 6 cars, 1 motorcycle, 2 buss, 2 trucks, 223.7ms\n",
      "Speed: 5.9ms preprocess, 223.7ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 6 cars, 1 motorcycle, 2 buss, 1 truck, 242.5ms\n",
      "Speed: 6.3ms preprocess, 242.5ms inference, 3.1ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 7 cars, 1 motorcycle, 2 buss, 1 truck, 280.6ms\n",
      "Speed: 15.4ms preprocess, 280.6ms inference, 3.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 6 cars, 1 motorcycle, 2 buss, 1 truck, 319.2ms\n",
      "Speed: 5.1ms preprocess, 319.2ms inference, 3.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 6 cars, 1 motorcycle, 2 buss, 1 truck, 297.9ms\n",
      "Speed: 5.4ms preprocess, 297.9ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 6 cars, 1 motorcycle, 3 buss, 2 trucks, 305.7ms\n",
      "Speed: 5.0ms preprocess, 305.7ms inference, 2.4ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 6 cars, 1 motorcycle, 2 buss, 2 trucks, 266.3ms\n",
      "Speed: 5.6ms preprocess, 266.3ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 person, 8 cars, 1 motorcycle, 3 buss, 1 train, 1 umbrella, 233.6ms\n",
      "Speed: 5.5ms preprocess, 233.6ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 person, 5 cars, 1 motorcycle, 2 buss, 1 umbrella, 239.5ms\n",
      "Speed: 5.0ms preprocess, 239.5ms inference, 2.4ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 person, 6 cars, 2 buss, 1 umbrella, 240.0ms\n",
      "Speed: 4.5ms preprocess, 240.0ms inference, 2.4ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 person, 6 cars, 2 buss, 2 umbrellas, 229.2ms\n",
      "Speed: 4.7ms preprocess, 229.2ms inference, 2.4ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 person, 6 cars, 2 buss, 1 umbrella, 230.5ms\n",
      "Speed: 6.1ms preprocess, 230.5ms inference, 2.4ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 2 persons, 6 cars, 2 buss, 1 truck, 1 umbrella, 239.7ms\n",
      "Speed: 4.9ms preprocess, 239.7ms inference, 2.4ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 2 persons, 6 cars, 1 bus, 2 trucks, 1 umbrella, 230.6ms\n",
      "Speed: 6.0ms preprocess, 230.6ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 2 persons, 7 cars, 1 bus, 2 trucks, 1 umbrella, 227.1ms\n",
      "Speed: 6.0ms preprocess, 227.1ms inference, 2.4ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 2 persons, 7 cars, 1 bus, 2 trucks, 1 umbrella, 252.5ms\n",
      "Speed: 5.6ms preprocess, 252.5ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 2 persons, 7 cars, 2 buss, 2 trucks, 2 umbrellas, 268.5ms\n",
      "Speed: 4.9ms preprocess, 268.5ms inference, 2.3ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 2 persons, 8 cars, 1 bus, 1 truck, 2 umbrellas, 229.7ms\n",
      "Speed: 7.1ms preprocess, 229.7ms inference, 2.4ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 person, 8 cars, 1 motorcycle, 1 bus, 1 truck, 2 umbrellas, 248.7ms\n",
      "Speed: 6.1ms preprocess, 248.7ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 person, 7 cars, 1 motorcycle, 1 bus, 1 truck, 2 umbrellas, 259.4ms\n",
      "Speed: 5.3ms preprocess, 259.4ms inference, 3.1ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 person, 7 cars, 1 motorcycle, 1 bus, 1 truck, 2 umbrellas, 252.1ms\n",
      "Speed: 5.5ms preprocess, 252.1ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 person, 7 cars, 1 motorcycle, 1 bus, 1 truck, 2 umbrellas, 270.1ms\n",
      "Speed: 5.4ms preprocess, 270.1ms inference, 3.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 3 persons, 6 cars, 1 motorcycle, 1 bus, 1 truck, 2 umbrellas, 289.8ms\n",
      "Speed: 5.2ms preprocess, 289.8ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 person, 6 cars, 1 motorcycle, 1 bus, 2 trucks, 2 umbrellas, 316.7ms\n",
      "Speed: 5.5ms preprocess, 316.7ms inference, 2.9ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 person, 6 cars, 1 motorcycle, 1 bus, 2 trucks, 1 traffic light, 2 umbrellas, 319.5ms\n",
      "Speed: 10.6ms preprocess, 319.5ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 person, 8 cars, 1 motorcycle, 1 bus, 1 truck, 1 traffic light, 2 umbrellas, 276.8ms\n",
      "Speed: 6.3ms preprocess, 276.8ms inference, 3.1ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 61\u001b[0m\n\u001b[0;32m     58\u001b[0m frame \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mresize(frame, (\u001b[38;5;241m1020\u001b[39m, \u001b[38;5;241m500\u001b[39m))\n\u001b[0;32m     60\u001b[0m \u001b[38;5;66;03m# ✅ YOLO Detection\u001b[39;00m\n\u001b[1;32m---> 61\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     62\u001b[0m a \u001b[38;5;241m=\u001b[39m results[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mboxes\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[0;32m     63\u001b[0m px \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(a)\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfloat\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\ultralytics\\engine\\model.py:560\u001b[0m, in \u001b[0;36mModel.predict\u001b[1;34m(self, source, stream, predictor, **kwargs)\u001b[0m\n\u001b[0;32m    558\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m prompts \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictor, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mset_prompts\u001b[39m\u001b[38;5;124m\"\u001b[39m):  \u001b[38;5;66;03m# for SAM-type models\u001b[39;00m\n\u001b[0;32m    559\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictor\u001b[38;5;241m.\u001b[39mset_prompts(prompts)\n\u001b[1;32m--> 560\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictor\u001b[38;5;241m.\u001b[39mpredict_cli(source\u001b[38;5;241m=\u001b[39msource) \u001b[38;5;28;01mif\u001b[39;00m is_cli \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredictor\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\ultralytics\\engine\\predictor.py:175\u001b[0m, in \u001b[0;36mBasePredictor.__call__\u001b[1;34m(self, source, model, stream, *args, **kwargs)\u001b[0m\n\u001b[0;32m    173\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream_inference(source, model, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    174\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 175\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstream_inference\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\utils\\_contextlib.py:36\u001b[0m, in \u001b[0;36m_wrap_generator.<locals>.generator_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     34\u001b[0m     \u001b[38;5;66;03m# Issuing `None` to a generator fires it up\u001b[39;00m\n\u001b[0;32m     35\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[1;32m---> 36\u001b[0m         response \u001b[38;5;241m=\u001b[39m \u001b[43mgen\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     38\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m     39\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     40\u001b[0m             \u001b[38;5;66;03m# Forward the response to our caller and get its next request\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\ultralytics\\engine\\predictor.py:261\u001b[0m, in \u001b[0;36mBasePredictor.stream_inference\u001b[1;34m(self, source, model, *args, **kwargs)\u001b[0m\n\u001b[0;32m    259\u001b[0m \u001b[38;5;66;03m# Inference\u001b[39;00m\n\u001b[0;32m    260\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m profilers[\u001b[38;5;241m1\u001b[39m]:\n\u001b[1;32m--> 261\u001b[0m     preds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minference\u001b[49m\u001b[43m(\u001b[49m\u001b[43mim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    262\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39membed:\n\u001b[0;32m    263\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m [preds] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(preds, torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;28;01melse\u001b[39;00m preds  \u001b[38;5;66;03m# yield embedding tensors\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\ultralytics\\engine\\predictor.py:145\u001b[0m, in \u001b[0;36mBasePredictor.inference\u001b[1;34m(self, im, *args, **kwargs)\u001b[0m\n\u001b[0;32m    139\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Runs inference on a given image using the specified model and arguments.\"\"\"\u001b[39;00m\n\u001b[0;32m    140\u001b[0m visualize \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    141\u001b[0m     increment_path(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave_dir \u001b[38;5;241m/\u001b[39m Path(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m])\u001b[38;5;241m.\u001b[39mstem, mkdir\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    142\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mvisualize \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msource_type\u001b[38;5;241m.\u001b[39mtensor)\n\u001b[0;32m    143\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    144\u001b[0m )\n\u001b[1;32m--> 145\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maugment\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maugment\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvisualize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvisualize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\ultralytics\\nn\\autobackend.py:557\u001b[0m, in \u001b[0;36mAutoBackend.forward\u001b[1;34m(self, im, augment, visualize, embed)\u001b[0m\n\u001b[0;32m    555\u001b[0m \u001b[38;5;66;03m# PyTorch\u001b[39;00m\n\u001b[0;32m    556\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpt \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnn_module:\n\u001b[1;32m--> 557\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maugment\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maugment\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvisualize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvisualize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43membed\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    559\u001b[0m \u001b[38;5;66;03m# TorchScript\u001b[39;00m\n\u001b[0;32m    560\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjit:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\ultralytics\\nn\\tasks.py:114\u001b[0m, in \u001b[0;36mBaseModel.forward\u001b[1;34m(self, x, *args, **kwargs)\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mdict\u001b[39m):  \u001b[38;5;66;03m# for cases of training and validating while training.\u001b[39;00m\n\u001b[0;32m    113\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss(x, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m--> 114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\ultralytics\\nn\\tasks.py:132\u001b[0m, in \u001b[0;36mBaseModel.predict\u001b[1;34m(self, x, profile, visualize, augment, embed)\u001b[0m\n\u001b[0;32m    130\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m augment:\n\u001b[0;32m    131\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_predict_augment(x)\n\u001b[1;32m--> 132\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_predict_once\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprofile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvisualize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membed\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\ultralytics\\nn\\tasks.py:153\u001b[0m, in \u001b[0;36mBaseModel._predict_once\u001b[1;34m(self, x, profile, visualize, embed)\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m profile:\n\u001b[0;32m    152\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_profile_one_layer(m, x, dt)\n\u001b[1;32m--> 153\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# run\u001b[39;00m\n\u001b[0;32m    154\u001b[0m y\u001b[38;5;241m.\u001b[39mappend(x \u001b[38;5;28;01mif\u001b[39;00m m\u001b[38;5;241m.\u001b[39mi \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)  \u001b[38;5;66;03m# save output\u001b[39;00m\n\u001b[0;32m    155\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m visualize:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\ultralytics\\nn\\modules\\block.py:239\u001b[0m, in \u001b[0;36mC2f.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    237\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Forward pass through C2f layer.\"\"\"\u001b[39;00m\n\u001b[0;32m    238\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcv1(x)\u001b[38;5;241m.\u001b[39mchunk(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m--> 239\u001b[0m \u001b[43my\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mm\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mm\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mm\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    240\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcv2(torch\u001b[38;5;241m.\u001b[39mcat(y, \u001b[38;5;241m1\u001b[39m))\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\ultralytics\\nn\\modules\\block.py:239\u001b[0m, in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    237\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Forward pass through C2f layer.\"\"\"\u001b[39;00m\n\u001b[0;32m    238\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcv1(x)\u001b[38;5;241m.\u001b[39mchunk(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m--> 239\u001b[0m y\u001b[38;5;241m.\u001b[39mextend(\u001b[43mm\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mm)\n\u001b[0;32m    240\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcv2(torch\u001b[38;5;241m.\u001b[39mcat(y, \u001b[38;5;241m1\u001b[39m))\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\ultralytics\\nn\\modules\\block.py:348\u001b[0m, in \u001b[0;36mBottleneck.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    346\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m    347\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Applies the YOLO FPN to input data.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 348\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcv2(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcv1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcv2(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcv1(x))\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\ultralytics\\nn\\modules\\conv.py:55\u001b[0m, in \u001b[0;36mConv.forward_fuse\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward_fuse\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m     54\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Apply convolution and activation without batch normalization.\"\"\"\u001b[39;00m\n\u001b[1;32m---> 55\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mact\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\activation.py:432\u001b[0m, in \u001b[0;36mSiLU.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    431\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 432\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msilu\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\functional.py:2379\u001b[0m, in \u001b[0;36msilu\u001b[1;34m(input, inplace)\u001b[0m\n\u001b[0;32m   2377\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(silu, (\u001b[38;5;28minput\u001b[39m,), \u001b[38;5;28minput\u001b[39m, inplace\u001b[38;5;241m=\u001b[39minplace)\n\u001b[0;32m   2378\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inplace:\n\u001b[1;32m-> 2379\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msilu_\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2380\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_nn\u001b[38;5;241m.\u001b[39msilu(\u001b[38;5;28minput\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import pandas as pd\n",
    "from ultralytics import YOLO\n",
    "from tracker import *\n",
    "import numpy as np\n",
    "import csv\n",
    "import os\n",
    "import time\n",
    "\n",
    "# ✅ Load YOLO model\n",
    "model = YOLO('yolov8s.pt')\n",
    "\n",
    "# ✅ Object classes\n",
    "class_list = [\n",
    "    \"person\", \"bicycle\", \"car\", \"motorcycle\", \"airplane\", \"bus\", \"train\", \"truck\", \"boat\",\n",
    "    \"traffic light\", \"fire hydrant\", \"stop sign\", \"parking meter\", \"bench\", \"bird\", \"cat\",\n",
    "    \"dog\", \"horse\", \"sheep\", \"cow\", \"elephant\", \"bear\", \"zebra\", \"giraffe\", \"backpack\",\n",
    "    \"umbrella\", \"handbag\", \"tie\", \"suitcase\", \"frisbee\", \"skis\", \"snowboard\", \"sports ball\",\n",
    "    \"kite\", \"baseball bat\", \"baseball glove\", \"skateboard\", \"surfboard\", \"tennis racket\",\n",
    "    \"bottle\", \"wine glass\", \"cup\", \"fork\", \"knife\", \"spoon\", \"bowl\", \"banana\", \"apple\",\n",
    "    \"sandwich\", \"orange\", \"broccoli\", \"carrot\", \"hot dog\", \"pizza\", \"donut\", \"cake\",\n",
    "    \"chair\", \"couch\", \"potted plant\", \"bed\", \"dining table\", \"toilet\", \"TV\", \"laptop\",\n",
    "    \"mouse\", \"remote\", \"keyboard\", \"cell phone\", \"microwave\", \"oven\", \"toaster\", \"sink\",\n",
    "    \"refrigerator\", \"book\", \"clock\", \"vase\", \"scissors\", \"teddy bear\", \"hair drier\", \"toothbrush\"\n",
    "]\n",
    "\n",
    "# ✅ Initialize tracker\n",
    "tracker = Tracker()\n",
    "cap = cv2.VideoCapture('camp12_rain_noon.mp4')\n",
    "\n",
    "# ✅ CSV File Setup\n",
    "csv_filename = \"vehicles_summary.csv\"\n",
    "\n",
    "# ✅ Create CSV file if it doesn't exist\n",
    "if not os.path.exists(csv_filename):\n",
    "    with open(csv_filename, mode=\"w\", newline=\"\") as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow([\"Timestamp\", \"Cars\", \"Buses\", \"Trucks\", \"Motorcycles\"])\n",
    "\n",
    "# ✅ Define reference lines\n",
    "red_line_y = 320\n",
    "blue_line_y = 350\n",
    "offset = 7  # Allow slight variation due to tracking jitter\n",
    "\n",
    "# ✅ Define vehicle classes to track\n",
    "vehicle_classes = [\"car\", \"bus\", \"truck\", \"motorcycle\"]\n",
    "vehicle_counts = {\"car\": 0, \"bus\": 0, \"truck\": 0, \"motorcycle\": 0}\n",
    "\n",
    "# ✅ Store vehicle IDs that crossed the red line first\n",
    "crossed_red = {}\n",
    "counter_down = []\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    frame = cv2.resize(frame, (1020, 500))\n",
    "\n",
    "    # ✅ YOLO Detection\n",
    "    results = model.predict(frame)\n",
    "    a = results[0].boxes.data.detach().cpu().numpy()\n",
    "    px = pd.DataFrame(a).astype(\"float\")\n",
    "\n",
    "    # ✅ Store detections\n",
    "    detections = []\n",
    "    detected_vehicles = {}\n",
    "\n",
    "    for _, row in px.iterrows():\n",
    "        x1, y1, x2, y2 = int(row[0]), int(row[1]), int(row[2]), int(row[3])\n",
    "        d = int(row[5])\n",
    "        vehicle_type = class_list[d]\n",
    "\n",
    "        if vehicle_type in vehicle_classes:\n",
    "            detections.append([x1, y1, x2, y2])\n",
    "            detected_vehicles[(x1, y1, x2, y2)] = vehicle_type\n",
    "\n",
    "    # ✅ Ensure 'detections' is not empty\n",
    "    bbox_id = tracker.update(np.array(detections)) if detections else []\n",
    "\n",
    "    # ✅ Process ALL detected vehicles\n",
    "    for bbox in bbox_id:\n",
    "        x3, y3, x4, y4, vehicle_id = bbox\n",
    "        cx, cy = (x3 + x4) // 2, (y3 + y4) // 2\n",
    "\n",
    "        vehicle_type = detected_vehicles.get((x3, y3, x4, y4), \"unknown\")\n",
    "\n",
    "        # ✅ Check if the vehicle crosses the RED line first\n",
    "        if red_line_y - offset < cy < red_line_y + offset:\n",
    "            crossed_red[vehicle_id] = (cy, vehicle_type)\n",
    "\n",
    "        # ✅ Only consider vehicles that crossed red before reaching blue\n",
    "        if vehicle_id in crossed_red and blue_line_y - offset < cy < blue_line_y + offset:\n",
    "            _, v_type = crossed_red[vehicle_id]\n",
    "\n",
    "            # ✅ Draw circle at the blue line for valid vehicles\n",
    "            cv2.circle(frame, (cx, cy), 4, (0, 0, 255), -1)\n",
    "            cv2.putText(frame, f\"{v_type}-{vehicle_id}\", (cx, cy), cv2.FONT_HERSHEY_COMPLEX, 0.8, (0, 255, 255), 2)\n",
    "\n",
    "            # ✅ Add to counter only once\n",
    "            if vehicle_id not in counter_down:\n",
    "                counter_down.append(vehicle_id)\n",
    "                vehicle_counts[v_type] += 1\n",
    "\n",
    "    # ✅ Draw reference lines\n",
    "    cv2.line(frame, (180, red_line_y), (950, red_line_y), (0, 0, 255), 3)\n",
    "    cv2.putText(frame, 'red line', (180, red_line_y), cv2.FONT_HERSHEY_COMPLEX, 0.5, (255, 255, 255), 1, cv2.LINE_AA)\n",
    "\n",
    "    cv2.line(frame, (150, blue_line_y), (950, blue_line_y), (255, 0, 0), 3)\n",
    "    cv2.putText(frame, 'blue line', (150, blue_line_y), cv2.FONT_HERSHEY_COMPLEX, 0.5, (255, 255, 255), 1, cv2.LINE_AA)\n",
    "\n",
    "    # ✅ Display vehicle count\n",
    "    cv2.putText(frame, f\"Cars: {vehicle_counts['car']}  Buses: {vehicle_counts['bus']}  Trucks: {vehicle_counts['truck']}  Motorcycles: {vehicle_counts['motorcycle']}\",\n",
    "                (60, 40), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 1, cv2.LINE_AA)\n",
    "\n",
    "    cv2.imshow(\"frames\", frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == 27:\n",
    "        break\n",
    "\n",
    "# ✅ Log the final vehicle count when the video ends\n",
    "timestamp = time.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "number_of_lanes=2\n",
    "# ✅ Calculate light duration using the given formula\n",
    "light_duration = ((vehicle_counts[\"car\"] * 2) + \n",
    "                  (vehicle_counts[\"motorcycle\"] * 1.8) + \n",
    "                  ((vehicle_counts[\"bus\"] + vehicle_counts[\"truck\"]) * 3.5)) / number_of_lanes\n",
    "with open(csv_filename, mode=\"a\", newline=\"\") as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow([timestamp, vehicle_counts[\"car\"], vehicle_counts[\"bus\"], vehicle_counts[\"truck\"], vehicle_counts[\"motorcycle\"], round(light_duration, 2)])\n",
    "\n",
    "print(f\"✅ Final vehicle count saved to CSV: {vehicle_counts}, Light Duration: {round(light_duration, 2)} sec\")\n",
    "\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc5f6e8a-8a4e-4099-a626-46ad33665978",
   "metadata": {},
   "source": [
    "# Noon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3f5a74d0-777c-4c33-9bba-f8c21f0688a2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 320x640 7 persons, 10 cars, 5 motorcycles, 1 truck, 208.7ms\n",
      "Speed: 6.1ms preprocess, 208.7ms inference, 1.6ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 8 persons, 9 cars, 6 motorcycles, 1 truck, 241.4ms\n",
      "Speed: 4.1ms preprocess, 241.4ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 7 persons, 9 cars, 5 motorcycles, 1 truck, 221.9ms\n",
      "Speed: 4.7ms preprocess, 221.9ms inference, 2.9ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 7 persons, 9 cars, 5 motorcycles, 1 truck, 1 backpack, 232.1ms\n",
      "Speed: 3.3ms preprocess, 232.1ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 9 persons, 8 cars, 6 motorcycles, 1 truck, 225.5ms\n",
      "Speed: 76.3ms preprocess, 225.5ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 6 persons, 9 cars, 7 motorcycles, 1 truck, 219.6ms\n",
      "Speed: 5.0ms preprocess, 219.6ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 6 persons, 9 cars, 6 motorcycles, 1 truck, 216.6ms\n",
      "Speed: 3.8ms preprocess, 216.6ms inference, 3.1ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 6 persons, 9 cars, 7 motorcycles, 1 truck, 216.9ms\n",
      "Speed: 6.0ms preprocess, 216.9ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 9 persons, 10 cars, 6 motorcycles, 1 truck, 238.7ms\n",
      "Speed: 5.2ms preprocess, 238.7ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 8 persons, 11 cars, 7 motorcycles, 1 truck, 216.7ms\n",
      "Speed: 3.5ms preprocess, 216.7ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 5 persons, 10 cars, 8 motorcycles, 1 truck, 230.3ms\n",
      "Speed: 4.0ms preprocess, 230.3ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 6 persons, 7 cars, 7 motorcycles, 1 truck, 278.3ms\n",
      "Speed: 4.9ms preprocess, 278.3ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 6 persons, 8 cars, 6 motorcycles, 1 truck, 215.1ms\n",
      "Speed: 5.5ms preprocess, 215.1ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 7 persons, 8 cars, 6 motorcycles, 1 bus, 1 truck, 225.6ms\n",
      "Speed: 4.4ms preprocess, 225.6ms inference, 2.8ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 7 persons, 9 cars, 7 motorcycles, 1 bus, 1 truck, 218.9ms\n",
      "Speed: 6.2ms preprocess, 218.9ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 7 persons, 9 cars, 6 motorcycles, 1 bus, 1 truck, 252.7ms\n",
      "Speed: 4.7ms preprocess, 252.7ms inference, 2.8ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 6 persons, 7 cars, 6 motorcycles, 1 bus, 1 truck, 220.1ms\n",
      "Speed: 3.6ms preprocess, 220.1ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 5 persons, 7 cars, 6 motorcycles, 1 bus, 1 truck, 223.0ms\n",
      "Speed: 4.8ms preprocess, 223.0ms inference, 1.9ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 6 persons, 7 cars, 7 motorcycles, 1 bus, 1 truck, 255.6ms\n",
      "Speed: 4.0ms preprocess, 255.6ms inference, 2.9ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 5 persons, 9 cars, 6 motorcycles, 1 bus, 1 truck, 242.7ms\n",
      "Speed: 5.8ms preprocess, 242.7ms inference, 2.2ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 6 persons, 9 cars, 5 motorcycles, 1 bus, 1 truck, 163.2ms\n",
      "Speed: 3.5ms preprocess, 163.2ms inference, 1.9ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 6 persons, 9 cars, 4 motorcycles, 1 bus, 1 truck, 150.5ms\n",
      "Speed: 3.0ms preprocess, 150.5ms inference, 1.4ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 7 persons, 10 cars, 3 motorcycles, 1 truck, 128.5ms\n",
      "Speed: 2.9ms preprocess, 128.5ms inference, 1.2ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 6 persons, 10 cars, 3 motorcycles, 1 truck, 131.8ms\n",
      "Speed: 3.2ms preprocess, 131.8ms inference, 1.5ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 6 persons, 10 cars, 3 motorcycles, 1 truck, 132.0ms\n",
      "Speed: 3.2ms preprocess, 132.0ms inference, 1.4ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 5 persons, 9 cars, 3 motorcycles, 1 truck, 129.3ms\n",
      "Speed: 3.6ms preprocess, 129.3ms inference, 1.3ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 5 persons, 10 cars, 3 motorcycles, 1 truck, 1 traffic light, 135.5ms\n",
      "Speed: 4.3ms preprocess, 135.5ms inference, 1.5ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 4 persons, 9 cars, 3 motorcycles, 1 truck, 1 traffic light, 130.6ms\n",
      "Speed: 4.2ms preprocess, 130.6ms inference, 1.3ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 4 persons, 10 cars, 4 motorcycles, 1 truck, 1 traffic light, 131.2ms\n",
      "Speed: 3.7ms preprocess, 131.2ms inference, 1.5ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 4 persons, 11 cars, 3 motorcycles, 1 truck, 1 traffic light, 130.9ms\n",
      "Speed: 3.9ms preprocess, 130.9ms inference, 1.2ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 4 persons, 10 cars, 4 motorcycles, 1 truck, 1 traffic light, 127.2ms\n",
      "Speed: 2.7ms preprocess, 127.2ms inference, 1.3ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 4 persons, 10 cars, 4 motorcycles, 1 truck, 1 traffic light, 139.1ms\n",
      "Speed: 3.4ms preprocess, 139.1ms inference, 1.2ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 4 persons, 10 cars, 5 motorcycles, 1 truck, 1 traffic light, 129.3ms\n",
      "Speed: 3.2ms preprocess, 129.3ms inference, 1.2ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 4 persons, 10 cars, 5 motorcycles, 1 truck, 1 traffic light, 131.0ms\n",
      "Speed: 2.7ms preprocess, 131.0ms inference, 1.3ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 4 persons, 10 cars, 5 motorcycles, 1 truck, 1 traffic light, 132.5ms\n",
      "Speed: 3.1ms preprocess, 132.5ms inference, 1.4ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 4 persons, 10 cars, 5 motorcycles, 1 truck, 130.4ms\n",
      "Speed: 2.6ms preprocess, 130.4ms inference, 1.2ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 4 persons, 9 cars, 6 motorcycles, 1 truck, 1 traffic light, 129.5ms\n",
      "Speed: 2.8ms preprocess, 129.5ms inference, 1.4ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 4 persons, 8 cars, 5 motorcycles, 1 truck, 143.7ms\n",
      "Speed: 3.6ms preprocess, 143.7ms inference, 1.5ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 5 persons, 9 cars, 6 motorcycles, 1 truck, 168.0ms\n",
      "Speed: 3.7ms preprocess, 168.0ms inference, 1.9ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 4 persons, 10 cars, 6 motorcycles, 1 truck, 220.2ms\n",
      "Speed: 4.1ms preprocess, 220.2ms inference, 2.3ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 4 persons, 10 cars, 7 motorcycles, 1 truck, 241.1ms\n",
      "Speed: 5.2ms preprocess, 241.1ms inference, 2.3ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 4 persons, 9 cars, 6 motorcycles, 1 truck, 243.2ms\n",
      "Speed: 5.8ms preprocess, 243.2ms inference, 2.4ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 4 persons, 8 cars, 6 motorcycles, 1 truck, 279.8ms\n",
      "Speed: 5.8ms preprocess, 279.8ms inference, 3.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 4 persons, 8 cars, 8 motorcycles, 1 truck, 267.7ms\n",
      "Speed: 5.7ms preprocess, 267.7ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 4 persons, 7 cars, 7 motorcycles, 1 truck, 273.6ms\n",
      "Speed: 6.0ms preprocess, 273.6ms inference, 2.8ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 4 persons, 6 cars, 7 motorcycles, 1 truck, 283.3ms\n",
      "Speed: 5.6ms preprocess, 283.3ms inference, 3.7ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 5 persons, 6 cars, 6 motorcycles, 1 truck, 264.9ms\n",
      "Speed: 5.7ms preprocess, 264.9ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 5 persons, 6 cars, 7 motorcycles, 1 truck, 354.2ms\n",
      "Speed: 6.5ms preprocess, 354.2ms inference, 4.2ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 5 persons, 7 cars, 8 motorcycles, 1 truck, 354.6ms\n",
      "Speed: 5.8ms preprocess, 354.6ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 6 persons, 7 cars, 8 motorcycles, 1 truck, 293.4ms\n",
      "Speed: 6.4ms preprocess, 293.4ms inference, 4.9ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 7 persons, 6 cars, 6 motorcycles, 1 truck, 336.8ms\n",
      "Speed: 6.9ms preprocess, 336.8ms inference, 2.8ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 6 persons, 5 cars, 6 motorcycles, 356.5ms\n",
      "Speed: 5.9ms preprocess, 356.5ms inference, 3.3ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 6 persons, 5 cars, 6 motorcycles, 273.4ms\n",
      "Speed: 6.6ms preprocess, 273.4ms inference, 3.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 8 persons, 5 cars, 6 motorcycles, 545.1ms\n",
      "Speed: 6.4ms preprocess, 545.1ms inference, 8.3ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 7 persons, 5 cars, 5 motorcycles, 344.4ms\n",
      "Speed: 7.0ms preprocess, 344.4ms inference, 4.7ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 5 persons, 5 cars, 5 motorcycles, 375.9ms\n",
      "Speed: 13.1ms preprocess, 375.9ms inference, 3.3ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 6 persons, 5 cars, 6 motorcycles, 1183.2ms\n",
      "Speed: 18.4ms preprocess, 1183.2ms inference, 9.3ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 6 persons, 5 cars, 6 motorcycles, 381.3ms\n",
      "Speed: 23.6ms preprocess, 381.3ms inference, 3.1ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 6 persons, 5 cars, 7 motorcycles, 410.3ms\n",
      "Speed: 7.8ms preprocess, 410.3ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 5 persons, 5 cars, 7 motorcycles, 346.0ms\n",
      "Speed: 6.0ms preprocess, 346.0ms inference, 3.6ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 5 persons, 5 cars, 8 motorcycles, 450.0ms\n",
      "Speed: 16.0ms preprocess, 450.0ms inference, 2.9ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 4 persons, 6 cars, 9 motorcycles, 401.5ms\n",
      "Speed: 8.0ms preprocess, 401.5ms inference, 3.7ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 4 persons, 6 cars, 7 motorcycles, 306.1ms\n",
      "Speed: 6.4ms preprocess, 306.1ms inference, 3.1ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 6 persons, 6 cars, 8 motorcycles, 293.7ms\n",
      "Speed: 7.8ms preprocess, 293.7ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 5 persons, 5 cars, 8 motorcycles, 331.6ms\n",
      "Speed: 6.1ms preprocess, 331.6ms inference, 3.5ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 6 persons, 6 cars, 8 motorcycles, 300.2ms\n",
      "Speed: 5.1ms preprocess, 300.2ms inference, 3.2ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 6 persons, 6 cars, 7 motorcycles, 310.6ms\n",
      "Speed: 6.2ms preprocess, 310.6ms inference, 3.1ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 6 persons, 5 cars, 9 motorcycles, 288.9ms\n",
      "Speed: 5.7ms preprocess, 288.9ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 6 persons, 5 cars, 9 motorcycles, 284.3ms\n",
      "Speed: 5.7ms preprocess, 284.3ms inference, 2.9ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 4 persons, 5 cars, 7 motorcycles, 321.4ms\n",
      "Speed: 5.4ms preprocess, 321.4ms inference, 3.2ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 4 persons, 6 cars, 8 motorcycles, 292.3ms\n",
      "Speed: 5.4ms preprocess, 292.3ms inference, 3.1ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 3 persons, 7 cars, 9 motorcycles, 288.3ms\n",
      "Speed: 6.1ms preprocess, 288.3ms inference, 3.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 3 persons, 6 cars, 9 motorcycles, 313.4ms\n",
      "Speed: 5.5ms preprocess, 313.4ms inference, 3.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 3 persons, 7 cars, 8 motorcycles, 313.8ms\n",
      "Speed: 5.2ms preprocess, 313.8ms inference, 2.8ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 4 persons, 7 cars, 8 motorcycles, 303.3ms\n",
      "Speed: 6.1ms preprocess, 303.3ms inference, 2.9ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 6 persons, 8 cars, 9 motorcycles, 267.1ms\n",
      "Speed: 5.2ms preprocess, 267.1ms inference, 2.9ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 6 persons, 6 cars, 8 motorcycles, 296.7ms\n",
      "Speed: 5.9ms preprocess, 296.7ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 7 persons, 5 cars, 8 motorcycles, 251.8ms\n",
      "Speed: 6.1ms preprocess, 251.8ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 9 persons, 5 cars, 8 motorcycles, 603.3ms\n",
      "Speed: 7.8ms preprocess, 603.3ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 7 persons, 6 cars, 8 motorcycles, 263.8ms\n",
      "Speed: 5.1ms preprocess, 263.8ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 6 persons, 6 cars, 8 motorcycles, 266.4ms\n",
      "Speed: 6.5ms preprocess, 266.4ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 7 persons, 5 cars, 8 motorcycles, 266.0ms\n",
      "Speed: 5.8ms preprocess, 266.0ms inference, 3.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 7 persons, 5 cars, 8 motorcycles, 264.9ms\n",
      "Speed: 6.4ms preprocess, 264.9ms inference, 3.2ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 7 persons, 6 cars, 8 motorcycles, 265.0ms\n",
      "Speed: 6.3ms preprocess, 265.0ms inference, 2.8ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 9 persons, 5 cars, 9 motorcycles, 261.9ms\n",
      "Speed: 6.1ms preprocess, 261.9ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 9 persons, 5 cars, 10 motorcycles, 263.9ms\n",
      "Speed: 5.9ms preprocess, 263.9ms inference, 2.8ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 8 persons, 5 cars, 11 motorcycles, 278.9ms\n",
      "Speed: 5.7ms preprocess, 278.9ms inference, 2.8ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 9 persons, 2 cars, 11 motorcycles, 269.3ms\n",
      "Speed: 5.9ms preprocess, 269.3ms inference, 2.9ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 8 persons, 2 cars, 10 motorcycles, 271.9ms\n",
      "Speed: 7.0ms preprocess, 271.9ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 7 persons, 4 cars, 11 motorcycles, 265.3ms\n",
      "Speed: 5.0ms preprocess, 265.3ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 8 persons, 4 cars, 9 motorcycles, 263.2ms\n",
      "Speed: 6.1ms preprocess, 263.2ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 9 persons, 4 cars, 9 motorcycles, 268.4ms\n",
      "Speed: 5.7ms preprocess, 268.4ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 8 persons, 5 cars, 9 motorcycles, 254.3ms\n",
      "Speed: 5.3ms preprocess, 254.3ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 8 persons, 5 cars, 9 motorcycles, 254.4ms\n",
      "Speed: 5.3ms preprocess, 254.4ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 8 persons, 5 cars, 10 motorcycles, 260.2ms\n",
      "Speed: 6.7ms preprocess, 260.2ms inference, 2.4ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 7 persons, 4 cars, 10 motorcycles, 245.6ms\n",
      "Speed: 5.3ms preprocess, 245.6ms inference, 2.3ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 7 persons, 5 cars, 8 motorcycles, 256.5ms\n",
      "Speed: 5.2ms preprocess, 256.5ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 6 persons, 5 cars, 9 motorcycles, 240.3ms\n",
      "Speed: 6.9ms preprocess, 240.3ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 8 persons, 5 cars, 8 motorcycles, 241.6ms\n",
      "Speed: 5.5ms preprocess, 241.6ms inference, 2.4ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 6 persons, 5 cars, 9 motorcycles, 240.5ms\n",
      "Speed: 5.3ms preprocess, 240.5ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 7 persons, 4 cars, 9 motorcycles, 276.8ms\n",
      "Speed: 5.0ms preprocess, 276.8ms inference, 2.4ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 7 persons, 1 bicycle, 4 cars, 9 motorcycles, 278.4ms\n",
      "Speed: 6.0ms preprocess, 278.4ms inference, 2.9ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 8 persons, 1 bicycle, 4 cars, 9 motorcycles, 270.4ms\n",
      "Speed: 5.9ms preprocess, 270.4ms inference, 2.4ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 6 persons, 1 bicycle, 4 cars, 9 motorcycles, 243.1ms\n",
      "Speed: 5.3ms preprocess, 243.1ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 6 persons, 2 bicycles, 4 cars, 9 motorcycles, 234.8ms\n",
      "Speed: 5.0ms preprocess, 234.8ms inference, 2.2ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 8 persons, 1 bicycle, 4 cars, 9 motorcycles, 236.6ms\n",
      "Speed: 6.2ms preprocess, 236.6ms inference, 2.8ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 9 persons, 1 bicycle, 4 cars, 8 motorcycles, 228.1ms\n",
      "Speed: 5.0ms preprocess, 228.1ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 12 persons, 1 bicycle, 4 cars, 8 motorcycles, 241.1ms\n",
      "Speed: 5.5ms preprocess, 241.1ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 9 persons, 1 bicycle, 5 cars, 9 motorcycles, 242.5ms\n",
      "Speed: 5.3ms preprocess, 242.5ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 9 persons, 1 bicycle, 4 cars, 9 motorcycles, 232.1ms\n",
      "Speed: 4.6ms preprocess, 232.1ms inference, 3.7ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 8 persons, 1 bicycle, 5 cars, 9 motorcycles, 1 truck, 260.7ms\n",
      "Speed: 5.4ms preprocess, 260.7ms inference, 2.4ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 8 persons, 1 bicycle, 7 cars, 9 motorcycles, 236.0ms\n",
      "Speed: 6.2ms preprocess, 236.0ms inference, 2.3ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 10 persons, 1 bicycle, 5 cars, 7 motorcycles, 230.1ms\n",
      "Speed: 5.8ms preprocess, 230.1ms inference, 2.4ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 8 persons, 1 bicycle, 4 cars, 7 motorcycles, 235.2ms\n",
      "Speed: 5.7ms preprocess, 235.2ms inference, 2.2ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 9 persons, 1 bicycle, 5 cars, 6 motorcycles, 232.3ms\n",
      "Speed: 4.6ms preprocess, 232.3ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 9 persons, 1 bicycle, 7 cars, 6 motorcycles, 261.4ms\n",
      "Speed: 4.8ms preprocess, 261.4ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 8 persons, 1 bicycle, 5 cars, 7 motorcycles, 248.3ms\n",
      "Speed: 6.2ms preprocess, 248.3ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 8 persons, 1 bicycle, 3 cars, 7 motorcycles, 233.8ms\n",
      "Speed: 6.5ms preprocess, 233.8ms inference, 2.8ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 7 persons, 1 bicycle, 4 cars, 7 motorcycles, 269.5ms\n",
      "Speed: 5.1ms preprocess, 269.5ms inference, 2.3ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 7 persons, 1 bicycle, 3 cars, 7 motorcycles, 234.9ms\n",
      "Speed: 6.1ms preprocess, 234.9ms inference, 2.2ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 9 persons, 1 bicycle, 3 cars, 7 motorcycles, 1 truck, 253.1ms\n",
      "Speed: 5.3ms preprocess, 253.1ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 6 persons, 1 bicycle, 3 cars, 9 motorcycles, 256.6ms\n",
      "Speed: 5.2ms preprocess, 256.6ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 6 persons, 1 bicycle, 3 cars, 9 motorcycles, 264.6ms\n",
      "Speed: 4.8ms preprocess, 264.6ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 5 persons, 1 bicycle, 3 cars, 9 motorcycles, 237.9ms\n",
      "Speed: 4.6ms preprocess, 237.9ms inference, 2.3ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 5 persons, 1 bicycle, 4 cars, 10 motorcycles, 233.4ms\n",
      "Speed: 4.7ms preprocess, 233.4ms inference, 2.3ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 6 persons, 1 bicycle, 4 cars, 10 motorcycles, 246.9ms\n",
      "Speed: 4.7ms preprocess, 246.9ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 8 persons, 1 bicycle, 4 cars, 9 motorcycles, 231.9ms\n",
      "Speed: 7.1ms preprocess, 231.9ms inference, 2.3ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 7 persons, 1 bicycle, 4 cars, 8 motorcycles, 240.9ms\n",
      "Speed: 5.3ms preprocess, 240.9ms inference, 2.2ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 7 persons, 1 bicycle, 4 cars, 7 motorcycles, 235.1ms\n",
      "Speed: 5.4ms preprocess, 235.1ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 9 persons, 1 bicycle, 4 cars, 8 motorcycles, 245.9ms\n",
      "Speed: 5.2ms preprocess, 245.9ms inference, 2.3ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 9 persons, 1 bicycle, 4 cars, 8 motorcycles, 239.0ms\n",
      "Speed: 6.3ms preprocess, 239.0ms inference, 2.3ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 8 persons, 1 bicycle, 4 cars, 7 motorcycles, 275.3ms\n",
      "Speed: 5.3ms preprocess, 275.3ms inference, 2.8ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 6 persons, 1 bicycle, 5 cars, 7 motorcycles, 274.3ms\n",
      "Speed: 5.5ms preprocess, 274.3ms inference, 2.9ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 7 persons, 1 bicycle, 5 cars, 5 motorcycles, 301.0ms\n",
      "Speed: 5.0ms preprocess, 301.0ms inference, 2.4ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 7 persons, 1 bicycle, 5 cars, 7 motorcycles, 247.4ms\n",
      "Speed: 5.5ms preprocess, 247.4ms inference, 2.4ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 6 persons, 1 bicycle, 5 cars, 7 motorcycles, 242.5ms\n",
      "Speed: 4.6ms preprocess, 242.5ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 7 persons, 1 bicycle, 5 cars, 7 motorcycles, 242.2ms\n",
      "Speed: 4.7ms preprocess, 242.2ms inference, 2.2ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 4 persons, 6 cars, 7 motorcycles, 255.7ms\n",
      "Speed: 4.8ms preprocess, 255.7ms inference, 2.2ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 4 persons, 5 cars, 7 motorcycles, 244.4ms\n",
      "Speed: 4.5ms preprocess, 244.4ms inference, 2.1ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 4 persons, 5 cars, 6 motorcycles, 244.3ms\n",
      "Speed: 4.6ms preprocess, 244.3ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 6 persons, 6 cars, 7 motorcycles, 238.9ms\n",
      "Speed: 4.6ms preprocess, 238.9ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 8 persons, 6 cars, 5 motorcycles, 238.9ms\n",
      "Speed: 5.2ms preprocess, 238.9ms inference, 2.4ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 8 persons, 5 cars, 5 motorcycles, 1 truck, 242.2ms\n",
      "Speed: 5.2ms preprocess, 242.2ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 6 persons, 5 cars, 5 motorcycles, 1 truck, 243.2ms\n",
      "Speed: 5.4ms preprocess, 243.2ms inference, 2.2ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 5 persons, 5 cars, 5 motorcycles, 1 truck, 243.7ms\n",
      "Speed: 4.8ms preprocess, 243.7ms inference, 2.3ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 7 persons, 7 cars, 5 motorcycles, 241.0ms\n",
      "Speed: 5.1ms preprocess, 241.0ms inference, 2.2ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 7 persons, 7 cars, 5 motorcycles, 242.2ms\n",
      "Speed: 4.6ms preprocess, 242.2ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 5 persons, 8 cars, 5 motorcycles, 235.0ms\n",
      "Speed: 4.4ms preprocess, 235.0ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 4 persons, 10 cars, 5 motorcycles, 241.6ms\n",
      "Speed: 5.3ms preprocess, 241.6ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 5 persons, 8 cars, 4 motorcycles, 328.1ms\n",
      "Speed: 6.9ms preprocess, 328.1ms inference, 4.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 6 persons, 7 cars, 5 motorcycles, 410.0ms\n",
      "Speed: 9.8ms preprocess, 410.0ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 5 persons, 9 cars, 4 motorcycles, 302.0ms\n",
      "Speed: 8.4ms preprocess, 302.0ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 6 persons, 7 cars, 3 motorcycles, 258.3ms\n",
      "Speed: 8.4ms preprocess, 258.3ms inference, 2.4ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 3 persons, 8 cars, 3 motorcycles, 247.3ms\n",
      "Speed: 6.4ms preprocess, 247.3ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 3 persons, 8 cars, 4 motorcycles, 273.5ms\n",
      "Speed: 5.4ms preprocess, 273.5ms inference, 2.4ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 4 persons, 8 cars, 3 motorcycles, 252.3ms\n",
      "Speed: 5.7ms preprocess, 252.3ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 3 persons, 7 cars, 3 motorcycles, 288.4ms\n",
      "Speed: 6.5ms preprocess, 288.4ms inference, 3.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 4 persons, 8 cars, 2 motorcycles, 261.5ms\n",
      "Speed: 5.9ms preprocess, 261.5ms inference, 2.2ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 3 persons, 6 cars, 2 motorcycles, 241.4ms\n",
      "Speed: 6.6ms preprocess, 241.4ms inference, 2.3ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 3 persons, 7 cars, 2 motorcycles, 242.0ms\n",
      "Speed: 6.9ms preprocess, 242.0ms inference, 2.1ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 5 persons, 6 cars, 2 motorcycles, 246.3ms\n",
      "Speed: 5.7ms preprocess, 246.3ms inference, 2.2ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 5 persons, 6 cars, 2 motorcycles, 235.5ms\n",
      "Speed: 5.4ms preprocess, 235.5ms inference, 2.2ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 4 persons, 7 cars, 2 motorcycles, 238.3ms\n",
      "Speed: 5.4ms preprocess, 238.3ms inference, 2.4ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 4 persons, 7 cars, 1 motorcycle, 242.4ms\n",
      "Speed: 6.2ms preprocess, 242.4ms inference, 2.4ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 5 persons, 7 cars, 1 motorcycle, 241.5ms\n",
      "Speed: 5.6ms preprocess, 241.5ms inference, 2.2ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 5 persons, 8 cars, 1 motorcycle, 242.9ms\n",
      "Speed: 5.2ms preprocess, 242.9ms inference, 2.2ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 4 persons, 8 cars, 2 motorcycles, 264.6ms\n",
      "Speed: 7.0ms preprocess, 264.6ms inference, 2.3ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 6 persons, 8 cars, 3 motorcycles, 267.2ms\n",
      "Speed: 6.3ms preprocess, 267.2ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 6 persons, 8 cars, 1 motorcycle, 265.4ms\n",
      "Speed: 7.5ms preprocess, 265.4ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 5 persons, 9 cars, 1 motorcycle, 262.9ms\n",
      "Speed: 6.1ms preprocess, 262.9ms inference, 2.4ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 5 persons, 8 cars, 1 motorcycle, 260.2ms\n",
      "Speed: 7.1ms preprocess, 260.2ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 5 persons, 9 cars, 1 motorcycle, 251.2ms\n",
      "Speed: 18.9ms preprocess, 251.2ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 4 persons, 7 cars, 2 motorcycles, 565.5ms\n",
      "Speed: 7.6ms preprocess, 565.5ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 4 persons, 7 cars, 3 motorcycles, 277.0ms\n",
      "Speed: 4.8ms preprocess, 277.0ms inference, 2.9ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 5 persons, 6 cars, 4 motorcycles, 259.8ms\n",
      "Speed: 6.3ms preprocess, 259.8ms inference, 2.4ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 4 persons, 5 cars, 6 motorcycles, 264.5ms\n",
      "Speed: 5.4ms preprocess, 264.5ms inference, 2.4ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 4 persons, 6 cars, 6 motorcycles, 263.2ms\n",
      "Speed: 5.6ms preprocess, 263.2ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 5 persons, 5 cars, 4 motorcycles, 258.8ms\n",
      "Speed: 5.7ms preprocess, 258.8ms inference, 2.4ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 4 persons, 5 cars, 4 motorcycles, 275.1ms\n",
      "Speed: 6.6ms preprocess, 275.1ms inference, 3.1ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 4 persons, 5 cars, 5 motorcycles, 245.9ms\n",
      "Speed: 5.1ms preprocess, 245.9ms inference, 2.4ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 6 persons, 5 cars, 7 motorcycles, 255.4ms\n",
      "Speed: 5.9ms preprocess, 255.4ms inference, 2.8ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 5 persons, 7 cars, 6 motorcycles, 256.8ms\n",
      "Speed: 5.4ms preprocess, 256.8ms inference, 2.4ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 6 persons, 6 cars, 6 motorcycles, 258.6ms\n",
      "Speed: 5.3ms preprocess, 258.6ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 6 persons, 5 cars, 6 motorcycles, 257.3ms\n",
      "Speed: 5.6ms preprocess, 257.3ms inference, 2.4ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 5 persons, 6 cars, 5 motorcycles, 256.6ms\n",
      "Speed: 5.2ms preprocess, 256.6ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 4 persons, 4 cars, 6 motorcycles, 254.6ms\n",
      "Speed: 5.7ms preprocess, 254.6ms inference, 2.4ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 5 persons, 6 cars, 6 motorcycles, 257.7ms\n",
      "Speed: 6.2ms preprocess, 257.7ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 6 persons, 6 cars, 6 motorcycles, 256.0ms\n",
      "Speed: 5.5ms preprocess, 256.0ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 7 persons, 6 cars, 6 motorcycles, 256.7ms\n",
      "Speed: 6.4ms preprocess, 256.7ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 6 persons, 5 cars, 5 motorcycles, 258.1ms\n",
      "Speed: 5.1ms preprocess, 258.1ms inference, 3.1ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 6 persons, 4 cars, 5 motorcycles, 271.5ms\n",
      "Speed: 5.5ms preprocess, 271.5ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 6 persons, 4 cars, 6 motorcycles, 299.8ms\n",
      "Speed: 6.6ms preprocess, 299.8ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 6 persons, 4 cars, 5 motorcycles, 1 truck, 259.4ms\n",
      "Speed: 5.2ms preprocess, 259.4ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 5 persons, 5 cars, 5 motorcycles, 1 truck, 255.0ms\n",
      "Speed: 5.3ms preprocess, 255.0ms inference, 2.3ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 4 persons, 4 cars, 5 motorcycles, 1 truck, 259.3ms\n",
      "Speed: 6.2ms preprocess, 259.3ms inference, 2.8ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 5 persons, 7 cars, 6 motorcycles, 1 truck, 258.4ms\n",
      "Speed: 5.8ms preprocess, 258.4ms inference, 1.9ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 2 persons, 6 cars, 5 motorcycles, 1 truck, 261.2ms\n",
      "Speed: 6.5ms preprocess, 261.2ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 7 persons, 6 cars, 6 motorcycles, 266.2ms\n",
      "Speed: 5.5ms preprocess, 266.2ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 4 persons, 6 cars, 6 motorcycles, 1 truck, 271.4ms\n",
      "Speed: 5.3ms preprocess, 271.4ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 6 persons, 7 cars, 5 motorcycles, 259.1ms\n",
      "Speed: 5.0ms preprocess, 259.1ms inference, 2.4ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 6 persons, 7 cars, 9 motorcycles, 258.4ms\n",
      "Speed: 4.6ms preprocess, 258.4ms inference, 2.4ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 5 persons, 7 cars, 9 motorcycles, 254.7ms\n",
      "Speed: 5.7ms preprocess, 254.7ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 5 persons, 6 cars, 6 motorcycles, 255.6ms\n",
      "Speed: 6.2ms preprocess, 255.6ms inference, 1.5ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 5 persons, 8 cars, 7 motorcycles, 265.5ms\n",
      "Speed: 5.0ms preprocess, 265.5ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 5 persons, 7 cars, 6 motorcycles, 1 truck, 264.5ms\n",
      "Speed: 5.3ms preprocess, 264.5ms inference, 2.4ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 6 persons, 7 cars, 4 motorcycles, 535.7ms\n",
      "Speed: 5.4ms preprocess, 535.7ms inference, 2.8ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 5 persons, 7 cars, 5 motorcycles, 1 truck, 257.9ms\n",
      "Speed: 6.1ms preprocess, 257.9ms inference, 2.8ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 6 persons, 7 cars, 5 motorcycles, 1 truck, 261.2ms\n",
      "Speed: 7.1ms preprocess, 261.2ms inference, 3.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 6 persons, 7 cars, 5 motorcycles, 1 truck, 259.4ms\n",
      "Speed: 6.6ms preprocess, 259.4ms inference, 2.3ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 7 persons, 7 cars, 5 motorcycles, 1 truck, 287.0ms\n",
      "Speed: 7.1ms preprocess, 287.0ms inference, 2.4ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 7 persons, 7 cars, 4 motorcycles, 1 truck, 269.7ms\n",
      "Speed: 6.1ms preprocess, 269.7ms inference, 2.4ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 6 persons, 7 cars, 4 motorcycles, 1 truck, 300.6ms\n",
      "Speed: 5.7ms preprocess, 300.6ms inference, 3.3ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 7 persons, 8 cars, 3 motorcycles, 1 truck, 260.6ms\n",
      "Speed: 6.2ms preprocess, 260.6ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 7 persons, 7 cars, 3 motorcycles, 1 truck, 274.4ms\n",
      "Speed: 5.9ms preprocess, 274.4ms inference, 2.2ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 6 persons, 8 cars, 3 motorcycles, 2 trucks, 263.0ms\n",
      "Speed: 6.2ms preprocess, 263.0ms inference, 2.4ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 7 persons, 8 cars, 3 motorcycles, 2 trucks, 276.4ms\n",
      "Speed: 6.3ms preprocess, 276.4ms inference, 2.9ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 9 persons, 7 cars, 3 motorcycles, 2 trucks, 424.7ms\n",
      "Speed: 4.7ms preprocess, 424.7ms inference, 5.4ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 7 persons, 7 cars, 3 motorcycles, 2 trucks, 542.5ms\n",
      "Speed: 7.5ms preprocess, 542.5ms inference, 3.9ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 8 persons, 7 cars, 3 motorcycles, 2 trucks, 388.3ms\n",
      "Speed: 7.2ms preprocess, 388.3ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 10 persons, 8 cars, 3 motorcycles, 2 trucks, 311.3ms\n",
      "Speed: 7.5ms preprocess, 311.3ms inference, 3.6ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 10 persons, 9 cars, 3 motorcycles, 1 truck, 275.4ms\n",
      "Speed: 7.4ms preprocess, 275.4ms inference, 2.9ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 9 persons, 9 cars, 4 motorcycles, 1 truck, 1 traffic light, 298.5ms\n",
      "Speed: 7.0ms preprocess, 298.5ms inference, 2.9ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 9 persons, 8 cars, 4 motorcycles, 1 truck, 1 traffic light, 313.3ms\n",
      "Speed: 6.7ms preprocess, 313.3ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 9 persons, 7 cars, 4 motorcycles, 1 truck, 287.2ms\n",
      "Speed: 7.4ms preprocess, 287.2ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 9 persons, 8 cars, 4 motorcycles, 1 truck, 273.7ms\n",
      "Speed: 8.5ms preprocess, 273.7ms inference, 3.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 10 persons, 9 cars, 4 motorcycles, 1 truck, 286.7ms\n",
      "Speed: 9.9ms preprocess, 286.7ms inference, 2.9ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 10 persons, 9 cars, 4 motorcycles, 1 truck, 278.1ms\n",
      "Speed: 8.5ms preprocess, 278.1ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 11 persons, 8 cars, 4 motorcycles, 1 truck, 303.0ms\n",
      "Speed: 5.5ms preprocess, 303.0ms inference, 3.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 9 persons, 8 cars, 6 motorcycles, 457.9ms\n",
      "Speed: 5.6ms preprocess, 457.9ms inference, 5.1ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 11 persons, 7 cars, 4 motorcycles, 532.0ms\n",
      "Speed: 14.6ms preprocess, 532.0ms inference, 5.7ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 10 persons, 8 cars, 4 motorcycles, 1 traffic light, 385.7ms\n",
      "Speed: 8.9ms preprocess, 385.7ms inference, 3.9ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 11 persons, 8 cars, 4 motorcycles, 333.2ms\n",
      "Speed: 15.0ms preprocess, 333.2ms inference, 3.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 10 persons, 9 cars, 3 motorcycles, 645.6ms\n",
      "Speed: 6.1ms preprocess, 645.6ms inference, 3.2ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 10 persons, 8 cars, 4 motorcycles, 330.0ms\n",
      "Speed: 6.3ms preprocess, 330.0ms inference, 2.8ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 8 persons, 8 cars, 4 motorcycles, 275.5ms\n",
      "Speed: 6.7ms preprocess, 275.5ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 9 persons, 8 cars, 5 motorcycles, 312.9ms\n",
      "Speed: 6.0ms preprocess, 312.9ms inference, 2.9ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 8 persons, 1 bicycle, 8 cars, 4 motorcycles, 363.3ms\n",
      "Speed: 11.3ms preprocess, 363.3ms inference, 3.1ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 10 persons, 8 cars, 3 motorcycles, 271.7ms\n",
      "Speed: 6.9ms preprocess, 271.7ms inference, 3.1ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 10 persons, 8 cars, 4 motorcycles, 322.8ms\n",
      "Speed: 7.4ms preprocess, 322.8ms inference, 3.4ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 11 persons, 8 cars, 3 motorcycles, 380.8ms\n",
      "Speed: 13.1ms preprocess, 380.8ms inference, 2.9ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 9 persons, 8 cars, 3 motorcycles, 299.4ms\n",
      "Speed: 5.5ms preprocess, 299.4ms inference, 2.9ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 10 persons, 6 cars, 4 motorcycles, 289.5ms\n",
      "Speed: 5.6ms preprocess, 289.5ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 9 persons, 8 cars, 4 motorcycles, 312.3ms\n",
      "Speed: 6.1ms preprocess, 312.3ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 9 persons, 6 cars, 4 motorcycles, 274.5ms\n",
      "Speed: 5.9ms preprocess, 274.5ms inference, 2.9ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 9 persons, 5 cars, 5 motorcycles, 1 truck, 281.8ms\n",
      "Speed: 5.9ms preprocess, 281.8ms inference, 2.9ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 9 persons, 6 cars, 5 motorcycles, 290.8ms\n",
      "Speed: 6.4ms preprocess, 290.8ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 9 persons, 7 cars, 9 motorcycles, 1 truck, 272.2ms\n",
      "Speed: 5.0ms preprocess, 272.2ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 10 persons, 7 cars, 6 motorcycles, 1 truck, 273.0ms\n",
      "Speed: 5.5ms preprocess, 273.0ms inference, 2.8ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 10 persons, 7 cars, 6 motorcycles, 277.5ms\n",
      "Speed: 6.0ms preprocess, 277.5ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 11 persons, 7 cars, 5 motorcycles, 333.1ms\n",
      "Speed: 5.7ms preprocess, 333.1ms inference, 2.4ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 9 persons, 6 cars, 5 motorcycles, 1 truck, 300.9ms\n",
      "Speed: 5.8ms preprocess, 300.9ms inference, 2.9ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 8 persons, 7 cars, 6 motorcycles, 1 truck, 266.6ms\n",
      "Speed: 5.2ms preprocess, 266.6ms inference, 2.8ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 8 persons, 7 cars, 6 motorcycles, 273.7ms\n",
      "Speed: 4.9ms preprocess, 273.7ms inference, 3.4ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 8 persons, 7 cars, 7 motorcycles, 284.1ms\n",
      "Speed: 5.2ms preprocess, 284.1ms inference, 3.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 9 persons, 7 cars, 8 motorcycles, 1 truck, 258.6ms\n",
      "Speed: 5.1ms preprocess, 258.6ms inference, 2.9ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 8 persons, 7 cars, 8 motorcycles, 1 truck, 266.5ms\n",
      "Speed: 5.2ms preprocess, 266.5ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 9 persons, 6 cars, 9 motorcycles, 1 truck, 262.0ms\n",
      "Speed: 5.5ms preprocess, 262.0ms inference, 2.3ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 8 persons, 6 cars, 9 motorcycles, 277.5ms\n",
      "Speed: 5.6ms preprocess, 277.5ms inference, 2.9ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 8 persons, 8 cars, 8 motorcycles, 1 truck, 598.9ms\n",
      "Speed: 5.5ms preprocess, 598.9ms inference, 2.8ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 9 persons, 7 cars, 9 motorcycles, 279.0ms\n",
      "Speed: 5.6ms preprocess, 279.0ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 11 persons, 7 cars, 9 motorcycles, 261.5ms\n",
      "Speed: 4.6ms preprocess, 261.5ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 11 persons, 6 cars, 8 motorcycles, 1 truck, 276.3ms\n",
      "Speed: 5.0ms preprocess, 276.3ms inference, 3.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 12 persons, 5 cars, 9 motorcycles, 1 truck, 313.7ms\n",
      "Speed: 5.3ms preprocess, 313.7ms inference, 2.4ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 14 persons, 5 cars, 12 motorcycles, 1 truck, 278.5ms\n",
      "Speed: 9.1ms preprocess, 278.5ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 14 persons, 6 cars, 11 motorcycles, 1 truck, 336.9ms\n",
      "Speed: 5.8ms preprocess, 336.9ms inference, 2.9ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 12 persons, 4 cars, 10 motorcycles, 1 truck, 292.4ms\n",
      "Speed: 9.5ms preprocess, 292.4ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 11 persons, 5 cars, 12 motorcycles, 1 truck, 277.2ms\n",
      "Speed: 4.8ms preprocess, 277.2ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 13 persons, 5 cars, 10 motorcycles, 1 truck, 310.1ms\n",
      "Speed: 5.6ms preprocess, 310.1ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 14 persons, 5 cars, 10 motorcycles, 1 truck, 306.8ms\n",
      "Speed: 7.2ms preprocess, 306.8ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 12 persons, 4 cars, 10 motorcycles, 1 truck, 307.5ms\n",
      "Speed: 5.5ms preprocess, 307.5ms inference, 3.3ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 11 persons, 4 cars, 9 motorcycles, 324.5ms\n",
      "Speed: 6.8ms preprocess, 324.5ms inference, 3.4ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 10 persons, 4 cars, 9 motorcycles, 314.5ms\n",
      "Speed: 5.7ms preprocess, 314.5ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 8 persons, 5 cars, 9 motorcycles, 303.3ms\n",
      "Speed: 6.2ms preprocess, 303.3ms inference, 2.4ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 8 persons, 4 cars, 9 motorcycles, 286.6ms\n",
      "Speed: 6.1ms preprocess, 286.6ms inference, 3.2ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 8 persons, 4 cars, 10 motorcycles, 286.9ms\n",
      "Speed: 6.2ms preprocess, 286.9ms inference, 2.9ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 10 persons, 4 cars, 9 motorcycles, 1 truck, 278.1ms\n",
      "Speed: 5.8ms preprocess, 278.1ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 9 persons, 3 cars, 9 motorcycles, 1 truck, 271.6ms\n",
      "Speed: 5.2ms preprocess, 271.6ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 9 persons, 3 cars, 9 motorcycles, 1 truck, 270.4ms\n",
      "Speed: 4.7ms preprocess, 270.4ms inference, 3.1ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 11 persons, 3 cars, 9 motorcycles, 1 truck, 283.5ms\n",
      "Speed: 5.8ms preprocess, 283.5ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 10 persons, 3 cars, 9 motorcycles, 1 truck, 288.3ms\n",
      "Speed: 6.7ms preprocess, 288.3ms inference, 2.9ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 10 persons, 3 cars, 9 motorcycles, 1 truck, 288.7ms\n",
      "Speed: 5.9ms preprocess, 288.7ms inference, 3.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 11 persons, 2 cars, 9 motorcycles, 1 truck, 599.4ms\n",
      "Speed: 5.8ms preprocess, 599.4ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 11 persons, 4 cars, 10 motorcycles, 1 truck, 281.9ms\n",
      "Speed: 6.1ms preprocess, 281.9ms inference, 4.1ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 11 persons, 5 cars, 11 motorcycles, 1 truck, 260.1ms\n",
      "Speed: 5.4ms preprocess, 260.1ms inference, 3.3ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 9 persons, 4 cars, 10 motorcycles, 1 truck, 271.0ms\n",
      "Speed: 6.6ms preprocess, 271.0ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 11 persons, 5 cars, 10 motorcycles, 1 truck, 274.1ms\n",
      "Speed: 5.8ms preprocess, 274.1ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 12 persons, 4 cars, 9 motorcycles, 1 truck, 289.8ms\n",
      "Speed: 5.7ms preprocess, 289.8ms inference, 2.8ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 11 persons, 3 cars, 9 motorcycles, 1 truck, 275.8ms\n",
      "Speed: 4.4ms preprocess, 275.8ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 11 persons, 3 cars, 9 motorcycles, 1 truck, 264.1ms\n",
      "Speed: 6.3ms preprocess, 264.1ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 10 persons, 4 cars, 9 motorcycles, 1 truck, 270.0ms\n",
      "Speed: 6.6ms preprocess, 270.0ms inference, 2.8ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 11 persons, 4 cars, 11 motorcycles, 1 truck, 284.0ms\n",
      "Speed: 5.0ms preprocess, 284.0ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 10 persons, 4 cars, 10 motorcycles, 1 truck, 260.6ms\n",
      "Speed: 5.7ms preprocess, 260.6ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 10 persons, 4 cars, 12 motorcycles, 1 truck, 260.7ms\n",
      "Speed: 5.8ms preprocess, 260.7ms inference, 3.2ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 10 persons, 4 cars, 13 motorcycles, 1 truck, 252.7ms\n",
      "Speed: 6.4ms preprocess, 252.7ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 10 persons, 6 cars, 12 motorcycles, 1 truck, 269.0ms\n",
      "Speed: 5.0ms preprocess, 269.0ms inference, 2.8ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 10 persons, 6 cars, 13 motorcycles, 1 truck, 262.3ms\n",
      "Speed: 6.2ms preprocess, 262.3ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 10 persons, 5 cars, 12 motorcycles, 1 truck, 263.7ms\n",
      "Speed: 5.2ms preprocess, 263.7ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 10 persons, 5 cars, 13 motorcycles, 1 truck, 285.2ms\n",
      "Speed: 5.0ms preprocess, 285.2ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 10 persons, 5 cars, 13 motorcycles, 1 truck, 282.5ms\n",
      "Speed: 5.7ms preprocess, 282.5ms inference, 2.9ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 10 persons, 4 cars, 12 motorcycles, 1 truck, 346.1ms\n",
      "Speed: 6.2ms preprocess, 346.1ms inference, 3.1ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 10 persons, 4 cars, 15 motorcycles, 1 truck, 308.7ms\n",
      "Speed: 11.7ms preprocess, 308.7ms inference, 2.9ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 11 persons, 3 cars, 13 motorcycles, 1 truck, 319.1ms\n",
      "Speed: 6.7ms preprocess, 319.1ms inference, 2.4ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 10 persons, 3 cars, 14 motorcycles, 1 truck, 332.2ms\n",
      "Speed: 6.2ms preprocess, 332.2ms inference, 3.9ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 10 persons, 3 cars, 14 motorcycles, 1 truck, 318.6ms\n",
      "Speed: 7.4ms preprocess, 318.6ms inference, 4.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 8 persons, 3 cars, 14 motorcycles, 1 truck, 710.4ms\n",
      "Speed: 6.4ms preprocess, 710.4ms inference, 2.8ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 9 persons, 3 cars, 14 motorcycles, 1 truck, 347.5ms\n",
      "Speed: 5.4ms preprocess, 347.5ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 10 persons, 4 cars, 14 motorcycles, 1 truck, 337.6ms\n",
      "Speed: 6.9ms preprocess, 337.6ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 11 persons, 3 cars, 12 motorcycles, 2 trucks, 308.5ms\n",
      "Speed: 8.8ms preprocess, 308.5ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 10 persons, 5 cars, 13 motorcycles, 1 truck, 291.3ms\n",
      "Speed: 5.6ms preprocess, 291.3ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 11 persons, 5 cars, 14 motorcycles, 1 truck, 277.8ms\n",
      "Speed: 6.6ms preprocess, 277.8ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 9 persons, 5 cars, 10 motorcycles, 304.5ms\n",
      "Speed: 6.1ms preprocess, 304.5ms inference, 2.9ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 7 persons, 5 cars, 14 motorcycles, 354.3ms\n",
      "Speed: 6.0ms preprocess, 354.3ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 8 persons, 5 cars, 12 motorcycles, 296.5ms\n",
      "Speed: 7.8ms preprocess, 296.5ms inference, 2.8ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 8 persons, 6 cars, 13 motorcycles, 290.3ms\n",
      "Speed: 5.9ms preprocess, 290.3ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 8 persons, 4 cars, 11 motorcycles, 287.7ms\n",
      "Speed: 8.4ms preprocess, 287.7ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 7 persons, 5 cars, 11 motorcycles, 266.0ms\n",
      "Speed: 6.1ms preprocess, 266.0ms inference, 2.9ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 7 persons, 5 cars, 13 motorcycles, 290.5ms\n",
      "Speed: 6.1ms preprocess, 290.5ms inference, 2.9ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 7 persons, 5 cars, 10 motorcycles, 313.2ms\n",
      "Speed: 5.0ms preprocess, 313.2ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 7 persons, 5 cars, 11 motorcycles, 282.3ms\n",
      "Speed: 5.1ms preprocess, 282.3ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 7 persons, 3 cars, 10 motorcycles, 263.9ms\n",
      "Speed: 6.8ms preprocess, 263.9ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 9 persons, 3 cars, 10 motorcycles, 1 truck, 273.4ms\n",
      "Speed: 5.7ms preprocess, 273.4ms inference, 2.4ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 8 persons, 2 cars, 11 motorcycles, 1 truck, 275.3ms\n",
      "Speed: 6.1ms preprocess, 275.3ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 8 persons, 4 cars, 10 motorcycles, 1 truck, 254.1ms\n",
      "Speed: 5.7ms preprocess, 254.1ms inference, 3.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 8 persons, 4 cars, 12 motorcycles, 1 truck, 285.5ms\n",
      "Speed: 5.0ms preprocess, 285.5ms inference, 2.8ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 8 persons, 3 cars, 10 motorcycles, 1 truck, 295.6ms\n",
      "Speed: 5.0ms preprocess, 295.6ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 7 persons, 4 cars, 10 motorcycles, 1 truck, 567.1ms\n",
      "Speed: 6.3ms preprocess, 567.1ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 7 persons, 4 cars, 11 motorcycles, 1 truck, 295.7ms\n",
      "Speed: 5.9ms preprocess, 295.7ms inference, 2.8ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 7 persons, 3 cars, 13 motorcycles, 1 truck, 286.2ms\n",
      "Speed: 5.4ms preprocess, 286.2ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 7 persons, 3 cars, 12 motorcycles, 1 truck, 260.8ms\n",
      "Speed: 6.1ms preprocess, 260.8ms inference, 2.4ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 7 persons, 3 cars, 12 motorcycles, 1 truck, 281.2ms\n",
      "Speed: 5.0ms preprocess, 281.2ms inference, 2.2ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 4 persons, 3 cars, 11 motorcycles, 1 truck, 280.0ms\n",
      "Speed: 6.5ms preprocess, 280.0ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 5 persons, 4 cars, 12 motorcycles, 1 truck, 258.3ms\n",
      "Speed: 6.0ms preprocess, 258.3ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 5 persons, 4 cars, 11 motorcycles, 1 truck, 274.6ms\n",
      "Speed: 6.0ms preprocess, 274.6ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 6 persons, 5 cars, 12 motorcycles, 1 truck, 285.3ms\n",
      "Speed: 5.0ms preprocess, 285.3ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 6 persons, 4 cars, 11 motorcycles, 1 truck, 319.0ms\n",
      "Speed: 5.9ms preprocess, 319.0ms inference, 4.1ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 6 persons, 4 cars, 12 motorcycles, 1 truck, 269.7ms\n",
      "Speed: 5.5ms preprocess, 269.7ms inference, 3.1ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 6 persons, 5 cars, 12 motorcycles, 1 truck, 290.8ms\n",
      "Speed: 5.2ms preprocess, 290.8ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 6 persons, 6 cars, 10 motorcycles, 1 truck, 315.7ms\n",
      "Speed: 5.0ms preprocess, 315.7ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 6 persons, 3 cars, 10 motorcycles, 1 truck, 312.7ms\n",
      "Speed: 3.6ms preprocess, 312.7ms inference, 3.1ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 6 persons, 4 cars, 10 motorcycles, 1 truck, 272.7ms\n",
      "Speed: 5.7ms preprocess, 272.7ms inference, 2.2ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 5 persons, 5 cars, 7 motorcycles, 1 truck, 293.8ms\n",
      "Speed: 5.1ms preprocess, 293.8ms inference, 3.2ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 6 persons, 6 cars, 5 motorcycles, 1 truck, 300.0ms\n",
      "Speed: 5.7ms preprocess, 300.0ms inference, 2.4ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 5 persons, 6 cars, 5 motorcycles, 1 truck, 346.9ms\n",
      "Speed: 7.2ms preprocess, 346.9ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 6 persons, 7 cars, 7 motorcycles, 2 trucks, 269.9ms\n",
      "Speed: 5.8ms preprocess, 269.9ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 6 persons, 7 cars, 7 motorcycles, 1 bus, 2 trucks, 261.4ms\n",
      "Speed: 5.9ms preprocess, 261.4ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 5 persons, 7 cars, 6 motorcycles, 1 bus, 2 trucks, 474.9ms\n",
      "Speed: 5.2ms preprocess, 474.9ms inference, 2.4ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 4 persons, 7 cars, 8 motorcycles, 2 trucks, 338.9ms\n",
      "Speed: 5.3ms preprocess, 338.9ms inference, 2.3ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 4 persons, 7 cars, 6 motorcycles, 1 truck, 279.7ms\n",
      "Speed: 5.1ms preprocess, 279.7ms inference, 2.8ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 4 persons, 5 cars, 7 motorcycles, 2 trucks, 263.5ms\n",
      "Speed: 4.3ms preprocess, 263.5ms inference, 3.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 4 persons, 6 cars, 9 motorcycles, 1 truck, 266.8ms\n",
      "Speed: 5.8ms preprocess, 266.8ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 4 persons, 7 cars, 7 motorcycles, 1 truck, 284.3ms\n",
      "Speed: 5.4ms preprocess, 284.3ms inference, 2.8ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 5 persons, 7 cars, 9 motorcycles, 1 truck, 265.1ms\n",
      "Speed: 6.0ms preprocess, 265.1ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 6 persons, 6 cars, 9 motorcycles, 1 truck, 249.4ms\n",
      "Speed: 4.7ms preprocess, 249.4ms inference, 2.4ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 6 persons, 6 cars, 10 motorcycles, 1 truck, 274.0ms\n",
      "Speed: 5.0ms preprocess, 274.0ms inference, 3.1ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 8 persons, 7 cars, 9 motorcycles, 2 trucks, 252.5ms\n",
      "Speed: 10.0ms preprocess, 252.5ms inference, 2.9ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 11 persons, 6 cars, 9 motorcycles, 2 trucks, 287.2ms\n",
      "Speed: 5.3ms preprocess, 287.2ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 11 persons, 6 cars, 8 motorcycles, 2 trucks, 282.4ms\n",
      "Speed: 4.6ms preprocess, 282.4ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 10 persons, 6 cars, 8 motorcycles, 2 trucks, 299.8ms\n",
      "Speed: 5.9ms preprocess, 299.8ms inference, 3.3ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 11 persons, 6 cars, 11 motorcycles, 2 trucks, 1 backpack, 262.2ms\n",
      "Speed: 4.7ms preprocess, 262.2ms inference, 2.8ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 11 persons, 6 cars, 10 motorcycles, 2 trucks, 2 backpacks, 264.2ms\n",
      "Speed: 5.4ms preprocess, 264.2ms inference, 2.4ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 9 persons, 6 cars, 6 motorcycles, 2 trucks, 276.7ms\n",
      "Speed: 5.1ms preprocess, 276.7ms inference, 2.8ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 8 persons, 6 cars, 10 motorcycles, 2 trucks, 268.3ms\n",
      "Speed: 5.1ms preprocess, 268.3ms inference, 2.9ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 10 persons, 6 cars, 6 motorcycles, 1 truck, 1 backpack, 287.8ms\n",
      "Speed: 6.8ms preprocess, 287.8ms inference, 3.3ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 10 persons, 7 cars, 6 motorcycles, 1 truck, 278.4ms\n",
      "Speed: 5.5ms preprocess, 278.4ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 8 persons, 5 cars, 4 motorcycles, 1 truck, 1 backpack, 553.7ms\n",
      "Speed: 5.3ms preprocess, 553.7ms inference, 2.8ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 8 persons, 5 cars, 4 motorcycles, 1 truck, 1 backpack, 285.1ms\n",
      "Speed: 5.6ms preprocess, 285.1ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 8 persons, 7 cars, 4 motorcycles, 1 truck, 260.9ms\n",
      "Speed: 6.1ms preprocess, 260.9ms inference, 2.9ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 8 persons, 7 cars, 3 motorcycles, 1 truck, 299.9ms\n",
      "Speed: 6.2ms preprocess, 299.9ms inference, 2.4ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 8 persons, 7 cars, 3 motorcycles, 1 truck, 289.9ms\n",
      "Speed: 4.3ms preprocess, 289.9ms inference, 2.8ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 9 persons, 7 cars, 4 motorcycles, 1 truck, 266.1ms\n",
      "Speed: 4.7ms preprocess, 266.1ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 9 persons, 7 cars, 5 motorcycles, 1 truck, 313.1ms\n",
      "Speed: 5.3ms preprocess, 313.1ms inference, 3.1ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 10 persons, 7 cars, 6 motorcycles, 2 trucks, 293.8ms\n",
      "Speed: 5.4ms preprocess, 293.8ms inference, 2.8ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 11 persons, 8 cars, 6 motorcycles, 2 trucks, 303.4ms\n",
      "Speed: 7.4ms preprocess, 303.4ms inference, 3.2ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 11 persons, 9 cars, 6 motorcycles, 2 trucks, 330.1ms\n",
      "Speed: 5.3ms preprocess, 330.1ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 9 persons, 10 cars, 5 motorcycles, 1 truck, 284.4ms\n",
      "Speed: 4.3ms preprocess, 284.4ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 10 persons, 9 cars, 6 motorcycles, 2 trucks, 259.3ms\n",
      "Speed: 6.8ms preprocess, 259.3ms inference, 2.4ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 9 persons, 8 cars, 8 motorcycles, 2 trucks, 268.3ms\n",
      "Speed: 5.0ms preprocess, 268.3ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 10 persons, 9 cars, 4 motorcycles, 1 truck, 287.0ms\n",
      "Speed: 5.6ms preprocess, 287.0ms inference, 3.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 12 persons, 9 cars, 4 motorcycles, 2 trucks, 309.0ms\n",
      "Speed: 7.0ms preprocess, 309.0ms inference, 3.3ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 11 persons, 6 cars, 4 motorcycles, 2 trucks, 1 backpack, 262.3ms\n",
      "Speed: 5.0ms preprocess, 262.3ms inference, 2.8ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 12 persons, 6 cars, 4 motorcycles, 2 trucks, 296.8ms\n",
      "Speed: 9.1ms preprocess, 296.8ms inference, 2.9ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 12 persons, 7 cars, 6 motorcycles, 1 truck, 273.8ms\n",
      "Speed: 5.9ms preprocess, 273.8ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 11 persons, 7 cars, 7 motorcycles, 1 truck, 1 backpack, 527.9ms\n",
      "Speed: 5.1ms preprocess, 527.9ms inference, 3.7ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 13 persons, 7 cars, 7 motorcycles, 1 truck, 1 backpack, 301.8ms\n",
      "Speed: 5.6ms preprocess, 301.8ms inference, 2.9ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 12 persons, 7 cars, 6 motorcycles, 1 truck, 1 backpack, 278.0ms\n",
      "Speed: 5.1ms preprocess, 278.0ms inference, 2.8ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 11 persons, 7 cars, 6 motorcycles, 1 truck, 1 backpack, 307.4ms\n",
      "Speed: 5.3ms preprocess, 307.4ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 11 persons, 7 cars, 5 motorcycles, 1 truck, 1 backpack, 263.1ms\n",
      "Speed: 12.0ms preprocess, 263.1ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 11 persons, 7 cars, 6 motorcycles, 1 truck, 1 backpack, 273.9ms\n",
      "Speed: 4.9ms preprocess, 273.9ms inference, 2.3ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 11 persons, 7 cars, 7 motorcycles, 1 truck, 1 backpack, 281.8ms\n",
      "Speed: 5.3ms preprocess, 281.8ms inference, 2.8ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 12 persons, 7 cars, 6 motorcycles, 1 truck, 2 backpacks, 271.3ms\n",
      "Speed: 5.9ms preprocess, 271.3ms inference, 2.9ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 12 persons, 7 cars, 6 motorcycles, 1 truck, 1 backpack, 292.5ms\n",
      "Speed: 4.7ms preprocess, 292.5ms inference, 3.5ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 12 persons, 7 cars, 5 motorcycles, 2 trucks, 1 backpack, 1 handbag, 270.5ms\n",
      "Speed: 5.2ms preprocess, 270.5ms inference, 2.8ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 11 persons, 7 cars, 5 motorcycles, 2 trucks, 1 handbag, 277.1ms\n",
      "Speed: 5.8ms preprocess, 277.1ms inference, 2.9ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 10 persons, 6 cars, 6 motorcycles, 3 trucks, 1 handbag, 279.5ms\n",
      "Speed: 4.5ms preprocess, 279.5ms inference, 3.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 10 persons, 6 cars, 8 motorcycles, 2 trucks, 264.2ms\n",
      "Speed: 5.1ms preprocess, 264.2ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 10 persons, 6 cars, 5 motorcycles, 2 trucks, 284.6ms\n",
      "Speed: 5.8ms preprocess, 284.6ms inference, 3.1ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 11 persons, 6 cars, 6 motorcycles, 2 trucks, 273.6ms\n",
      "Speed: 6.2ms preprocess, 273.6ms inference, 2.8ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 11 persons, 6 cars, 5 motorcycles, 2 trucks, 276.5ms\n",
      "Speed: 6.1ms preprocess, 276.5ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 11 persons, 7 cars, 5 motorcycles, 2 trucks, 285.1ms\n",
      "Speed: 5.4ms preprocess, 285.1ms inference, 3.6ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 9 persons, 6 cars, 5 motorcycles, 2 trucks, 534.1ms\n",
      "Speed: 6.5ms preprocess, 534.1ms inference, 3.6ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 9 persons, 6 cars, 5 motorcycles, 3 trucks, 283.4ms\n",
      "Speed: 4.2ms preprocess, 283.4ms inference, 3.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 9 persons, 4 cars, 5 motorcycles, 2 trucks, 263.4ms\n",
      "Speed: 4.9ms preprocess, 263.4ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 11 persons, 4 cars, 5 motorcycles, 2 trucks, 290.7ms\n",
      "Speed: 6.6ms preprocess, 290.7ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 9 persons, 4 cars, 6 motorcycles, 2 trucks, 293.0ms\n",
      "Speed: 8.2ms preprocess, 293.0ms inference, 2.9ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 9 persons, 4 cars, 5 motorcycles, 3 trucks, 327.6ms\n",
      "Speed: 5.7ms preprocess, 327.6ms inference, 2.4ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 9 persons, 4 cars, 5 motorcycles, 2 trucks, 287.2ms\n",
      "Speed: 5.0ms preprocess, 287.2ms inference, 3.1ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 11 persons, 4 cars, 5 motorcycles, 2 trucks, 287.4ms\n",
      "Speed: 5.6ms preprocess, 287.4ms inference, 3.6ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 9 persons, 4 cars, 5 motorcycles, 2 trucks, 294.2ms\n",
      "Speed: 5.8ms preprocess, 294.2ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 9 persons, 4 cars, 6 motorcycles, 3 trucks, 273.2ms\n",
      "Speed: 6.6ms preprocess, 273.2ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 9 persons, 4 cars, 6 motorcycles, 2 trucks, 265.8ms\n",
      "Speed: 5.9ms preprocess, 265.8ms inference, 2.8ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 9 persons, 5 cars, 5 motorcycles, 3 trucks, 296.2ms\n",
      "Speed: 5.5ms preprocess, 296.2ms inference, 2.8ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 9 persons, 4 cars, 6 motorcycles, 2 trucks, 264.7ms\n",
      "Speed: 4.8ms preprocess, 264.7ms inference, 2.4ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 9 persons, 4 cars, 6 motorcycles, 1 truck, 271.3ms\n",
      "Speed: 5.3ms preprocess, 271.3ms inference, 3.4ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 11 persons, 4 cars, 6 motorcycles, 2 trucks, 254.8ms\n",
      "Speed: 6.3ms preprocess, 254.8ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 9 persons, 4 cars, 7 motorcycles, 1 truck, 286.9ms\n",
      "Speed: 6.5ms preprocess, 286.9ms inference, 2.8ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 9 persons, 4 cars, 7 motorcycles, 1 truck, 619.8ms\n",
      "Speed: 7.3ms preprocess, 619.8ms inference, 3.2ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 9 persons, 4 cars, 6 motorcycles, 1 truck, 331.6ms\n",
      "Speed: 5.2ms preprocess, 331.6ms inference, 3.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 10 persons, 5 cars, 6 motorcycles, 1 truck, 296.9ms\n",
      "Speed: 13.6ms preprocess, 296.9ms inference, 2.8ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 10 persons, 4 cars, 5 motorcycles, 1 truck, 287.9ms\n",
      "Speed: 9.5ms preprocess, 287.9ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 9 persons, 4 cars, 5 motorcycles, 1 truck, 302.8ms\n",
      "Speed: 6.1ms preprocess, 302.8ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 9 persons, 4 cars, 8 motorcycles, 1 truck, 333.9ms\n",
      "Speed: 6.3ms preprocess, 333.9ms inference, 3.2ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 9 persons, 3 cars, 8 motorcycles, 2 trucks, 318.3ms\n",
      "Speed: 4.9ms preprocess, 318.3ms inference, 2.8ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 9 persons, 4 cars, 8 motorcycles, 2 trucks, 1 traffic light, 296.4ms\n",
      "Speed: 9.9ms preprocess, 296.4ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 8 persons, 3 cars, 10 motorcycles, 1 truck, 1 traffic light, 282.0ms\n",
      "Speed: 4.5ms preprocess, 282.0ms inference, 2.9ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 9 persons, 3 cars, 10 motorcycles, 1 truck, 1 traffic light, 274.8ms\n",
      "Speed: 7.9ms preprocess, 274.8ms inference, 2.2ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 10 persons, 3 cars, 11 motorcycles, 1 truck, 260.7ms\n",
      "Speed: 4.5ms preprocess, 260.7ms inference, 3.2ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 10 persons, 3 cars, 11 motorcycles, 1 truck, 263.1ms\n",
      "Speed: 5.8ms preprocess, 263.1ms inference, 2.9ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 7 persons, 1 bicycle, 4 cars, 9 motorcycles, 2 trucks, 325.0ms\n",
      "Speed: 5.0ms preprocess, 325.0ms inference, 3.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 9 persons, 4 cars, 8 motorcycles, 1 truck, 310.8ms\n",
      "Speed: 4.8ms preprocess, 310.8ms inference, 2.9ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 10 persons, 4 cars, 8 motorcycles, 1 truck, 297.6ms\n",
      "Speed: 5.6ms preprocess, 297.6ms inference, 2.8ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 11 persons, 5 cars, 9 motorcycles, 1 truck, 296.8ms\n",
      "Speed: 5.8ms preprocess, 296.8ms inference, 2.8ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 10 persons, 5 cars, 9 motorcycles, 1 truck, 295.8ms\n",
      "Speed: 4.5ms preprocess, 295.8ms inference, 3.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 10 persons, 4 cars, 9 motorcycles, 1 truck, 305.9ms\n",
      "Speed: 6.7ms preprocess, 305.9ms inference, 3.3ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 11 persons, 5 cars, 9 motorcycles, 1 truck, 536.8ms\n",
      "Speed: 4.5ms preprocess, 536.8ms inference, 2.1ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 9 persons, 5 cars, 9 motorcycles, 1 truck, 429.0ms\n",
      "Speed: 12.8ms preprocess, 429.0ms inference, 2.9ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 11 persons, 6 cars, 9 motorcycles, 1 truck, 307.2ms\n",
      "Speed: 6.2ms preprocess, 307.2ms inference, 3.2ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 11 persons, 6 cars, 10 motorcycles, 1 truck, 281.7ms\n",
      "Speed: 4.4ms preprocess, 281.7ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 12 persons, 4 cars, 12 motorcycles, 1 truck, 316.6ms\n",
      "Speed: 5.2ms preprocess, 316.6ms inference, 3.1ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 11 persons, 4 cars, 11 motorcycles, 1 truck, 323.5ms\n",
      "Speed: 6.6ms preprocess, 323.5ms inference, 3.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 11 persons, 4 cars, 10 motorcycles, 1 truck, 309.5ms\n",
      "Speed: 7.9ms preprocess, 309.5ms inference, 3.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 11 persons, 4 cars, 9 motorcycles, 2 trucks, 341.6ms\n",
      "Speed: 7.3ms preprocess, 341.6ms inference, 3.5ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 11 persons, 5 cars, 9 motorcycles, 1 truck, 293.6ms\n",
      "Speed: 5.2ms preprocess, 293.6ms inference, 3.5ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 10 persons, 5 cars, 9 motorcycles, 1 truck, 265.0ms\n",
      "Speed: 5.3ms preprocess, 265.0ms inference, 3.2ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 10 persons, 5 cars, 9 motorcycles, 1 truck, 345.2ms\n",
      "Speed: 6.0ms preprocess, 345.2ms inference, 3.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 11 persons, 4 cars, 10 motorcycles, 1 truck, 286.5ms\n",
      "Speed: 6.3ms preprocess, 286.5ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 10 persons, 4 cars, 9 motorcycles, 1 truck, 298.8ms\n",
      "Speed: 5.6ms preprocess, 298.8ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 11 persons, 4 cars, 9 motorcycles, 1 truck, 288.0ms\n",
      "Speed: 5.4ms preprocess, 288.0ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 11 persons, 4 cars, 9 motorcycles, 1 truck, 292.8ms\n",
      "Speed: 7.5ms preprocess, 292.8ms inference, 3.2ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 12 persons, 3 cars, 8 motorcycles, 1 truck, 510.4ms\n",
      "Speed: 6.6ms preprocess, 510.4ms inference, 3.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 12 persons, 2 cars, 8 motorcycles, 1 truck, 363.6ms\n",
      "Speed: 5.7ms preprocess, 363.6ms inference, 2.9ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 13 persons, 3 cars, 8 motorcycles, 1 truck, 295.4ms\n",
      "Speed: 5.2ms preprocess, 295.4ms inference, 2.9ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 12 persons, 3 cars, 8 motorcycles, 1 truck, 290.2ms\n",
      "Speed: 6.8ms preprocess, 290.2ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 11 persons, 4 cars, 7 motorcycles, 1 truck, 299.0ms\n",
      "Speed: 5.6ms preprocess, 299.0ms inference, 3.1ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 10 persons, 4 cars, 7 motorcycles, 1 truck, 284.6ms\n",
      "Speed: 7.1ms preprocess, 284.6ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 9 persons, 4 cars, 7 motorcycles, 1 truck, 270.6ms\n",
      "Speed: 5.5ms preprocess, 270.6ms inference, 3.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 8 persons, 4 cars, 8 motorcycles, 2 trucks, 297.3ms\n",
      "Speed: 6.3ms preprocess, 297.3ms inference, 2.9ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 9 persons, 5 cars, 8 motorcycles, 1 truck, 267.2ms\n",
      "Speed: 6.3ms preprocess, 267.2ms inference, 3.1ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 9 persons, 5 cars, 8 motorcycles, 2 trucks, 330.3ms\n",
      "Speed: 9.3ms preprocess, 330.3ms inference, 2.8ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 9 persons, 5 cars, 8 motorcycles, 1 truck, 282.0ms\n",
      "Speed: 5.1ms preprocess, 282.0ms inference, 2.4ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 9 persons, 4 cars, 10 motorcycles, 1 truck, 279.7ms\n",
      "Speed: 5.3ms preprocess, 279.7ms inference, 2.8ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 10 persons, 4 cars, 10 motorcycles, 1 truck, 269.7ms\n",
      "Speed: 5.7ms preprocess, 269.7ms inference, 2.9ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 8 persons, 4 cars, 9 motorcycles, 287.8ms\n",
      "Speed: 5.4ms preprocess, 287.8ms inference, 2.9ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 6 persons, 4 cars, 9 motorcycles, 261.1ms\n",
      "Speed: 4.7ms preprocess, 261.1ms inference, 2.8ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 7 persons, 4 cars, 9 motorcycles, 296.8ms\n",
      "Speed: 5.4ms preprocess, 296.8ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 7 persons, 4 cars, 10 motorcycles, 503.5ms\n",
      "Speed: 105.7ms preprocess, 503.5ms inference, 3.9ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 7 persons, 4 cars, 9 motorcycles, 295.0ms\n",
      "Speed: 5.5ms preprocess, 295.0ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 7 persons, 4 cars, 9 motorcycles, 287.5ms\n",
      "Speed: 4.9ms preprocess, 287.5ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 7 persons, 4 cars, 9 motorcycles, 273.2ms\n",
      "Speed: 5.2ms preprocess, 273.2ms inference, 2.4ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 8 persons, 5 cars, 9 motorcycles, 292.2ms\n",
      "Speed: 5.6ms preprocess, 292.2ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 9 persons, 5 cars, 8 motorcycles, 315.6ms\n",
      "Speed: 5.2ms preprocess, 315.6ms inference, 2.9ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 8 persons, 4 cars, 8 motorcycles, 295.8ms\n",
      "Speed: 5.6ms preprocess, 295.8ms inference, 2.8ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 6 persons, 5 cars, 7 motorcycles, 272.9ms\n",
      "Speed: 7.2ms preprocess, 272.9ms inference, 2.8ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 8 persons, 5 cars, 6 motorcycles, 1 truck, 297.0ms\n",
      "Speed: 5.6ms preprocess, 297.0ms inference, 2.8ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 5 persons, 4 cars, 6 motorcycles, 1 truck, 273.7ms\n",
      "Speed: 6.4ms preprocess, 273.7ms inference, 2.8ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 5 persons, 5 cars, 7 motorcycles, 294.6ms\n",
      "Speed: 6.4ms preprocess, 294.6ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 5 persons, 5 cars, 7 motorcycles, 267.8ms\n",
      "Speed: 4.9ms preprocess, 267.8ms inference, 3.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 7 persons, 6 cars, 8 motorcycles, 284.8ms\n",
      "Speed: 5.9ms preprocess, 284.8ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 6 persons, 6 cars, 8 motorcycles, 279.1ms\n",
      "Speed: 5.0ms preprocess, 279.1ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 5 persons, 6 cars, 8 motorcycles, 590.6ms\n",
      "Speed: 5.1ms preprocess, 590.6ms inference, 2.8ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 6 persons, 7 cars, 8 motorcycles, 319.6ms\n",
      "Speed: 5.7ms preprocess, 319.6ms inference, 3.6ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 6 persons, 7 cars, 8 motorcycles, 305.7ms\n",
      "Speed: 5.1ms preprocess, 305.7ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 6 persons, 6 cars, 9 motorcycles, 343.3ms\n",
      "Speed: 6.8ms preprocess, 343.3ms inference, 2.3ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 5 persons, 6 cars, 8 motorcycles, 307.2ms\n",
      "Speed: 5.4ms preprocess, 307.2ms inference, 2.4ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 5 persons, 6 cars, 8 motorcycles, 251.4ms\n",
      "Speed: 4.7ms preprocess, 251.4ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 5 persons, 6 cars, 7 motorcycles, 272.1ms\n",
      "Speed: 7.1ms preprocess, 272.1ms inference, 3.2ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 5 persons, 6 cars, 8 motorcycles, 295.1ms\n",
      "Speed: 5.4ms preprocess, 295.1ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 6 persons, 7 cars, 8 motorcycles, 282.7ms\n",
      "Speed: 4.3ms preprocess, 282.7ms inference, 3.3ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 7 persons, 6 cars, 8 motorcycles, 315.0ms\n",
      "Speed: 4.6ms preprocess, 315.0ms inference, 3.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 6 persons, 6 cars, 7 motorcycles, 293.5ms\n",
      "Speed: 5.3ms preprocess, 293.5ms inference, 3.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 5 persons, 5 cars, 6 motorcycles, 1 truck, 276.6ms\n",
      "Speed: 5.4ms preprocess, 276.6ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 5 persons, 6 cars, 7 motorcycles, 282.9ms\n",
      "Speed: 5.3ms preprocess, 282.9ms inference, 3.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 5 persons, 7 cars, 8 motorcycles, 287.7ms\n",
      "Speed: 6.0ms preprocess, 287.7ms inference, 2.9ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 5 persons, 6 cars, 8 motorcycles, 287.1ms\n",
      "Speed: 6.5ms preprocess, 287.1ms inference, 3.1ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 5 persons, 6 cars, 8 motorcycles, 498.3ms\n",
      "Speed: 6.0ms preprocess, 498.3ms inference, 4.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 7 persons, 6 cars, 8 motorcycles, 373.3ms\n",
      "Speed: 4.9ms preprocess, 373.3ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 7 persons, 7 cars, 9 motorcycles, 1 truck, 288.0ms\n",
      "Speed: 6.4ms preprocess, 288.0ms inference, 3.3ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 6 persons, 10 cars, 9 motorcycles, 1 truck, 287.2ms\n",
      "Speed: 5.8ms preprocess, 287.2ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 6 persons, 8 cars, 10 motorcycles, 1 truck, 280.7ms\n",
      "Speed: 5.9ms preprocess, 280.7ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 6 persons, 8 cars, 10 motorcycles, 1 truck, 370.6ms\n",
      "Speed: 8.0ms preprocess, 370.6ms inference, 3.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 6 persons, 9 cars, 9 motorcycles, 1 truck, 360.6ms\n",
      "Speed: 17.5ms preprocess, 360.6ms inference, 3.3ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 6 persons, 9 cars, 11 motorcycles, 1 truck, 340.8ms\n",
      "Speed: 5.2ms preprocess, 340.8ms inference, 2.8ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 6 persons, 7 cars, 10 motorcycles, 1 truck, 294.2ms\n",
      "Speed: 5.3ms preprocess, 294.2ms inference, 2.8ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 7 persons, 8 cars, 9 motorcycles, 1 truck, 286.3ms\n",
      "Speed: 6.4ms preprocess, 286.3ms inference, 2.4ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 7 persons, 8 cars, 8 motorcycles, 1 truck, 270.1ms\n",
      "Speed: 5.3ms preprocess, 270.1ms inference, 3.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 6 persons, 9 cars, 9 motorcycles, 292.6ms\n",
      "Speed: 4.4ms preprocess, 292.6ms inference, 2.9ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 6 persons, 9 cars, 9 motorcycles, 332.0ms\n",
      "Speed: 11.1ms preprocess, 332.0ms inference, 2.8ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 5 persons, 10 cars, 9 motorcycles, 338.1ms\n",
      "Speed: 6.1ms preprocess, 338.1ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 5 persons, 10 cars, 9 motorcycles, 1 truck, 344.4ms\n",
      "Speed: 11.6ms preprocess, 344.4ms inference, 2.8ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 5 persons, 8 cars, 8 motorcycles, 1 truck, 633.3ms\n",
      "Speed: 109.1ms preprocess, 633.3ms inference, 3.3ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 5 persons, 7 cars, 7 motorcycles, 1 truck, 495.4ms\n",
      "Speed: 19.9ms preprocess, 495.4ms inference, 3.5ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 5 persons, 8 cars, 7 motorcycles, 1 truck, 419.1ms\n",
      "Speed: 11.7ms preprocess, 419.1ms inference, 3.1ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 6 persons, 8 cars, 8 motorcycles, 1 truck, 342.0ms\n",
      "Speed: 5.9ms preprocess, 342.0ms inference, 2.8ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 6 persons, 7 cars, 8 motorcycles, 1 truck, 271.9ms\n",
      "Speed: 5.9ms preprocess, 271.9ms inference, 2.8ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 7 persons, 8 cars, 7 motorcycles, 1 truck, 294.9ms\n",
      "Speed: 4.9ms preprocess, 294.9ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 6 persons, 8 cars, 9 motorcycles, 1 truck, 378.5ms\n",
      "Speed: 6.1ms preprocess, 378.5ms inference, 3.1ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 5 persons, 8 cars, 9 motorcycles, 1 truck, 297.0ms\n",
      "Speed: 6.2ms preprocess, 297.0ms inference, 3.5ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 5 persons, 8 cars, 8 motorcycles, 2 trucks, 268.6ms\n",
      "Speed: 6.2ms preprocess, 268.6ms inference, 3.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 6 persons, 8 cars, 7 motorcycles, 2 trucks, 278.6ms\n",
      "Speed: 5.1ms preprocess, 278.6ms inference, 2.4ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 6 persons, 8 cars, 4 motorcycles, 2 trucks, 280.9ms\n",
      "Speed: 6.9ms preprocess, 280.9ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 7 persons, 9 cars, 4 motorcycles, 1 truck, 313.1ms\n",
      "Speed: 7.7ms preprocess, 313.1ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 8 persons, 7 cars, 4 motorcycles, 2 trucks, 299.2ms\n",
      "Speed: 6.2ms preprocess, 299.2ms inference, 3.1ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 7 persons, 8 cars, 3 motorcycles, 1 truck, 285.2ms\n",
      "Speed: 6.2ms preprocess, 285.2ms inference, 2.9ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 7 persons, 7 cars, 3 motorcycles, 1 truck, 271.0ms\n",
      "Speed: 4.8ms preprocess, 271.0ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 6 persons, 7 cars, 3 motorcycles, 1 truck, 528.7ms\n",
      "Speed: 5.1ms preprocess, 528.7ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 5 persons, 8 cars, 3 motorcycles, 1 truck, 323.7ms\n",
      "Speed: 6.1ms preprocess, 323.7ms inference, 2.8ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 5 persons, 9 cars, 3 motorcycles, 1 truck, 285.2ms\n",
      "Speed: 6.8ms preprocess, 285.2ms inference, 2.9ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 5 persons, 7 cars, 3 motorcycles, 2 trucks, 312.2ms\n",
      "Speed: 5.2ms preprocess, 312.2ms inference, 3.1ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 5 persons, 6 cars, 3 motorcycles, 1 truck, 474.8ms\n",
      "Speed: 6.4ms preprocess, 474.8ms inference, 3.5ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 5 persons, 7 cars, 3 motorcycles, 1 truck, 614.5ms\n",
      "Speed: 5.8ms preprocess, 614.5ms inference, 5.6ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 5 persons, 7 cars, 3 motorcycles, 1 truck, 379.0ms\n",
      "Speed: 5.3ms preprocess, 379.0ms inference, 2.9ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 6 persons, 7 cars, 3 motorcycles, 2 trucks, 361.3ms\n",
      "Speed: 6.7ms preprocess, 361.3ms inference, 3.6ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 5 persons, 7 cars, 3 motorcycles, 2 trucks, 291.0ms\n",
      "Speed: 5.6ms preprocess, 291.0ms inference, 2.4ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 6 persons, 8 cars, 2 motorcycles, 2 trucks, 281.8ms\n",
      "Speed: 9.1ms preprocess, 281.8ms inference, 3.5ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 6 persons, 9 cars, 2 motorcycles, 2 trucks, 290.4ms\n",
      "Speed: 7.5ms preprocess, 290.4ms inference, 3.2ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 7 persons, 7 cars, 2 motorcycles, 2 trucks, 516.6ms\n",
      "Speed: 5.5ms preprocess, 516.6ms inference, 3.5ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 7 persons, 6 cars, 2 motorcycles, 2 trucks, 326.4ms\n",
      "Speed: 8.0ms preprocess, 326.4ms inference, 3.1ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 7 persons, 6 cars, 2 motorcycles, 2 trucks, 293.2ms\n",
      "Speed: 6.4ms preprocess, 293.2ms inference, 3.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 7 persons, 6 cars, 2 motorcycles, 2 trucks, 282.2ms\n",
      "Speed: 5.5ms preprocess, 282.2ms inference, 2.9ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 5 persons, 7 cars, 2 motorcycles, 1 truck, 275.4ms\n",
      "Speed: 7.0ms preprocess, 275.4ms inference, 2.9ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 4 persons, 7 cars, 2 motorcycles, 1 truck, 276.6ms\n",
      "Speed: 5.7ms preprocess, 276.6ms inference, 3.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 6 persons, 7 cars, 2 motorcycles, 1 truck, 302.0ms\n",
      "Speed: 7.0ms preprocess, 302.0ms inference, 2.8ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 6 persons, 7 cars, 1 motorcycle, 1 truck, 301.3ms\n",
      "Speed: 6.3ms preprocess, 301.3ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 6 persons, 9 cars, 1 truck, 417.3ms\n",
      "Speed: 6.1ms preprocess, 417.3ms inference, 3.8ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 6 persons, 10 cars, 2 motorcycles, 1 truck, 352.0ms\n",
      "Speed: 5.7ms preprocess, 352.0ms inference, 3.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 5 persons, 10 cars, 3 motorcycles, 1 truck, 810.9ms\n",
      "Speed: 5.7ms preprocess, 810.9ms inference, 5.4ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 5 persons, 11 cars, 3 motorcycles, 431.0ms\n",
      "Speed: 7.0ms preprocess, 431.0ms inference, 6.2ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 6 persons, 10 cars, 3 motorcycles, 373.1ms\n",
      "Speed: 6.4ms preprocess, 373.1ms inference, 2.8ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 8 persons, 9 cars, 2 motorcycles, 456.9ms\n",
      "Speed: 8.7ms preprocess, 456.9ms inference, 3.3ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 9 persons, 10 cars, 4 motorcycles, 406.9ms\n",
      "Speed: 7.5ms preprocess, 406.9ms inference, 3.3ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 6 persons, 9 cars, 4 motorcycles, 391.1ms\n",
      "Speed: 7.5ms preprocess, 391.1ms inference, 3.3ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 5 persons, 10 cars, 6 motorcycles, 1 truck, 381.2ms\n",
      "Speed: 7.7ms preprocess, 381.2ms inference, 3.1ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 5 persons, 9 cars, 5 motorcycles, 1 truck, 345.5ms\n",
      "Speed: 6.8ms preprocess, 345.5ms inference, 2.8ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 5 persons, 9 cars, 5 motorcycles, 1 truck, 322.5ms\n",
      "Speed: 6.0ms preprocess, 322.5ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 5 persons, 8 cars, 4 motorcycles, 1 truck, 304.7ms\n",
      "Speed: 8.9ms preprocess, 304.7ms inference, 2.8ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 6 persons, 8 cars, 4 motorcycles, 1 truck, 374.9ms\n",
      "Speed: 6.3ms preprocess, 374.9ms inference, 3.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 8 persons, 8 cars, 5 motorcycles, 1 truck, 518.5ms\n",
      "Speed: 5.8ms preprocess, 518.5ms inference, 3.4ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 8 persons, 8 cars, 7 motorcycles, 1 truck, 449.5ms\n",
      "Speed: 10.0ms preprocess, 449.5ms inference, 3.7ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 10 persons, 8 cars, 7 motorcycles, 1 truck, 908.8ms\n",
      "Speed: 7.5ms preprocess, 908.8ms inference, 3.3ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 8 persons, 7 cars, 6 motorcycles, 1 truck, 314.9ms\n",
      "Speed: 6.0ms preprocess, 314.9ms inference, 3.8ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 8 persons, 7 cars, 10 motorcycles, 1 truck, 813.9ms\n",
      "Speed: 7.7ms preprocess, 813.9ms inference, 3.3ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 6 persons, 6 cars, 11 motorcycles, 1 truck, 868.2ms\n",
      "Speed: 16.7ms preprocess, 868.2ms inference, 3.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 6 persons, 5 cars, 12 motorcycles, 1 truck, 1054.2ms\n",
      "Speed: 50.8ms preprocess, 1054.2ms inference, 3.2ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 7 persons, 5 cars, 10 motorcycles, 1 truck, 549.1ms\n",
      "Speed: 9.3ms preprocess, 549.1ms inference, 3.6ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 10 persons, 6 cars, 11 motorcycles, 1 truck, 633.4ms\n",
      "Speed: 89.4ms preprocess, 633.4ms inference, 3.1ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 8 persons, 5 cars, 10 motorcycles, 1 truck, 297.3ms\n",
      "Speed: 6.0ms preprocess, 297.3ms inference, 2.8ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 9 persons, 5 cars, 10 motorcycles, 1 truck, 345.3ms\n",
      "Speed: 5.9ms preprocess, 345.3ms inference, 3.6ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 6 persons, 4 cars, 9 motorcycles, 1 truck, 580.0ms\n",
      "Speed: 5.5ms preprocess, 580.0ms inference, 4.1ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 6 persons, 4 cars, 9 motorcycles, 1 truck, 305.7ms\n",
      "Speed: 5.6ms preprocess, 305.7ms inference, 3.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 6 persons, 5 cars, 11 motorcycles, 1 truck, 705.1ms\n",
      "Speed: 10.4ms preprocess, 705.1ms inference, 3.6ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 61\u001b[0m\n\u001b[0;32m     58\u001b[0m frame \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mresize(frame, (\u001b[38;5;241m1020\u001b[39m, \u001b[38;5;241m500\u001b[39m))\n\u001b[0;32m     60\u001b[0m \u001b[38;5;66;03m# ✅ YOLO Detection\u001b[39;00m\n\u001b[1;32m---> 61\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     62\u001b[0m a \u001b[38;5;241m=\u001b[39m results[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mboxes\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[0;32m     63\u001b[0m px \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(a)\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfloat\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\ultralytics\\engine\\model.py:560\u001b[0m, in \u001b[0;36mModel.predict\u001b[1;34m(self, source, stream, predictor, **kwargs)\u001b[0m\n\u001b[0;32m    558\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m prompts \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictor, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mset_prompts\u001b[39m\u001b[38;5;124m\"\u001b[39m):  \u001b[38;5;66;03m# for SAM-type models\u001b[39;00m\n\u001b[0;32m    559\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictor\u001b[38;5;241m.\u001b[39mset_prompts(prompts)\n\u001b[1;32m--> 560\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictor\u001b[38;5;241m.\u001b[39mpredict_cli(source\u001b[38;5;241m=\u001b[39msource) \u001b[38;5;28;01mif\u001b[39;00m is_cli \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredictor\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\ultralytics\\engine\\predictor.py:175\u001b[0m, in \u001b[0;36mBasePredictor.__call__\u001b[1;34m(self, source, model, stream, *args, **kwargs)\u001b[0m\n\u001b[0;32m    173\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream_inference(source, model, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    174\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 175\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstream_inference\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\utils\\_contextlib.py:36\u001b[0m, in \u001b[0;36m_wrap_generator.<locals>.generator_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     34\u001b[0m     \u001b[38;5;66;03m# Issuing `None` to a generator fires it up\u001b[39;00m\n\u001b[0;32m     35\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[1;32m---> 36\u001b[0m         response \u001b[38;5;241m=\u001b[39m \u001b[43mgen\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     38\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m     39\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     40\u001b[0m             \u001b[38;5;66;03m# Forward the response to our caller and get its next request\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\ultralytics\\engine\\predictor.py:261\u001b[0m, in \u001b[0;36mBasePredictor.stream_inference\u001b[1;34m(self, source, model, *args, **kwargs)\u001b[0m\n\u001b[0;32m    259\u001b[0m \u001b[38;5;66;03m# Inference\u001b[39;00m\n\u001b[0;32m    260\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m profilers[\u001b[38;5;241m1\u001b[39m]:\n\u001b[1;32m--> 261\u001b[0m     preds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minference\u001b[49m\u001b[43m(\u001b[49m\u001b[43mim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    262\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39membed:\n\u001b[0;32m    263\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m [preds] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(preds, torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;28;01melse\u001b[39;00m preds  \u001b[38;5;66;03m# yield embedding tensors\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\ultralytics\\engine\\predictor.py:145\u001b[0m, in \u001b[0;36mBasePredictor.inference\u001b[1;34m(self, im, *args, **kwargs)\u001b[0m\n\u001b[0;32m    139\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Runs inference on a given image using the specified model and arguments.\"\"\"\u001b[39;00m\n\u001b[0;32m    140\u001b[0m visualize \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    141\u001b[0m     increment_path(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave_dir \u001b[38;5;241m/\u001b[39m Path(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m])\u001b[38;5;241m.\u001b[39mstem, mkdir\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    142\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mvisualize \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msource_type\u001b[38;5;241m.\u001b[39mtensor)\n\u001b[0;32m    143\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    144\u001b[0m )\n\u001b[1;32m--> 145\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maugment\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maugment\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvisualize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvisualize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\ultralytics\\nn\\autobackend.py:557\u001b[0m, in \u001b[0;36mAutoBackend.forward\u001b[1;34m(self, im, augment, visualize, embed)\u001b[0m\n\u001b[0;32m    555\u001b[0m \u001b[38;5;66;03m# PyTorch\u001b[39;00m\n\u001b[0;32m    556\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpt \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnn_module:\n\u001b[1;32m--> 557\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maugment\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maugment\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvisualize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvisualize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43membed\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    559\u001b[0m \u001b[38;5;66;03m# TorchScript\u001b[39;00m\n\u001b[0;32m    560\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjit:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\ultralytics\\nn\\tasks.py:114\u001b[0m, in \u001b[0;36mBaseModel.forward\u001b[1;34m(self, x, *args, **kwargs)\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mdict\u001b[39m):  \u001b[38;5;66;03m# for cases of training and validating while training.\u001b[39;00m\n\u001b[0;32m    113\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss(x, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m--> 114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\ultralytics\\nn\\tasks.py:132\u001b[0m, in \u001b[0;36mBaseModel.predict\u001b[1;34m(self, x, profile, visualize, augment, embed)\u001b[0m\n\u001b[0;32m    130\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m augment:\n\u001b[0;32m    131\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_predict_augment(x)\n\u001b[1;32m--> 132\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_predict_once\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprofile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvisualize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membed\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\ultralytics\\nn\\tasks.py:153\u001b[0m, in \u001b[0;36mBaseModel._predict_once\u001b[1;34m(self, x, profile, visualize, embed)\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m profile:\n\u001b[0;32m    152\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_profile_one_layer(m, x, dt)\n\u001b[1;32m--> 153\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# run\u001b[39;00m\n\u001b[0;32m    154\u001b[0m y\u001b[38;5;241m.\u001b[39mappend(x \u001b[38;5;28;01mif\u001b[39;00m m\u001b[38;5;241m.\u001b[39mi \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)  \u001b[38;5;66;03m# save output\u001b[39;00m\n\u001b[0;32m    155\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m visualize:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\ultralytics\\nn\\modules\\conv.py:55\u001b[0m, in \u001b[0;36mConv.forward_fuse\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward_fuse\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m     54\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Apply convolution and activation without batch normalization.\"\"\"\u001b[39;00m\n\u001b[1;32m---> 55\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mact\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\activation.py:432\u001b[0m, in \u001b[0;36mSiLU.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    431\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 432\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msilu\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\functional.py:2379\u001b[0m, in \u001b[0;36msilu\u001b[1;34m(input, inplace)\u001b[0m\n\u001b[0;32m   2377\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(silu, (\u001b[38;5;28minput\u001b[39m,), \u001b[38;5;28minput\u001b[39m, inplace\u001b[38;5;241m=\u001b[39minplace)\n\u001b[0;32m   2378\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inplace:\n\u001b[1;32m-> 2379\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msilu_\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2380\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_nn\u001b[38;5;241m.\u001b[39msilu(\u001b[38;5;28minput\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import pandas as pd\n",
    "from ultralytics import YOLO\n",
    "from tracker import *\n",
    "import numpy as np\n",
    "import csv\n",
    "import os\n",
    "import time\n",
    "\n",
    "# ✅ Load YOLO model\n",
    "model = YOLO('yolov8s.pt')\n",
    "\n",
    "# ✅ Object classes\n",
    "class_list = [\n",
    "    \"person\", \"bicycle\", \"car\", \"motorcycle\", \"airplane\", \"bus\", \"train\", \"truck\", \"boat\",\n",
    "    \"traffic light\", \"fire hydrant\", \"stop sign\", \"parking meter\", \"bench\", \"bird\", \"cat\",\n",
    "    \"dog\", \"horse\", \"sheep\", \"cow\", \"elephant\", \"bear\", \"zebra\", \"giraffe\", \"backpack\",\n",
    "    \"umbrella\", \"handbag\", \"tie\", \"suitcase\", \"frisbee\", \"skis\", \"snowboard\", \"sports ball\",\n",
    "    \"kite\", \"baseball bat\", \"baseball glove\", \"skateboard\", \"surfboard\", \"tennis racket\",\n",
    "    \"bottle\", \"wine glass\", \"cup\", \"fork\", \"knife\", \"spoon\", \"bowl\", \"banana\", \"apple\",\n",
    "    \"sandwich\", \"orange\", \"broccoli\", \"carrot\", \"hot dog\", \"pizza\", \"donut\", \"cake\",\n",
    "    \"chair\", \"couch\", \"potted plant\", \"bed\", \"dining table\", \"toilet\", \"TV\", \"laptop\",\n",
    "    \"mouse\", \"remote\", \"keyboard\", \"cell phone\", \"microwave\", \"oven\", \"toaster\", \"sink\",\n",
    "    \"refrigerator\", \"book\", \"clock\", \"vase\", \"scissors\", \"teddy bear\", \"hair drier\", \"toothbrush\"\n",
    "]\n",
    "\n",
    "# ✅ Initialize tracker\n",
    "tracker = Tracker()\n",
    "cap = cv2.VideoCapture('IMG_8981.MOV')\n",
    "\n",
    "# ✅ CSV File Setup\n",
    "csv_filename = \"vehicles_summary.csv\"\n",
    "\n",
    "# ✅ Create CSV file if it doesn't exist\n",
    "if not os.path.exists(csv_filename):\n",
    "    with open(csv_filename, mode=\"w\", newline=\"\") as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow([\"Timestamp\", \"Cars\", \"Buses\", \"Trucks\", \"Motorcycles\"])\n",
    "\n",
    "# ✅ Define reference lines\n",
    "red_line_y = 250\n",
    "blue_line_y = 340\n",
    "offset = 7  # Allow slight variation due to tracking jitter\n",
    "\n",
    "# ✅ Define vehicle classes to track\n",
    "vehicle_classes = [\"car\", \"bus\", \"truck\", \"motorcycle\"]\n",
    "vehicle_counts = {\"car\": 0, \"bus\": 0, \"truck\": 0, \"motorcycle\": 0}\n",
    "\n",
    "# ✅ Store vehicle IDs that crossed the red line first\n",
    "crossed_red = {}\n",
    "counter_down = []\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    frame = cv2.resize(frame, (1020, 500))\n",
    "\n",
    "    # ✅ YOLO Detection\n",
    "    results = model.predict(frame)\n",
    "    a = results[0].boxes.data.detach().cpu().numpy()\n",
    "    px = pd.DataFrame(a).astype(\"float\")\n",
    "\n",
    "    # ✅ Store detections\n",
    "    detections = []\n",
    "    detected_vehicles = {}\n",
    "\n",
    "    for _, row in px.iterrows():\n",
    "        x1, y1, x2, y2 = int(row[0]), int(row[1]), int(row[2]), int(row[3])\n",
    "        d = int(row[5])\n",
    "        vehicle_type = class_list[d]\n",
    "\n",
    "        if vehicle_type in vehicle_classes:\n",
    "            detections.append([x1, y1, x2, y2])\n",
    "            detected_vehicles[(x1, y1, x2, y2)] = vehicle_type\n",
    "\n",
    "    # ✅ Ensure 'detections' is not empty\n",
    "    bbox_id = tracker.update(np.array(detections)) if detections else []\n",
    "\n",
    "    # ✅ Process ALL detected vehicles\n",
    "    for bbox in bbox_id:\n",
    "        x3, y3, x4, y4, vehicle_id = bbox\n",
    "        cx, cy = (x3 + x4) // 2, (y3 + y4) // 2\n",
    "\n",
    "        vehicle_type = detected_vehicles.get((x3, y3, x4, y4), \"unknown\")\n",
    "\n",
    "        # ✅ Check if the vehicle crosses the RED line first\n",
    "        if red_line_y - offset < cy < red_line_y + offset:\n",
    "            crossed_red[vehicle_id] = (cy, vehicle_type)\n",
    "\n",
    "        # ✅ Only consider vehicles that crossed red before reaching blue\n",
    "        if vehicle_id in crossed_red and blue_line_y - offset < cy < blue_line_y + offset:\n",
    "            _, v_type = crossed_red[vehicle_id]\n",
    "\n",
    "            # ✅ Draw circle at the blue line for valid vehicles\n",
    "            cv2.circle(frame, (cx, cy), 4, (0, 0, 255), -1)\n",
    "            cv2.putText(frame, f\"{v_type}-{vehicle_id}\", (cx, cy), cv2.FONT_HERSHEY_COMPLEX, 0.8, (0, 255, 255), 2)\n",
    "\n",
    "            # ✅ Add to counter only once\n",
    "            if vehicle_id not in counter_down:\n",
    "                counter_down.append(vehicle_id)\n",
    "                vehicle_counts[v_type] += 1\n",
    "\n",
    "    # ✅ Draw reference lines\n",
    "    cv2.line(frame, (550, red_line_y), (880, red_line_y), (0, 0, 255), 3)\n",
    "    cv2.putText(frame, 'red line', (550, red_line_y), cv2.FONT_HERSHEY_COMPLEX, 0.5, (255, 255, 255), 1, cv2.LINE_AA)\n",
    "\n",
    "    cv2.line(frame, (200, blue_line_y), (900, blue_line_y), (255, 0, 0), 3)\n",
    "    cv2.putText(frame, 'blue line', (200, blue_line_y), cv2.FONT_HERSHEY_COMPLEX, 0.5, (255, 255, 255), 1, cv2.LINE_AA)\n",
    "\n",
    "    # ✅ Display vehicle count\n",
    "    cv2.putText(frame, f\"Cars: {vehicle_counts['car']}  Buses: {vehicle_counts['bus']}  Trucks: {vehicle_counts['truck']}  Motorcycles: {vehicle_counts['motorcycle']}\",\n",
    "                (60, 40), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 1, cv2.LINE_AA)\n",
    "\n",
    "    cv2.imshow(\"frames\", frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == 27:\n",
    "        break\n",
    "\n",
    "# ✅ Log the final vehicle count when the video ends\n",
    "timestamp = time.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "number_of_lanes=2\n",
    "# ✅ Calculate light duration using the given formula\n",
    "light_duration = ((vehicle_counts[\"car\"] * 2) + \n",
    "                  (vehicle_counts[\"motorcycle\"] * 1.8) + \n",
    "                  ((vehicle_counts[\"bus\"] + vehicle_counts[\"truck\"]) * 3.5)) / number_of_lanes\n",
    "with open(csv_filename, mode=\"a\", newline=\"\") as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow([timestamp, vehicle_counts[\"car\"], vehicle_counts[\"bus\"], vehicle_counts[\"truck\"], vehicle_counts[\"motorcycle\"], round(light_duration, 2)])\n",
    "\n",
    "print(f\"✅ Final vehicle count saved to CSV: {vehicle_counts}, Light Duration: {round(light_duration, 2)} sec\")\n",
    "\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b20aaebc-0ca7-4c78-af95-3e2510f16638",
   "metadata": {},
   "source": [
    "# Evening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c220c6d3-a238-44cd-b87f-acec2be53cd4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 320x640 9 persons, 4 cars, 2 motorcycles, 1 truck, 247.3ms\n",
      "Speed: 4.6ms preprocess, 247.3ms inference, 2.9ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 9 persons, 4 cars, 1 motorcycle, 2 trucks, 247.0ms\n",
      "Speed: 3.8ms preprocess, 247.0ms inference, 2.8ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 9 persons, 4 cars, 1 motorcycle, 260.7ms\n",
      "Speed: 4.9ms preprocess, 260.7ms inference, 2.4ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 8 persons, 4 cars, 1 motorcycle, 1 truck, 262.6ms\n",
      "Speed: 6.5ms preprocess, 262.6ms inference, 3.2ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 11 persons, 3 cars, 1 motorcycle, 1 truck, 255.7ms\n",
      "Speed: 5.3ms preprocess, 255.7ms inference, 3.1ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 10 persons, 4 cars, 1 motorcycle, 1 truck, 247.8ms\n",
      "Speed: 5.8ms preprocess, 247.8ms inference, 2.9ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 10 persons, 4 cars, 1 motorcycle, 1 truck, 257.5ms\n",
      "Speed: 5.9ms preprocess, 257.5ms inference, 2.9ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 8 persons, 4 cars, 1 motorcycle, 1 bus, 1 truck, 267.1ms\n",
      "Speed: 6.1ms preprocess, 267.1ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 9 persons, 4 cars, 1 motorcycle, 1 train, 1 truck, 294.0ms\n",
      "Speed: 5.0ms preprocess, 294.0ms inference, 2.8ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 9 persons, 3 cars, 1 motorcycle, 1 truck, 253.6ms\n",
      "Speed: 6.0ms preprocess, 253.6ms inference, 2.8ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 7 persons, 4 cars, 3 motorcycles, 2 trucks, 307.8ms\n",
      "Speed: 5.2ms preprocess, 307.8ms inference, 5.8ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 11 persons, 2 cars, 3 motorcycles, 1 bus, 1 truck, 289.3ms\n",
      "Speed: 8.3ms preprocess, 289.3ms inference, 3.7ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 14 persons, 3 cars, 3 motorcycles, 1 truck, 261.1ms\n",
      "Speed: 7.5ms preprocess, 261.1ms inference, 3.6ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 14 persons, 2 cars, 3 motorcycles, 1 truck, 245.2ms\n",
      "Speed: 5.8ms preprocess, 245.2ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 11 persons, 3 cars, 2 motorcycles, 1 truck, 242.4ms\n",
      "Speed: 4.8ms preprocess, 242.4ms inference, 3.5ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 10 persons, 3 cars, 2 motorcycles, 1 truck, 230.9ms\n",
      "Speed: 5.2ms preprocess, 230.9ms inference, 2.3ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 10 persons, 3 cars, 3 motorcycles, 224.9ms\n",
      "Speed: 6.1ms preprocess, 224.9ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 10 persons, 3 cars, 2 motorcycles, 1 truck, 212.3ms\n",
      "Speed: 6.0ms preprocess, 212.3ms inference, 2.3ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 10 persons, 3 cars, 2 motorcycles, 1 truck, 204.2ms\n",
      "Speed: 5.7ms preprocess, 204.2ms inference, 2.2ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 9 persons, 3 cars, 2 motorcycles, 1 truck, 215.6ms\n",
      "Speed: 4.5ms preprocess, 215.6ms inference, 2.4ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 10 persons, 3 cars, 2 motorcycles, 1 truck, 241.5ms\n",
      "Speed: 5.0ms preprocess, 241.5ms inference, 2.4ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 12 persons, 2 cars, 2 motorcycles, 1 truck, 245.7ms\n",
      "Speed: 5.5ms preprocess, 245.7ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 10 persons, 4 cars, 2 motorcycles, 1 truck, 209.6ms\n",
      "Speed: 6.4ms preprocess, 209.6ms inference, 2.4ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 12 persons, 5 cars, 2 motorcycles, 2 trucks, 216.7ms\n",
      "Speed: 4.9ms preprocess, 216.7ms inference, 2.2ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 13 persons, 2 cars, 2 motorcycles, 1 truck, 227.4ms\n",
      "Speed: 4.8ms preprocess, 227.4ms inference, 2.3ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 15 persons, 2 cars, 4 motorcycles, 1 truck, 213.4ms\n",
      "Speed: 4.7ms preprocess, 213.4ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 15 persons, 2 cars, 3 motorcycles, 1 truck, 222.3ms\n",
      "Speed: 4.8ms preprocess, 222.3ms inference, 2.8ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 14 persons, 1 car, 4 motorcycles, 1 truck, 228.1ms\n",
      "Speed: 5.8ms preprocess, 228.1ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 14 persons, 2 cars, 4 motorcycles, 1 truck, 222.6ms\n",
      "Speed: 5.4ms preprocess, 222.6ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 14 persons, 3 cars, 5 motorcycles, 2 trucks, 222.8ms\n",
      "Speed: 6.2ms preprocess, 222.8ms inference, 2.2ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 14 persons, 2 cars, 3 motorcycles, 1 truck, 250.1ms\n",
      "Speed: 5.6ms preprocess, 250.1ms inference, 3.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 13 persons, 1 car, 5 motorcycles, 2 trucks, 242.1ms\n",
      "Speed: 6.0ms preprocess, 242.1ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 13 persons, 1 car, 5 motorcycles, 2 trucks, 227.8ms\n",
      "Speed: 6.9ms preprocess, 227.8ms inference, 2.4ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 14 persons, 1 car, 4 motorcycles, 1 truck, 218.8ms\n",
      "Speed: 6.5ms preprocess, 218.8ms inference, 2.4ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 12 persons, 1 car, 4 motorcycles, 1 truck, 225.5ms\n",
      "Speed: 5.1ms preprocess, 225.5ms inference, 2.4ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 13 persons, 1 car, 6 motorcycles, 220.7ms\n",
      "Speed: 6.3ms preprocess, 220.7ms inference, 2.4ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 11 persons, 1 car, 6 motorcycles, 2 trucks, 226.9ms\n",
      "Speed: 5.6ms preprocess, 226.9ms inference, 2.9ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 14 persons, 1 car, 5 motorcycles, 1 truck, 227.9ms\n",
      "Speed: 5.9ms preprocess, 227.9ms inference, 2.3ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 12 persons, 1 car, 5 motorcycles, 1 truck, 271.4ms\n",
      "Speed: 5.7ms preprocess, 271.4ms inference, 2.4ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 13 persons, 1 car, 3 motorcycles, 1 truck, 269.0ms\n",
      "Speed: 5.3ms preprocess, 269.0ms inference, 6.9ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 12 persons, 2 cars, 4 motorcycles, 1 truck, 384.7ms\n",
      "Speed: 19.3ms preprocess, 384.7ms inference, 3.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 15 persons, 1 car, 4 motorcycles, 1 truck, 288.4ms\n",
      "Speed: 7.9ms preprocess, 288.4ms inference, 3.5ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 13 persons, 2 cars, 4 motorcycles, 1 truck, 282.8ms\n",
      "Speed: 8.0ms preprocess, 282.8ms inference, 3.1ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 13 persons, 1 car, 4 motorcycles, 1 truck, 275.8ms\n",
      "Speed: 5.9ms preprocess, 275.8ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 14 persons, 1 car, 4 motorcycles, 1 truck, 271.0ms\n",
      "Speed: 6.7ms preprocess, 271.0ms inference, 10.8ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 15 persons, 1 car, 3 motorcycles, 1 truck, 379.8ms\n",
      "Speed: 20.3ms preprocess, 379.8ms inference, 3.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 16 persons, 1 car, 3 motorcycles, 1 truck, 323.1ms\n",
      "Speed: 8.2ms preprocess, 323.1ms inference, 4.5ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 15 persons, 2 cars, 3 motorcycles, 1 truck, 338.9ms\n",
      "Speed: 9.8ms preprocess, 338.9ms inference, 2.9ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 15 persons, 1 car, 3 motorcycles, 1 truck, 366.7ms\n",
      "Speed: 5.8ms preprocess, 366.7ms inference, 3.1ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 15 persons, 1 car, 3 motorcycles, 1 truck, 264.2ms\n",
      "Speed: 5.9ms preprocess, 264.2ms inference, 3.3ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 15 persons, 1 car, 4 motorcycles, 1 truck, 269.0ms\n",
      "Speed: 6.9ms preprocess, 269.0ms inference, 3.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 15 persons, 1 car, 4 motorcycles, 1 truck, 345.5ms\n",
      "Speed: 6.1ms preprocess, 345.5ms inference, 3.7ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 14 persons, 1 car, 3 motorcycles, 1 truck, 353.0ms\n",
      "Speed: 6.1ms preprocess, 353.0ms inference, 2.8ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 14 persons, 1 car, 3 motorcycles, 1 truck, 472.2ms\n",
      "Speed: 7.5ms preprocess, 472.2ms inference, 5.3ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 13 persons, 1 car, 4 motorcycles, 1 truck, 362.4ms\n",
      "Speed: 8.5ms preprocess, 362.4ms inference, 3.2ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 13 persons, 1 car, 4 motorcycles, 1 truck, 356.7ms\n",
      "Speed: 6.4ms preprocess, 356.7ms inference, 3.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 15 persons, 1 car, 4 motorcycles, 1 truck, 325.2ms\n",
      "Speed: 7.5ms preprocess, 325.2ms inference, 3.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 15 persons, 1 car, 4 motorcycles, 1 truck, 276.7ms\n",
      "Speed: 6.1ms preprocess, 276.7ms inference, 3.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 15 persons, 1 car, 3 motorcycles, 1 truck, 354.3ms\n",
      "Speed: 5.3ms preprocess, 354.3ms inference, 2.9ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 15 persons, 1 car, 3 motorcycles, 1 truck, 783.0ms\n",
      "Speed: 6.6ms preprocess, 783.0ms inference, 4.1ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 15 persons, 1 car, 3 motorcycles, 2 trucks, 615.6ms\n",
      "Speed: 7.3ms preprocess, 615.6ms inference, 3.3ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 16 persons, 1 car, 4 motorcycles, 2 trucks, 407.0ms\n",
      "Speed: 5.7ms preprocess, 407.0ms inference, 3.1ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 17 persons, 3 motorcycles, 2 trucks, 348.2ms\n",
      "Speed: 5.2ms preprocess, 348.2ms inference, 2.8ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 17 persons, 1 car, 5 motorcycles, 2 trucks, 415.5ms\n",
      "Speed: 9.5ms preprocess, 415.5ms inference, 4.4ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 16 persons, 2 cars, 4 motorcycles, 2 trucks, 1377.2ms\n",
      "Speed: 6.6ms preprocess, 1377.2ms inference, 4.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 61\u001b[0m\n\u001b[0;32m     58\u001b[0m frame \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mresize(frame, (\u001b[38;5;241m1020\u001b[39m, \u001b[38;5;241m500\u001b[39m))\n\u001b[0;32m     60\u001b[0m \u001b[38;5;66;03m# ✅ YOLO Detection\u001b[39;00m\n\u001b[1;32m---> 61\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     62\u001b[0m a \u001b[38;5;241m=\u001b[39m results[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mboxes\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[0;32m     63\u001b[0m px \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(a)\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfloat\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\ultralytics\\engine\\model.py:560\u001b[0m, in \u001b[0;36mModel.predict\u001b[1;34m(self, source, stream, predictor, **kwargs)\u001b[0m\n\u001b[0;32m    558\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m prompts \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictor, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mset_prompts\u001b[39m\u001b[38;5;124m\"\u001b[39m):  \u001b[38;5;66;03m# for SAM-type models\u001b[39;00m\n\u001b[0;32m    559\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictor\u001b[38;5;241m.\u001b[39mset_prompts(prompts)\n\u001b[1;32m--> 560\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictor\u001b[38;5;241m.\u001b[39mpredict_cli(source\u001b[38;5;241m=\u001b[39msource) \u001b[38;5;28;01mif\u001b[39;00m is_cli \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredictor\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\ultralytics\\engine\\predictor.py:175\u001b[0m, in \u001b[0;36mBasePredictor.__call__\u001b[1;34m(self, source, model, stream, *args, **kwargs)\u001b[0m\n\u001b[0;32m    173\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream_inference(source, model, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    174\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 175\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstream_inference\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\utils\\_contextlib.py:36\u001b[0m, in \u001b[0;36m_wrap_generator.<locals>.generator_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     34\u001b[0m     \u001b[38;5;66;03m# Issuing `None` to a generator fires it up\u001b[39;00m\n\u001b[0;32m     35\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[1;32m---> 36\u001b[0m         response \u001b[38;5;241m=\u001b[39m \u001b[43mgen\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     38\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m     39\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     40\u001b[0m             \u001b[38;5;66;03m# Forward the response to our caller and get its next request\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\ultralytics\\engine\\predictor.py:261\u001b[0m, in \u001b[0;36mBasePredictor.stream_inference\u001b[1;34m(self, source, model, *args, **kwargs)\u001b[0m\n\u001b[0;32m    259\u001b[0m \u001b[38;5;66;03m# Inference\u001b[39;00m\n\u001b[0;32m    260\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m profilers[\u001b[38;5;241m1\u001b[39m]:\n\u001b[1;32m--> 261\u001b[0m     preds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minference\u001b[49m\u001b[43m(\u001b[49m\u001b[43mim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    262\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39membed:\n\u001b[0;32m    263\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m [preds] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(preds, torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;28;01melse\u001b[39;00m preds  \u001b[38;5;66;03m# yield embedding tensors\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\ultralytics\\engine\\predictor.py:145\u001b[0m, in \u001b[0;36mBasePredictor.inference\u001b[1;34m(self, im, *args, **kwargs)\u001b[0m\n\u001b[0;32m    139\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Runs inference on a given image using the specified model and arguments.\"\"\"\u001b[39;00m\n\u001b[0;32m    140\u001b[0m visualize \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    141\u001b[0m     increment_path(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave_dir \u001b[38;5;241m/\u001b[39m Path(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m])\u001b[38;5;241m.\u001b[39mstem, mkdir\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    142\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mvisualize \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msource_type\u001b[38;5;241m.\u001b[39mtensor)\n\u001b[0;32m    143\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    144\u001b[0m )\n\u001b[1;32m--> 145\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maugment\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maugment\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvisualize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvisualize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\ultralytics\\nn\\autobackend.py:557\u001b[0m, in \u001b[0;36mAutoBackend.forward\u001b[1;34m(self, im, augment, visualize, embed)\u001b[0m\n\u001b[0;32m    555\u001b[0m \u001b[38;5;66;03m# PyTorch\u001b[39;00m\n\u001b[0;32m    556\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpt \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnn_module:\n\u001b[1;32m--> 557\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maugment\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maugment\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvisualize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvisualize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43membed\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    559\u001b[0m \u001b[38;5;66;03m# TorchScript\u001b[39;00m\n\u001b[0;32m    560\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjit:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\ultralytics\\nn\\tasks.py:114\u001b[0m, in \u001b[0;36mBaseModel.forward\u001b[1;34m(self, x, *args, **kwargs)\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mdict\u001b[39m):  \u001b[38;5;66;03m# for cases of training and validating while training.\u001b[39;00m\n\u001b[0;32m    113\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss(x, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m--> 114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\ultralytics\\nn\\tasks.py:132\u001b[0m, in \u001b[0;36mBaseModel.predict\u001b[1;34m(self, x, profile, visualize, augment, embed)\u001b[0m\n\u001b[0;32m    130\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m augment:\n\u001b[0;32m    131\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_predict_augment(x)\n\u001b[1;32m--> 132\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_predict_once\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprofile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvisualize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membed\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\ultralytics\\nn\\tasks.py:153\u001b[0m, in \u001b[0;36mBaseModel._predict_once\u001b[1;34m(self, x, profile, visualize, embed)\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m profile:\n\u001b[0;32m    152\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_profile_one_layer(m, x, dt)\n\u001b[1;32m--> 153\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# run\u001b[39;00m\n\u001b[0;32m    154\u001b[0m y\u001b[38;5;241m.\u001b[39mappend(x \u001b[38;5;28;01mif\u001b[39;00m m\u001b[38;5;241m.\u001b[39mi \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)  \u001b[38;5;66;03m# save output\u001b[39;00m\n\u001b[0;32m    155\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m visualize:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\ultralytics\\nn\\modules\\block.py:240\u001b[0m, in \u001b[0;36mC2f.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    238\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcv1(x)\u001b[38;5;241m.\u001b[39mchunk(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m    239\u001b[0m y\u001b[38;5;241m.\u001b[39mextend(m(y[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]) \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mm)\n\u001b[1;32m--> 240\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcv2(\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import pandas as pd\n",
    "from ultralytics import YOLO\n",
    "from tracker import *\n",
    "import numpy as np\n",
    "import csv\n",
    "import os\n",
    "import time\n",
    "\n",
    "# ✅ Load YOLO model\n",
    "model = YOLO('yolov8s.pt')\n",
    "\n",
    "# ✅ Object classes\n",
    "class_list = [\n",
    "    \"person\", \"bicycle\", \"car\", \"motorcycle\", \"airplane\", \"bus\", \"train\", \"truck\", \"boat\",\n",
    "    \"traffic light\", \"fire hydrant\", \"stop sign\", \"parking meter\", \"bench\", \"bird\", \"cat\",\n",
    "    \"dog\", \"horse\", \"sheep\", \"cow\", \"elephant\", \"bear\", \"zebra\", \"giraffe\", \"backpack\",\n",
    "    \"umbrella\", \"handbag\", \"tie\", \"suitcase\", \"frisbee\", \"skis\", \"snowboard\", \"sports ball\",\n",
    "    \"kite\", \"baseball bat\", \"baseball glove\", \"skateboard\", \"surfboard\", \"tennis racket\",\n",
    "    \"bottle\", \"wine glass\", \"cup\", \"fork\", \"knife\", \"spoon\", \"bowl\", \"banana\", \"apple\",\n",
    "    \"sandwich\", \"orange\", \"broccoli\", \"carrot\", \"hot dog\", \"pizza\", \"donut\", \"cake\",\n",
    "    \"chair\", \"couch\", \"potted plant\", \"bed\", \"dining table\", \"toilet\", \"TV\", \"laptop\",\n",
    "    \"mouse\", \"remote\", \"keyboard\", \"cell phone\", \"microwave\", \"oven\", \"toaster\", \"sink\",\n",
    "    \"refrigerator\", \"book\", \"clock\", \"vase\", \"scissors\", \"teddy bear\", \"hair drier\", \"toothbrush\"\n",
    "]\n",
    "\n",
    "# ✅ Initialize tracker\n",
    "tracker = Tracker()\n",
    "cap = cv2.VideoCapture('camp12_eve.mp4')\n",
    "\n",
    "# ✅ CSV File Setup\n",
    "csv_filename = \"vehicles_summary.csv\"\n",
    "\n",
    "# ✅ Create CSV file if it doesn't exist\n",
    "if not os.path.exists(csv_filename):\n",
    "    with open(csv_filename, mode=\"w\", newline=\"\") as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow([\"Timestamp\", \"Cars\", \"Buses\", \"Trucks\", \"Motorcycles\"])\n",
    "\n",
    "# ✅ Define reference lines\n",
    "red_line_y = 355\n",
    "blue_line_y = 375\n",
    "offset = 7  # Allow slight variation due to tracking jitter\n",
    "\n",
    "# ✅ Define vehicle classes to track\n",
    "vehicle_classes = [\"car\", \"bus\", \"truck\", \"motorcycle\"]\n",
    "vehicle_counts = {\"car\": 0, \"bus\": 0, \"truck\": 0, \"motorcycle\": 0}\n",
    "\n",
    "# ✅ Store vehicle IDs that crossed the red line first\n",
    "crossed_red = {}\n",
    "counter_down = []\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    frame = cv2.resize(frame, (1020, 500))\n",
    "\n",
    "    # ✅ YOLO Detection\n",
    "    results = model.predict(frame)\n",
    "    a = results[0].boxes.data.detach().cpu().numpy()\n",
    "    px = pd.DataFrame(a).astype(\"float\")\n",
    "\n",
    "    # ✅ Store detections\n",
    "    detections = []\n",
    "    detected_vehicles = {}\n",
    "\n",
    "    for _, row in px.iterrows():\n",
    "        x1, y1, x2, y2 = int(row[0]), int(row[1]), int(row[2]), int(row[3])\n",
    "        d = int(row[5])\n",
    "        vehicle_type = class_list[d]\n",
    "\n",
    "        if vehicle_type in vehicle_classes:\n",
    "            detections.append([x1, y1, x2, y2])\n",
    "            detected_vehicles[(x1, y1, x2, y2)] = vehicle_type\n",
    "\n",
    "    # ✅ Ensure 'detections' is not empty\n",
    "    bbox_id = tracker.update(np.array(detections)) if detections else []\n",
    "\n",
    "    # ✅ Process ALL detected vehicles\n",
    "    for bbox in bbox_id:\n",
    "        x3, y3, x4, y4, vehicle_id = bbox\n",
    "        cx, cy = (x3 + x4) // 2, (y3 + y4) // 2\n",
    "\n",
    "        vehicle_type = detected_vehicles.get((x3, y3, x4, y4), \"unknown\")\n",
    "\n",
    "        # ✅ Check if the vehicle crosses the RED line first\n",
    "        if red_line_y - offset < cy < red_line_y + offset:\n",
    "            crossed_red[vehicle_id] = (cy, vehicle_type)\n",
    "\n",
    "        # ✅ Only consider vehicles that crossed red before reaching blue\n",
    "        if vehicle_id in crossed_red and blue_line_y - offset < cy < blue_line_y + offset:\n",
    "            _, v_type = crossed_red[vehicle_id]\n",
    "\n",
    "            # ✅ Draw circle at the blue line for valid vehicles\n",
    "            cv2.circle(frame, (cx, cy), 4, (0, 0, 255), -1)\n",
    "            cv2.putText(frame, f\"{v_type}-{vehicle_id}\", (cx, cy), cv2.FONT_HERSHEY_COMPLEX, 0.8, (0, 255, 255), 2)\n",
    "\n",
    "            # ✅ Add to counter only once\n",
    "            if vehicle_id not in counter_down:\n",
    "                counter_down.append(vehicle_id)\n",
    "                vehicle_counts[v_type] += 1\n",
    "\n",
    "    # ✅ Draw reference lines\n",
    "    cv2.line(frame, (260, red_line_y), (724, red_line_y), (0, 0, 255), 3)\n",
    "    cv2.putText(frame, 'red line', (260, red_line_y), cv2.FONT_HERSHEY_COMPLEX, 0.5, (255, 255, 255), 1, cv2.LINE_AA)\n",
    "\n",
    "    cv2.line(frame, (200, blue_line_y), (779, blue_line_y), (255, 0, 0), 3)\n",
    "    cv2.putText(frame, 'blue line', (200, blue_line_y), cv2.FONT_HERSHEY_COMPLEX, 0.5, (255, 255, 255), 1, cv2.LINE_AA)\n",
    "\n",
    "    # ✅ Display vehicle count\n",
    "    cv2.putText(frame, f\"Cars: {vehicle_counts['car']}  Buses: {vehicle_counts['bus']}  Trucks: {vehicle_counts['truck']}  Motorcycles: {vehicle_counts['motorcycle']}\",\n",
    "                (60, 40), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 1, cv2.LINE_AA)\n",
    "\n",
    "    cv2.imshow(\"frames\", frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == 27:\n",
    "        break\n",
    "\n",
    "# ✅ Log the final vehicle count when the video ends\n",
    "timestamp = time.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "number_of_lanes=2\n",
    "# ✅ Calculate light duration using the given formula\n",
    "light_duration = ((vehicle_counts[\"car\"] * 2) + \n",
    "                  (vehicle_counts[\"motorcycle\"] * 1.8) + \n",
    "                  ((vehicle_counts[\"bus\"] + vehicle_counts[\"truck\"]) * 3.5)) / number_of_lanes\n",
    "with open(csv_filename, mode=\"a\", newline=\"\") as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow([timestamp, vehicle_counts[\"car\"], vehicle_counts[\"bus\"], vehicle_counts[\"truck\"], vehicle_counts[\"motorcycle\"], round(light_duration, 2)])\n",
    "\n",
    "print(f\"✅ Final vehicle count saved to CSV: {vehicle_counts}, Light Duration: {round(light_duration, 2)} sec\")\n",
    "\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c27eb7ac-be7c-4472-aa70-a825047a59e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

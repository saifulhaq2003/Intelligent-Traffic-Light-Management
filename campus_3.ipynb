{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a06212f-a475-4ad2-bc49-9f674808805e",
   "metadata": {},
   "source": [
    "# Morning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2516533b-2199-4567-ab12-dab82527b7e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 320x640 6 cars, 3 motorcycles, 2 trucks, 288.1ms\n",
      "Speed: 5.5ms preprocess, 288.1ms inference, 3.3ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 person, 6 cars, 3 motorcycles, 1 bus, 1 truck, 245.9ms\n",
      "Speed: 6.5ms preprocess, 245.9ms inference, 1.9ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 2 persons, 7 cars, 3 motorcycles, 1 bus, 1 truck, 247.1ms\n",
      "Speed: 2.9ms preprocess, 247.1ms inference, 1.4ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 3 persons, 6 cars, 2 motorcycles, 1 bus, 2 trucks, 267.6ms\n",
      "Speed: 4.5ms preprocess, 267.6ms inference, 2.3ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 person, 5 cars, 2 motorcycles, 1 bus, 1 truck, 293.5ms\n",
      "Speed: 96.8ms preprocess, 293.5ms inference, 3.2ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 person, 5 cars, 2 motorcycles, 1 bus, 1 truck, 239.4ms\n",
      "Speed: 4.3ms preprocess, 239.4ms inference, 2.9ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 2 persons, 5 cars, 3 motorcycles, 1 bus, 1 truck, 244.3ms\n",
      "Speed: 5.1ms preprocess, 244.3ms inference, 2.3ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 6 cars, 2 motorcycles, 1 bus, 1 truck, 216.4ms\n",
      "Speed: 3.1ms preprocess, 216.4ms inference, 2.8ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 3 persons, 6 cars, 2 motorcycles, 1 bus, 2 trucks, 232.0ms\n",
      "Speed: 2.6ms preprocess, 232.0ms inference, 2.1ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 5 persons, 6 cars, 1 motorcycle, 1 bus, 2 trucks, 223.1ms\n",
      "Speed: 5.2ms preprocess, 223.1ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 2 persons, 4 cars, 2 motorcycles, 1 bus, 2 trucks, 233.5ms\n",
      "Speed: 4.0ms preprocess, 233.5ms inference, 2.4ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 4 persons, 5 cars, 2 motorcycles, 1 bus, 2 trucks, 218.9ms\n",
      "Speed: 4.4ms preprocess, 218.9ms inference, 2.3ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 3 persons, 4 cars, 1 motorcycle, 1 bus, 2 trucks, 229.2ms\n",
      "Speed: 2.7ms preprocess, 229.2ms inference, 2.4ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 2 persons, 4 cars, 2 motorcycles, 1 bus, 1 truck, 235.5ms\n",
      "Speed: 4.3ms preprocess, 235.5ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 person, 4 cars, 2 motorcycles, 1 bus, 1 truck, 245.3ms\n",
      "Speed: 4.7ms preprocess, 245.3ms inference, 2.3ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 person, 5 cars, 2 motorcycles, 1 bus, 2 trucks, 233.5ms\n",
      "Speed: 3.7ms preprocess, 233.5ms inference, 2.4ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 person, 6 cars, 1 motorcycle, 1 bus, 2 trucks, 224.1ms\n",
      "Speed: 2.8ms preprocess, 224.1ms inference, 2.4ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 person, 6 cars, 1 motorcycle, 1 bus, 2 trucks, 221.7ms\n",
      "Speed: 2.7ms preprocess, 221.7ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 2 persons, 6 cars, 1 motorcycle, 1 bus, 2 trucks, 216.8ms\n",
      "Speed: 3.5ms preprocess, 216.8ms inference, 2.9ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 person, 7 cars, 1 motorcycle, 1 bus, 2 trucks, 182.1ms\n",
      "Speed: 3.4ms preprocess, 182.1ms inference, 1.3ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 person, 5 cars, 1 motorcycle, 1 bus, 2 trucks, 188.7ms\n",
      "Speed: 3.8ms preprocess, 188.7ms inference, 1.4ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 person, 5 cars, 2 motorcycles, 1 bus, 2 trucks, 188.3ms\n",
      "Speed: 3.3ms preprocess, 188.3ms inference, 1.2ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 3 persons, 5 cars, 1 motorcycle, 1 bus, 2 trucks, 158.3ms\n",
      "Speed: 2.7ms preprocess, 158.3ms inference, 1.7ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 person, 4 cars, 1 motorcycle, 1 bus, 2 trucks, 140.7ms\n",
      "Speed: 2.8ms preprocess, 140.7ms inference, 1.2ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 person, 5 cars, 1 motorcycle, 1 bus, 2 trucks, 147.7ms\n",
      "Speed: 2.7ms preprocess, 147.7ms inference, 1.3ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 person, 5 cars, 1 motorcycle, 1 bus, 2 trucks, 193.4ms\n",
      "Speed: 3.2ms preprocess, 193.4ms inference, 1.4ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 person, 5 cars, 1 motorcycle, 1 bus, 3 trucks, 164.9ms\n",
      "Speed: 2.7ms preprocess, 164.9ms inference, 1.4ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 person, 5 cars, 1 motorcycle, 2 buss, 3 trucks, 188.7ms\n",
      "Speed: 2.8ms preprocess, 188.7ms inference, 1.7ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 person, 5 cars, 1 motorcycle, 1 bus, 3 trucks, 162.4ms\n",
      "Speed: 2.8ms preprocess, 162.4ms inference, 1.4ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 2 persons, 4 cars, 2 motorcycles, 1 bus, 2 trucks, 164.3ms\n",
      "Speed: 2.8ms preprocess, 164.3ms inference, 1.4ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 person, 4 cars, 1 motorcycle, 1 bus, 2 trucks, 182.1ms\n",
      "Speed: 2.7ms preprocess, 182.1ms inference, 1.2ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 2 persons, 4 cars, 1 motorcycle, 1 bus, 2 trucks, 161.9ms\n",
      "Speed: 3.6ms preprocess, 161.9ms inference, 1.3ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 2 persons, 4 cars, 2 motorcycles, 1 bus, 2 trucks, 173.8ms\n",
      "Speed: 3.3ms preprocess, 173.8ms inference, 1.5ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 2 persons, 5 cars, 2 motorcycles, 1 bus, 2 trucks, 183.9ms\n",
      "Speed: 2.9ms preprocess, 183.9ms inference, 1.3ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 3 persons, 6 cars, 2 motorcycles, 1 bus, 3 trucks, 157.1ms\n",
      "Speed: 2.7ms preprocess, 157.1ms inference, 1.3ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 3 persons, 7 cars, 2 motorcycles, 1 bus, 2 trucks, 157.7ms\n",
      "Speed: 2.9ms preprocess, 157.7ms inference, 1.4ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 2 persons, 6 cars, 3 motorcycles, 1 bus, 2 trucks, 159.1ms\n",
      "Speed: 2.5ms preprocess, 159.1ms inference, 1.4ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 3 persons, 7 cars, 2 motorcycles, 1 bus, 2 trucks, 125.5ms\n",
      "Speed: 2.7ms preprocess, 125.5ms inference, 1.4ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 2 persons, 5 cars, 2 motorcycles, 1 bus, 2 trucks, 132.8ms\n",
      "Speed: 2.9ms preprocess, 132.8ms inference, 1.2ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 2 persons, 5 cars, 2 motorcycles, 1 bus, 1 truck, 126.0ms\n",
      "Speed: 2.6ms preprocess, 126.0ms inference, 1.2ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 2 persons, 5 cars, 2 motorcycles, 2 buss, 1 truck, 131.7ms\n",
      "Speed: 3.3ms preprocess, 131.7ms inference, 1.2ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 2 persons, 6 cars, 2 motorcycles, 1 bus, 3 trucks, 119.9ms\n",
      "Speed: 2.7ms preprocess, 119.9ms inference, 1.2ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 2 persons, 4 cars, 2 motorcycles, 3 trucks, 1 backpack, 131.0ms\n",
      "Speed: 2.9ms preprocess, 131.0ms inference, 1.3ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 4 persons, 4 cars, 2 motorcycles, 1 bus, 3 trucks, 131.1ms\n",
      "Speed: 3.0ms preprocess, 131.1ms inference, 1.4ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 3 persons, 4 cars, 2 motorcycles, 1 bus, 2 trucks, 148.8ms\n",
      "Speed: 2.6ms preprocess, 148.8ms inference, 1.5ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 3 persons, 5 cars, 2 motorcycles, 1 bus, 2 trucks, 147.4ms\n",
      "Speed: 3.6ms preprocess, 147.4ms inference, 1.6ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 3 persons, 5 cars, 2 motorcycles, 1 bus, 2 trucks, 201.3ms\n",
      "Speed: 3.8ms preprocess, 201.3ms inference, 2.1ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 3 persons, 4 cars, 2 motorcycles, 1 bus, 2 trucks, 234.0ms\n",
      "Speed: 4.8ms preprocess, 234.0ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 3 persons, 5 cars, 1 motorcycle, 1 bus, 3 trucks, 235.7ms\n",
      "Speed: 5.9ms preprocess, 235.7ms inference, 2.4ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 4 persons, 4 cars, 1 motorcycle, 1 bus, 2 trucks, 224.8ms\n",
      "Speed: 5.7ms preprocess, 224.8ms inference, 2.8ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 3 persons, 5 cars, 1 motorcycle, 1 bus, 2 trucks, 269.3ms\n",
      "Speed: 7.4ms preprocess, 269.3ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 2 persons, 5 cars, 1 motorcycle, 1 bus, 3 trucks, 272.6ms\n",
      "Speed: 5.3ms preprocess, 272.6ms inference, 2.9ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 3 persons, 5 cars, 1 motorcycle, 1 bus, 2 trucks, 237.5ms\n",
      "Speed: 5.5ms preprocess, 237.5ms inference, 2.4ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 3 persons, 4 cars, 2 motorcycles, 1 bus, 2 trucks, 264.5ms\n",
      "Speed: 5.7ms preprocess, 264.5ms inference, 3.1ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 3 persons, 4 cars, 2 motorcycles, 1 bus, 3 trucks, 270.4ms\n",
      "Speed: 6.6ms preprocess, 270.4ms inference, 2.9ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 4 persons, 4 cars, 1 motorcycle, 1 bus, 3 trucks, 226.2ms\n",
      "Speed: 6.1ms preprocess, 226.2ms inference, 3.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 2 persons, 4 cars, 1 motorcycle, 3 trucks, 255.5ms\n",
      "Speed: 5.3ms preprocess, 255.5ms inference, 2.8ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 2 persons, 5 cars, 2 motorcycles, 1 bus, 3 trucks, 248.2ms\n",
      "Speed: 5.9ms preprocess, 248.2ms inference, 2.8ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 person, 6 cars, 1 motorcycle, 2 trucks, 236.3ms\n",
      "Speed: 5.5ms preprocess, 236.3ms inference, 3.7ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 person, 5 cars, 1 motorcycle, 3 trucks, 257.8ms\n",
      "Speed: 8.0ms preprocess, 257.8ms inference, 2.9ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 2 persons, 6 cars, 1 motorcycle, 3 trucks, 291.5ms\n",
      "Speed: 6.2ms preprocess, 291.5ms inference, 3.6ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 2 persons, 7 cars, 1 motorcycle, 1 truck, 281.4ms\n",
      "Speed: 6.0ms preprocess, 281.4ms inference, 3.1ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 2 persons, 5 cars, 1 motorcycle, 2 trucks, 261.5ms\n",
      "Speed: 5.9ms preprocess, 261.5ms inference, 2.3ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 2 persons, 6 cars, 1 motorcycle, 2 trucks, 268.2ms\n",
      "Speed: 5.8ms preprocess, 268.2ms inference, 2.3ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 2 persons, 6 cars, 1 motorcycle, 3 trucks, 256.7ms\n",
      "Speed: 5.4ms preprocess, 256.7ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 2 persons, 5 cars, 1 motorcycle, 3 trucks, 289.3ms\n",
      "Speed: 5.6ms preprocess, 289.3ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 2 persons, 6 cars, 1 motorcycle, 1 bus, 2 trucks, 253.6ms\n",
      "Speed: 5.3ms preprocess, 253.6ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 2 persons, 5 cars, 1 motorcycle, 1 bus, 3 trucks, 282.2ms\n",
      "Speed: 5.5ms preprocess, 282.2ms inference, 2.4ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 2 persons, 5 cars, 1 motorcycle, 1 bus, 3 trucks, 273.5ms\n",
      "Speed: 5.3ms preprocess, 273.5ms inference, 2.8ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 2 persons, 5 cars, 1 motorcycle, 1 bus, 3 trucks, 272.0ms\n",
      "Speed: 5.8ms preprocess, 272.0ms inference, 2.9ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 2 persons, 5 cars, 1 motorcycle, 1 bus, 3 trucks, 350.1ms\n",
      "Speed: 5.4ms preprocess, 350.1ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 3 persons, 4 cars, 1 motorcycle, 1 bus, 2 trucks, 373.3ms\n",
      "Speed: 7.0ms preprocess, 373.3ms inference, 4.1ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 2 persons, 3 cars, 1 motorcycle, 1 bus, 1 truck, 311.2ms\n",
      "Speed: 9.4ms preprocess, 311.2ms inference, 3.1ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 2 persons, 3 cars, 1 motorcycle, 1 bus, 1 truck, 309.2ms\n",
      "Speed: 5.9ms preprocess, 309.2ms inference, 3.4ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 2 persons, 3 cars, 1 motorcycle, 1 bus, 1 truck, 284.8ms\n",
      "Speed: 8.5ms preprocess, 284.8ms inference, 3.1ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 person, 3 cars, 2 motorcycles, 1 bus, 1 truck, 304.4ms\n",
      "Speed: 6.3ms preprocess, 304.4ms inference, 3.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 person, 3 cars, 1 motorcycle, 1 bus, 3 trucks, 353.3ms\n",
      "Speed: 6.2ms preprocess, 353.3ms inference, 4.6ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 2 persons, 3 cars, 2 motorcycles, 1 bus, 2 trucks, 362.2ms\n",
      "Speed: 6.3ms preprocess, 362.2ms inference, 5.1ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 2 persons, 3 cars, 2 motorcycles, 1 bus, 1 truck, 717.6ms\n",
      "Speed: 10.8ms preprocess, 717.6ms inference, 3.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 3 persons, 3 cars, 2 motorcycles, 1 bus, 1 truck, 297.7ms\n",
      "Speed: 4.0ms preprocess, 297.7ms inference, 3.2ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 2 persons, 4 cars, 1 motorcycle, 1 bus, 2 trucks, 244.9ms\n",
      "Speed: 6.2ms preprocess, 244.9ms inference, 2.4ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 3 persons, 6 cars, 2 motorcycles, 1 bus, 2 trucks, 252.8ms\n",
      "Speed: 5.8ms preprocess, 252.8ms inference, 2.8ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 2 persons, 5 cars, 1 motorcycle, 1 bus, 2 trucks, 237.2ms\n",
      "Speed: 4.9ms preprocess, 237.2ms inference, 2.4ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 2 persons, 5 cars, 1 motorcycle, 1 bus, 2 trucks, 316.9ms\n",
      "Speed: 5.1ms preprocess, 316.9ms inference, 3.3ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 2 persons, 5 cars, 1 motorcycle, 1 bus, 2 trucks, 321.1ms\n",
      "Speed: 6.0ms preprocess, 321.1ms inference, 4.2ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 2 persons, 5 cars, 1 motorcycle, 1 bus, 2 trucks, 292.5ms\n",
      "Speed: 8.3ms preprocess, 292.5ms inference, 4.1ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 2 persons, 6 cars, 1 motorcycle, 1 bus, 2 trucks, 341.9ms\n",
      "Speed: 7.9ms preprocess, 341.9ms inference, 5.2ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 person, 9 cars, 1 motorcycle, 1 bus, 2 trucks, 272.5ms\n",
      "Speed: 7.4ms preprocess, 272.5ms inference, 2.3ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 person, 8 cars, 1 motorcycle, 1 bus, 2 trucks, 263.3ms\n",
      "Speed: 5.6ms preprocess, 263.3ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 person, 7 cars, 1 motorcycle, 2 trucks, 298.0ms\n",
      "Speed: 5.4ms preprocess, 298.0ms inference, 3.5ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 person, 7 cars, 1 motorcycle, 2 trucks, 311.2ms\n",
      "Speed: 5.9ms preprocess, 311.2ms inference, 2.3ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 person, 7 cars, 1 motorcycle, 1 bus, 2 trucks, 247.8ms\n",
      "Speed: 5.5ms preprocess, 247.8ms inference, 2.8ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 person, 7 cars, 1 motorcycle, 1 bus, 2 trucks, 280.3ms\n",
      "Speed: 6.1ms preprocess, 280.3ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 person, 7 cars, 1 motorcycle, 1 bus, 3 trucks, 302.3ms\n",
      "Speed: 5.1ms preprocess, 302.3ms inference, 3.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 person, 7 cars, 1 motorcycle, 1 bus, 3 trucks, 250.7ms\n",
      "Speed: 5.6ms preprocess, 250.7ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 person, 7 cars, 1 motorcycle, 1 bus, 3 trucks, 247.8ms\n",
      "Speed: 6.1ms preprocess, 247.8ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 person, 7 cars, 1 motorcycle, 1 bus, 2 trucks, 246.3ms\n",
      "Speed: 5.1ms preprocess, 246.3ms inference, 3.2ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 person, 7 cars, 1 motorcycle, 1 bus, 2 trucks, 245.4ms\n",
      "Speed: 5.8ms preprocess, 245.4ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 person, 7 cars, 1 motorcycle, 1 bus, 2 trucks, 231.3ms\n",
      "Speed: 5.5ms preprocess, 231.3ms inference, 2.4ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 person, 7 cars, 1 motorcycle, 1 bus, 2 trucks, 262.4ms\n",
      "Speed: 5.2ms preprocess, 262.4ms inference, 3.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 person, 6 cars, 1 motorcycle, 1 bus, 2 trucks, 269.9ms\n",
      "Speed: 5.2ms preprocess, 269.9ms inference, 2.9ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 person, 5 cars, 1 motorcycle, 1 bus, 3 trucks, 265.5ms\n",
      "Speed: 5.4ms preprocess, 265.5ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 2 persons, 5 cars, 1 motorcycle, 1 bus, 3 trucks, 277.3ms\n",
      "Speed: 5.4ms preprocess, 277.3ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 person, 5 cars, 1 motorcycle, 1 bus, 2 trucks, 274.9ms\n",
      "Speed: 5.8ms preprocess, 274.9ms inference, 2.8ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 2 persons, 5 cars, 1 motorcycle, 1 bus, 2 trucks, 246.1ms\n",
      "Speed: 6.0ms preprocess, 246.1ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 2 persons, 5 cars, 1 motorcycle, 1 bus, 2 trucks, 317.1ms\n",
      "Speed: 8.5ms preprocess, 317.1ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 person, 5 cars, 1 motorcycle, 1 bus, 2 trucks, 344.9ms\n",
      "Speed: 3.1ms preprocess, 344.9ms inference, 3.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 person, 5 cars, 1 motorcycle, 1 bus, 2 trucks, 373.9ms\n",
      "Speed: 15.7ms preprocess, 373.9ms inference, 3.1ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 person, 5 cars, 1 motorcycle, 1 bus, 2 trucks, 342.4ms\n",
      "Speed: 10.1ms preprocess, 342.4ms inference, 3.3ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 person, 5 cars, 1 motorcycle, 1 bus, 2 trucks, 353.3ms\n",
      "Speed: 7.4ms preprocess, 353.3ms inference, 3.9ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 person, 6 cars, 1 bus, 3 trucks, 271.9ms\n",
      "Speed: 9.9ms preprocess, 271.9ms inference, 3.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 person, 7 cars, 1 bus, 3 trucks, 301.3ms\n",
      "Speed: 6.5ms preprocess, 301.3ms inference, 2.4ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 person, 8 cars, 1 bus, 3 trucks, 560.3ms\n",
      "Speed: 6.0ms preprocess, 560.3ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 person, 7 cars, 1 bus, 2 trucks, 249.9ms\n",
      "Speed: 7.7ms preprocess, 249.9ms inference, 2.4ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 person, 7 cars, 1 bus, 2 trucks, 265.6ms\n",
      "Speed: 6.2ms preprocess, 265.6ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 person, 7 cars, 1 bus, 2 trucks, 270.2ms\n",
      "Speed: 5.7ms preprocess, 270.2ms inference, 3.1ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 person, 5 cars, 1 motorcycle, 1 bus, 2 trucks, 265.2ms\n",
      "Speed: 5.5ms preprocess, 265.2ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 person, 4 cars, 1 bus, 2 trucks, 250.3ms\n",
      "Speed: 6.5ms preprocess, 250.3ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 person, 4 cars, 1 motorcycle, 1 bus, 2 trucks, 279.0ms\n",
      "Speed: 8.1ms preprocess, 279.0ms inference, 2.8ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 person, 4 cars, 2 motorcycles, 1 bus, 2 trucks, 281.4ms\n",
      "Speed: 5.1ms preprocess, 281.4ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 2 persons, 5 cars, 1 motorcycle, 1 bus, 1 truck, 289.2ms\n",
      "Speed: 8.4ms preprocess, 289.2ms inference, 2.8ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 2 persons, 6 cars, 1 motorcycle, 1 bus, 1 truck, 337.0ms\n",
      "Speed: 5.6ms preprocess, 337.0ms inference, 2.3ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 person, 5 cars, 1 motorcycle, 1 bus, 1 truck, 241.0ms\n",
      "Speed: 5.4ms preprocess, 241.0ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 person, 5 cars, 1 motorcycle, 2 buss, 1 truck, 236.2ms\n",
      "Speed: 6.8ms preprocess, 236.2ms inference, 2.4ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 2 persons, 5 cars, 2 motorcycles, 2 buss, 1 truck, 242.5ms\n",
      "Speed: 5.0ms preprocess, 242.5ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 2 persons, 6 cars, 2 motorcycles, 1 bus, 1 truck, 294.1ms\n",
      "Speed: 5.9ms preprocess, 294.1ms inference, 2.3ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 4 persons, 6 cars, 2 motorcycles, 2 buss, 1 truck, 235.6ms\n",
      "Speed: 4.5ms preprocess, 235.6ms inference, 2.3ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 4 persons, 6 cars, 2 motorcycles, 1 bus, 2 trucks, 230.4ms\n",
      "Speed: 4.5ms preprocess, 230.4ms inference, 2.4ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 3 persons, 8 cars, 2 motorcycles, 1 bus, 1 truck, 268.1ms\n",
      "Speed: 4.4ms preprocess, 268.1ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 person, 6 cars, 2 motorcycles, 1 bus, 2 trucks, 245.9ms\n",
      "Speed: 5.1ms preprocess, 245.9ms inference, 2.4ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 person, 5 cars, 2 motorcycles, 1 bus, 3 trucks, 265.3ms\n",
      "Speed: 6.3ms preprocess, 265.3ms inference, 2.3ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 2 persons, 6 cars, 2 motorcycles, 1 bus, 3 trucks, 258.7ms\n",
      "Speed: 5.3ms preprocess, 258.7ms inference, 3.2ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 2 persons, 5 cars, 2 motorcycles, 1 bus, 3 trucks, 355.6ms\n",
      "Speed: 6.3ms preprocess, 355.6ms inference, 2.9ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 4 persons, 6 cars, 2 motorcycles, 2 trucks, 332.8ms\n",
      "Speed: 6.0ms preprocess, 332.8ms inference, 3.6ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 3 persons, 5 cars, 2 motorcycles, 2 trucks, 307.1ms\n",
      "Speed: 7.4ms preprocess, 307.1ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 3 persons, 7 cars, 2 motorcycles, 1 bus, 1 truck, 262.5ms\n",
      "Speed: 6.4ms preprocess, 262.5ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 4 persons, 7 cars, 2 motorcycles, 1 bus, 1 truck, 1 traffic light, 304.0ms\n",
      "Speed: 7.8ms preprocess, 304.0ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 4 persons, 6 cars, 2 motorcycles, 1 bus, 2 trucks, 1 traffic light, 262.2ms\n",
      "Speed: 6.5ms preprocess, 262.2ms inference, 2.8ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 61\u001b[0m\n\u001b[0;32m     58\u001b[0m frame \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mresize(frame, (\u001b[38;5;241m1020\u001b[39m, \u001b[38;5;241m500\u001b[39m))\n\u001b[0;32m     60\u001b[0m \u001b[38;5;66;03m# ✅ YOLO Detection\u001b[39;00m\n\u001b[1;32m---> 61\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     62\u001b[0m a \u001b[38;5;241m=\u001b[39m results[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mboxes\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[0;32m     63\u001b[0m px \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(a)\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfloat\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\ultralytics\\engine\\model.py:560\u001b[0m, in \u001b[0;36mModel.predict\u001b[1;34m(self, source, stream, predictor, **kwargs)\u001b[0m\n\u001b[0;32m    558\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m prompts \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictor, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mset_prompts\u001b[39m\u001b[38;5;124m\"\u001b[39m):  \u001b[38;5;66;03m# for SAM-type models\u001b[39;00m\n\u001b[0;32m    559\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictor\u001b[38;5;241m.\u001b[39mset_prompts(prompts)\n\u001b[1;32m--> 560\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictor\u001b[38;5;241m.\u001b[39mpredict_cli(source\u001b[38;5;241m=\u001b[39msource) \u001b[38;5;28;01mif\u001b[39;00m is_cli \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredictor\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\ultralytics\\engine\\predictor.py:175\u001b[0m, in \u001b[0;36mBasePredictor.__call__\u001b[1;34m(self, source, model, stream, *args, **kwargs)\u001b[0m\n\u001b[0;32m    173\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream_inference(source, model, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    174\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 175\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstream_inference\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\utils\\_contextlib.py:36\u001b[0m, in \u001b[0;36m_wrap_generator.<locals>.generator_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     34\u001b[0m     \u001b[38;5;66;03m# Issuing `None` to a generator fires it up\u001b[39;00m\n\u001b[0;32m     35\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[1;32m---> 36\u001b[0m         response \u001b[38;5;241m=\u001b[39m \u001b[43mgen\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     38\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m     39\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     40\u001b[0m             \u001b[38;5;66;03m# Forward the response to our caller and get its next request\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\ultralytics\\engine\\predictor.py:261\u001b[0m, in \u001b[0;36mBasePredictor.stream_inference\u001b[1;34m(self, source, model, *args, **kwargs)\u001b[0m\n\u001b[0;32m    259\u001b[0m \u001b[38;5;66;03m# Inference\u001b[39;00m\n\u001b[0;32m    260\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m profilers[\u001b[38;5;241m1\u001b[39m]:\n\u001b[1;32m--> 261\u001b[0m     preds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minference\u001b[49m\u001b[43m(\u001b[49m\u001b[43mim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    262\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39membed:\n\u001b[0;32m    263\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m [preds] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(preds, torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;28;01melse\u001b[39;00m preds  \u001b[38;5;66;03m# yield embedding tensors\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\ultralytics\\engine\\predictor.py:145\u001b[0m, in \u001b[0;36mBasePredictor.inference\u001b[1;34m(self, im, *args, **kwargs)\u001b[0m\n\u001b[0;32m    139\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Runs inference on a given image using the specified model and arguments.\"\"\"\u001b[39;00m\n\u001b[0;32m    140\u001b[0m visualize \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    141\u001b[0m     increment_path(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave_dir \u001b[38;5;241m/\u001b[39m Path(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m])\u001b[38;5;241m.\u001b[39mstem, mkdir\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    142\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mvisualize \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msource_type\u001b[38;5;241m.\u001b[39mtensor)\n\u001b[0;32m    143\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    144\u001b[0m )\n\u001b[1;32m--> 145\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maugment\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maugment\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvisualize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvisualize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\ultralytics\\nn\\autobackend.py:557\u001b[0m, in \u001b[0;36mAutoBackend.forward\u001b[1;34m(self, im, augment, visualize, embed)\u001b[0m\n\u001b[0;32m    555\u001b[0m \u001b[38;5;66;03m# PyTorch\u001b[39;00m\n\u001b[0;32m    556\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpt \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnn_module:\n\u001b[1;32m--> 557\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maugment\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maugment\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvisualize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvisualize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43membed\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    559\u001b[0m \u001b[38;5;66;03m# TorchScript\u001b[39;00m\n\u001b[0;32m    560\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjit:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\ultralytics\\nn\\tasks.py:114\u001b[0m, in \u001b[0;36mBaseModel.forward\u001b[1;34m(self, x, *args, **kwargs)\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mdict\u001b[39m):  \u001b[38;5;66;03m# for cases of training and validating while training.\u001b[39;00m\n\u001b[0;32m    113\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss(x, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m--> 114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\ultralytics\\nn\\tasks.py:132\u001b[0m, in \u001b[0;36mBaseModel.predict\u001b[1;34m(self, x, profile, visualize, augment, embed)\u001b[0m\n\u001b[0;32m    130\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m augment:\n\u001b[0;32m    131\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_predict_augment(x)\n\u001b[1;32m--> 132\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_predict_once\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprofile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvisualize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membed\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\ultralytics\\nn\\tasks.py:153\u001b[0m, in \u001b[0;36mBaseModel._predict_once\u001b[1;34m(self, x, profile, visualize, embed)\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m profile:\n\u001b[0;32m    152\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_profile_one_layer(m, x, dt)\n\u001b[1;32m--> 153\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# run\u001b[39;00m\n\u001b[0;32m    154\u001b[0m y\u001b[38;5;241m.\u001b[39mappend(x \u001b[38;5;28;01mif\u001b[39;00m m\u001b[38;5;241m.\u001b[39mi \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)  \u001b[38;5;66;03m# save output\u001b[39;00m\n\u001b[0;32m    155\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m visualize:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\ultralytics\\nn\\modules\\block.py:189\u001b[0m, in \u001b[0;36mSPPF.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    187\u001b[0m y \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcv1(x)]\n\u001b[0;32m    188\u001b[0m y\u001b[38;5;241m.\u001b[39mextend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mm(y[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]) \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m3\u001b[39m))\n\u001b[1;32m--> 189\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcv2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\ultralytics\\nn\\modules\\conv.py:55\u001b[0m, in \u001b[0;36mConv.forward_fuse\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward_fuse\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m     54\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Apply convolution and activation without batch normalization.\"\"\"\u001b[39;00m\n\u001b[1;32m---> 55\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mact(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:554\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    553\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 554\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:549\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    537\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    538\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(\n\u001b[0;32m    539\u001b[0m         F\u001b[38;5;241m.\u001b[39mpad(\n\u001b[0;32m    540\u001b[0m             \u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    547\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups,\n\u001b[0;32m    548\u001b[0m     )\n\u001b[1;32m--> 549\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    550\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\n\u001b[0;32m    551\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import pandas as pd\n",
    "from ultralytics import YOLO\n",
    "from tracker import *\n",
    "import numpy as np\n",
    "import csv\n",
    "import os\n",
    "import time\n",
    "\n",
    "# ✅ Load YOLO model\n",
    "model = YOLO('yolov8s.pt')\n",
    "\n",
    "# ✅ Object classes\n",
    "class_list = [\n",
    "    \"person\", \"bicycle\", \"car\", \"motorcycle\", \"airplane\", \"bus\", \"train\", \"truck\", \"boat\",\n",
    "    \"traffic light\", \"fire hydrant\", \"stop sign\", \"parking meter\", \"bench\", \"bird\", \"cat\",\n",
    "    \"dog\", \"horse\", \"sheep\", \"cow\", \"elephant\", \"bear\", \"zebra\", \"giraffe\", \"backpack\",\n",
    "    \"umbrella\", \"handbag\", \"tie\", \"suitcase\", \"frisbee\", \"skis\", \"snowboard\", \"sports ball\",\n",
    "    \"kite\", \"baseball bat\", \"baseball glove\", \"skateboard\", \"surfboard\", \"tennis racket\",\n",
    "    \"bottle\", \"wine glass\", \"cup\", \"fork\", \"knife\", \"spoon\", \"bowl\", \"banana\", \"apple\",\n",
    "    \"sandwich\", \"orange\", \"broccoli\", \"carrot\", \"hot dog\", \"pizza\", \"donut\", \"cake\",\n",
    "    \"chair\", \"couch\", \"potted plant\", \"bed\", \"dining table\", \"toilet\", \"TV\", \"laptop\",\n",
    "    \"mouse\", \"remote\", \"keyboard\", \"cell phone\", \"microwave\", \"oven\", \"toaster\", \"sink\",\n",
    "    \"refrigerator\", \"book\", \"clock\", \"vase\", \"scissors\", \"teddy bear\", \"hair drier\", \"toothbrush\"\n",
    "]\n",
    "\n",
    "# ✅ Initialize tracker\n",
    "tracker = Tracker()\n",
    "cap = cv2.VideoCapture('camp3_morning.MOV')\n",
    "\n",
    "# ✅ CSV File Setup\n",
    "csv_filename = \"vehicles_summary.csv\"\n",
    "\n",
    "# ✅ Create CSV file if it doesn't exist\n",
    "if not os.path.exists(csv_filename):\n",
    "    with open(csv_filename, mode=\"w\", newline=\"\") as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow([\"Timestamp\", \"Cars\", \"Buses\", \"Trucks\", \"Motorcycles\"])\n",
    "\n",
    "# ✅ Define reference lines\n",
    "red_line_y = 385\n",
    "blue_line_y = 415\n",
    "offset = 7  # Allow slight variation due to tracking jitter\n",
    "\n",
    "# ✅ Define vehicle classes to track\n",
    "vehicle_classes = [\"car\", \"bus\", \"truck\", \"motorcycle\"]\n",
    "vehicle_counts = {\"car\": 0, \"bus\": 0, \"truck\": 0, \"motorcycle\": 0}\n",
    "\n",
    "# ✅ Store vehicle IDs that crossed the red line first\n",
    "crossed_red = {}\n",
    "counter_down = []\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    frame = cv2.resize(frame, (1020, 500))\n",
    "\n",
    "    # ✅ YOLO Detection\n",
    "    results = model.predict(frame)\n",
    "    a = results[0].boxes.data.detach().cpu().numpy()\n",
    "    px = pd.DataFrame(a).astype(\"float\")\n",
    "\n",
    "    # ✅ Store detections\n",
    "    detections = []\n",
    "    detected_vehicles = {}\n",
    "\n",
    "    for _, row in px.iterrows():\n",
    "        x1, y1, x2, y2 = int(row[0]), int(row[1]), int(row[2]), int(row[3])\n",
    "        d = int(row[5])\n",
    "        vehicle_type = class_list[d]\n",
    "\n",
    "        if vehicle_type in vehicle_classes:\n",
    "            detections.append([x1, y1, x2, y2])\n",
    "            detected_vehicles[(x1, y1, x2, y2)] = vehicle_type\n",
    "\n",
    "    # ✅ Ensure 'detections' is not empty\n",
    "    bbox_id = tracker.update(np.array(detections)) if detections else []\n",
    "\n",
    "    # ✅ Process ALL detected vehicles\n",
    "    for bbox in bbox_id:\n",
    "        x3, y3, x4, y4, vehicle_id = bbox\n",
    "        cx, cy = (x3 + x4) // 2, (y3 + y4) // 2\n",
    "\n",
    "        vehicle_type = detected_vehicles.get((x3, y3, x4, y4), \"unknown\")\n",
    "\n",
    "        # ✅ Check if the vehicle crosses the RED line first\n",
    "        if red_line_y - offset < cy < red_line_y + offset:\n",
    "            crossed_red[vehicle_id] = (cy, vehicle_type)\n",
    "\n",
    "        # ✅ Only consider vehicles that crossed red before reaching blue\n",
    "        if vehicle_id in crossed_red and blue_line_y - offset < cy < blue_line_y + offset:\n",
    "            _, v_type = crossed_red[vehicle_id]\n",
    "\n",
    "            # ✅ Draw circle at the blue line for valid vehicles\n",
    "            cv2.circle(frame, (cx, cy), 4, (0, 0, 255), -1)\n",
    "            cv2.putText(frame, f\"{v_type}-{vehicle_id}\", (cx, cy), cv2.FONT_HERSHEY_COMPLEX, 0.8, (0, 255, 255), 2)\n",
    "\n",
    "            # ✅ Add to counter only once\n",
    "            if vehicle_id not in counter_down:\n",
    "                counter_down.append(vehicle_id)\n",
    "                vehicle_counts[v_type] += 1\n",
    "\n",
    "    # ✅ Draw reference lines\n",
    "    cv2.line(frame, (260, red_line_y), (724, red_line_y), (0, 0, 255), 3)\n",
    "    cv2.putText(frame, 'red line', (260, red_line_y), cv2.FONT_HERSHEY_COMPLEX, 0.5, (255, 255, 255), 1, cv2.LINE_AA)\n",
    "\n",
    "    cv2.line(frame, (200, blue_line_y), (779, blue_line_y), (255, 0, 0), 3)\n",
    "    cv2.putText(frame, 'blue line', (200, blue_line_y), cv2.FONT_HERSHEY_COMPLEX, 0.5, (255, 255, 255), 1, cv2.LINE_AA)\n",
    "\n",
    "    # ✅ Display vehicle count\n",
    "    cv2.putText(frame, f\"Cars: {vehicle_counts['car']}  Buses: {vehicle_counts['bus']}  Trucks: {vehicle_counts['truck']}  Motorcycles: {vehicle_counts['motorcycle']}\",\n",
    "                (60, 40), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 1, cv2.LINE_AA)\n",
    "\n",
    "    cv2.imshow(\"frames\", frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == 27:\n",
    "        break\n",
    "\n",
    "# ✅ Log the final vehicle count when the video ends\n",
    "timestamp = time.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "number_of_lanes=2\n",
    "# ✅ Calculate light duration using the given formula\n",
    "light_duration = ((vehicle_counts[\"car\"] * 2) + \n",
    "                  (vehicle_counts[\"motorcycle\"] * 1.8) + \n",
    "                  ((vehicle_counts[\"bus\"] + vehicle_counts[\"truck\"]) * 3.5)) / number_of_lanes\n",
    "with open(csv_filename, mode=\"a\", newline=\"\") as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow([timestamp, vehicle_counts[\"car\"], vehicle_counts[\"bus\"], vehicle_counts[\"truck\"], vehicle_counts[\"motorcycle\"], round(light_duration, 2)])\n",
    "\n",
    "print(f\"✅ Final vehicle count saved to CSV: {vehicle_counts}, Light Duration: {round(light_duration, 2)} sec\")\n",
    "\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0ce3819-05e0-491c-9ed0-8a26ce446095",
   "metadata": {},
   "source": [
    "# Noon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f5eb2edf-4708-4cde-b15f-b0d328138b79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 320x640 1 person, 7 cars, 1 motorcycle, 2 trucks, 406.0ms\n",
      "Speed: 5.8ms preprocess, 406.0ms inference, 2.3ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 person, 7 cars, 2 motorcycles, 1 truck, 227.5ms\n",
      "Speed: 4.3ms preprocess, 227.5ms inference, 2.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 person, 7 cars, 2 motorcycles, 221.5ms\n",
      "Speed: 5.4ms preprocess, 221.5ms inference, 2.1ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 person, 6 cars, 2 motorcycles, 1 truck, 228.2ms\n",
      "Speed: 3.3ms preprocess, 228.2ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 person, 8 cars, 2 motorcycles, 1 bus, 1 truck, 243.0ms\n",
      "Speed: 4.6ms preprocess, 243.0ms inference, 2.9ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 person, 7 cars, 1 motorcycle, 1 truck, 268.4ms\n",
      "Speed: 5.6ms preprocess, 268.4ms inference, 3.6ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 person, 8 cars, 1 motorcycle, 1 truck, 289.0ms\n",
      "Speed: 5.8ms preprocess, 289.0ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 person, 9 cars, 1 motorcycle, 284.2ms\n",
      "Speed: 6.5ms preprocess, 284.2ms inference, 3.1ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 person, 8 cars, 1 motorcycle, 328.2ms\n",
      "Speed: 6.7ms preprocess, 328.2ms inference, 3.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 person, 8 cars, 1 motorcycle, 318.0ms\n",
      "Speed: 7.0ms preprocess, 318.0ms inference, 3.5ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 person, 7 cars, 1 motorcycle, 320.2ms\n",
      "Speed: 5.8ms preprocess, 320.2ms inference, 3.7ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 person, 6 cars, 329.8ms\n",
      "Speed: 4.7ms preprocess, 329.8ms inference, 3.2ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 person, 5 cars, 2 motorcycles, 336.6ms\n",
      "Speed: 5.0ms preprocess, 336.6ms inference, 3.7ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 person, 4 cars, 1 motorcycle, 300.7ms\n",
      "Speed: 7.6ms preprocess, 300.7ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 4 cars, 1 motorcycle, 1 truck, 289.4ms\n",
      "Speed: 7.1ms preprocess, 289.4ms inference, 3.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 person, 6 cars, 1 motorcycle, 2 trucks, 267.7ms\n",
      "Speed: 7.5ms preprocess, 267.7ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 person, 6 cars, 1 motorcycle, 259.8ms\n",
      "Speed: 5.7ms preprocess, 259.8ms inference, 2.3ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 person, 8 cars, 1 motorcycle, 239.5ms\n",
      "Speed: 5.8ms preprocess, 239.5ms inference, 2.4ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 person, 6 cars, 2 motorcycles, 253.6ms\n",
      "Speed: 6.5ms preprocess, 253.6ms inference, 2.3ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 person, 5 cars, 1 motorcycle, 1 truck, 250.0ms\n",
      "Speed: 5.1ms preprocess, 250.0ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 person, 5 cars, 2 motorcycles, 277.7ms\n",
      "Speed: 5.7ms preprocess, 277.7ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 person, 5 cars, 2 motorcycles, 1 truck, 327.5ms\n",
      "Speed: 5.3ms preprocess, 327.5ms inference, 2.4ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 person, 6 cars, 2 motorcycles, 1 truck, 273.1ms\n",
      "Speed: 5.1ms preprocess, 273.1ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 person, 6 cars, 2 motorcycles, 1 truck, 284.6ms\n",
      "Speed: 5.1ms preprocess, 284.6ms inference, 3.2ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 person, 5 cars, 2 motorcycles, 1 truck, 293.4ms\n",
      "Speed: 6.4ms preprocess, 293.4ms inference, 2.4ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 person, 5 cars, 2 motorcycles, 1 truck, 307.1ms\n",
      "Speed: 5.8ms preprocess, 307.1ms inference, 3.2ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 person, 5 cars, 1 motorcycle, 2 trucks, 341.7ms\n",
      "Speed: 6.0ms preprocess, 341.7ms inference, 3.7ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 person, 6 cars, 1 truck, 355.2ms\n",
      "Speed: 6.4ms preprocess, 355.2ms inference, 2.4ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 person, 5 cars, 4 motorcycles, 1 truck, 311.0ms\n",
      "Speed: 7.6ms preprocess, 311.0ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 2 persons, 5 cars, 3 motorcycles, 2 trucks, 331.6ms\n",
      "Speed: 6.2ms preprocess, 331.6ms inference, 2.3ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 2 persons, 5 cars, 3 motorcycles, 2 trucks, 291.6ms\n",
      "Speed: 7.4ms preprocess, 291.6ms inference, 4.2ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 2 persons, 6 cars, 2 motorcycles, 1 truck, 285.1ms\n",
      "Speed: 7.5ms preprocess, 285.1ms inference, 3.9ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 2 persons, 5 cars, 2 motorcycles, 1 truck, 281.1ms\n",
      "Speed: 6.8ms preprocess, 281.1ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 3 persons, 5 cars, 3 motorcycles, 2 trucks, 351.5ms\n",
      "Speed: 6.4ms preprocess, 351.5ms inference, 2.8ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 2 persons, 5 cars, 2 motorcycles, 2 trucks, 412.1ms\n",
      "Speed: 7.4ms preprocess, 412.1ms inference, 3.5ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 2 persons, 6 cars, 1 motorcycle, 2 trucks, 386.3ms\n",
      "Speed: 3.3ms preprocess, 386.3ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 2 persons, 5 cars, 2 motorcycles, 2 trucks, 242.6ms\n",
      "Speed: 5.1ms preprocess, 242.6ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 4 persons, 5 cars, 2 motorcycles, 1 truck, 267.0ms\n",
      "Speed: 5.8ms preprocess, 267.0ms inference, 3.1ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 2 persons, 5 cars, 2 motorcycles, 1 truck, 323.4ms\n",
      "Speed: 7.6ms preprocess, 323.4ms inference, 2.8ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 2 persons, 6 cars, 2 motorcycles, 2 trucks, 285.5ms\n",
      "Speed: 5.7ms preprocess, 285.5ms inference, 2.4ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 person, 6 cars, 2 motorcycles, 3 trucks, 308.3ms\n",
      "Speed: 5.4ms preprocess, 308.3ms inference, 3.5ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 2 persons, 4 cars, 3 motorcycles, 3 trucks, 1 umbrella, 427.5ms\n",
      "Speed: 5.3ms preprocess, 427.5ms inference, 8.4ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 2 persons, 4 cars, 3 motorcycles, 3 trucks, 1 umbrella, 319.8ms\n",
      "Speed: 7.2ms preprocess, 319.8ms inference, 5.8ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 2 persons, 5 cars, 2 motorcycles, 2 trucks, 1 umbrella, 337.5ms\n",
      "Speed: 8.9ms preprocess, 337.5ms inference, 3.2ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 2 persons, 5 cars, 2 motorcycles, 3 trucks, 485.3ms\n",
      "Speed: 116.4ms preprocess, 485.3ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 2 persons, 5 cars, 3 motorcycles, 2 trucks, 324.9ms\n",
      "Speed: 7.9ms preprocess, 324.9ms inference, 3.2ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 3 persons, 5 cars, 2 motorcycles, 2 trucks, 301.5ms\n",
      "Speed: 5.8ms preprocess, 301.5ms inference, 2.3ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 2 persons, 5 cars, 2 motorcycles, 1 truck, 402.7ms\n",
      "Speed: 5.6ms preprocess, 402.7ms inference, 3.8ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 3 persons, 5 cars, 2 motorcycles, 1 truck, 272.5ms\n",
      "Speed: 7.3ms preprocess, 272.5ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 2 persons, 5 cars, 1 motorcycle, 268.0ms\n",
      "Speed: 12.3ms preprocess, 268.0ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 2 persons, 5 cars, 2 motorcycles, 545.4ms\n",
      "Speed: 7.2ms preprocess, 545.4ms inference, 3.8ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 3 persons, 5 cars, 2 motorcycles, 281.6ms\n",
      "Speed: 5.8ms preprocess, 281.6ms inference, 2.8ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 2 persons, 5 cars, 1 motorcycle, 258.5ms\n",
      "Speed: 5.4ms preprocess, 258.5ms inference, 2.4ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 2 persons, 5 cars, 1 motorcycle, 382.6ms\n",
      "Speed: 6.2ms preprocess, 382.6ms inference, 3.3ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 3 persons, 5 cars, 2 motorcycles, 350.3ms\n",
      "Speed: 9.2ms preprocess, 350.3ms inference, 2.9ms postprocess per image at shape (1, 3, 320, 640)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 118\u001b[0m\n\u001b[0;32m    113\u001b[0m     cv2\u001b[38;5;241m.\u001b[39mputText(frame, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCars: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvehicle_counts[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcar\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m  Buses: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvehicle_counts[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbus\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m  Trucks: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvehicle_counts[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtruck\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m  Motorcycles: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvehicle_counts[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmotorcycle\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    114\u001b[0m                 (\u001b[38;5;241m60\u001b[39m, \u001b[38;5;241m40\u001b[39m), cv2\u001b[38;5;241m.\u001b[39mFONT_HERSHEY_SIMPLEX, \u001b[38;5;241m0.5\u001b[39m, (\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m255\u001b[39m, \u001b[38;5;241m0\u001b[39m), \u001b[38;5;241m1\u001b[39m, cv2\u001b[38;5;241m.\u001b[39mLINE_AA)\n\u001b[0;32m    116\u001b[0m     cv2\u001b[38;5;241m.\u001b[39mimshow(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mframes\u001b[39m\u001b[38;5;124m\"\u001b[39m, frame)\n\u001b[1;32m--> 118\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwaitKey\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;241m&\u001b[39m \u001b[38;5;241m0xFF\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m27\u001b[39m:\n\u001b[0;32m    119\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m    121\u001b[0m \u001b[38;5;66;03m# ✅ Log the final vehicle count when the video ends\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import pandas as pd\n",
    "from ultralytics import YOLO\n",
    "from tracker import *\n",
    "import numpy as np\n",
    "import csv\n",
    "import os\n",
    "import time\n",
    "\n",
    "# ✅ Load YOLO model\n",
    "model = YOLO('yolov8s.pt')\n",
    "\n",
    "# ✅ Object classes\n",
    "class_list = [\n",
    "    \"person\", \"bicycle\", \"car\", \"motorcycle\", \"airplane\", \"bus\", \"train\", \"truck\", \"boat\",\n",
    "    \"traffic light\", \"fire hydrant\", \"stop sign\", \"parking meter\", \"bench\", \"bird\", \"cat\",\n",
    "    \"dog\", \"horse\", \"sheep\", \"cow\", \"elephant\", \"bear\", \"zebra\", \"giraffe\", \"backpack\",\n",
    "    \"umbrella\", \"handbag\", \"tie\", \"suitcase\", \"frisbee\", \"skis\", \"snowboard\", \"sports ball\",\n",
    "    \"kite\", \"baseball bat\", \"baseball glove\", \"skateboard\", \"surfboard\", \"tennis racket\",\n",
    "    \"bottle\", \"wine glass\", \"cup\", \"fork\", \"knife\", \"spoon\", \"bowl\", \"banana\", \"apple\",\n",
    "    \"sandwich\", \"orange\", \"broccoli\", \"carrot\", \"hot dog\", \"pizza\", \"donut\", \"cake\",\n",
    "    \"chair\", \"couch\", \"potted plant\", \"bed\", \"dining table\", \"toilet\", \"TV\", \"laptop\",\n",
    "    \"mouse\", \"remote\", \"keyboard\", \"cell phone\", \"microwave\", \"oven\", \"toaster\", \"sink\",\n",
    "    \"refrigerator\", \"book\", \"clock\", \"vase\", \"scissors\", \"teddy bear\", \"hair drier\", \"toothbrush\"\n",
    "]\n",
    "\n",
    "# ✅ Initialize tracker\n",
    "tracker = Tracker()\n",
    "cap = cv2.VideoCapture('IMG_8980.MOV')\n",
    "\n",
    "# ✅ CSV File Setup\n",
    "csv_filename = \"vehicles_summary.csv\"\n",
    "\n",
    "# ✅ Create CSV file if it doesn't exist\n",
    "if not os.path.exists(csv_filename):\n",
    "    with open(csv_filename, mode=\"w\", newline=\"\") as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow([\"Timestamp\", \"Cars\", \"Buses\", \"Trucks\", \"Motorcycles\"])\n",
    "\n",
    "# ✅ Define reference lines\n",
    "red_line_y = 338\n",
    "blue_line_y = 380\n",
    "offset = 7  # Allow slight variation due to tracking jitter\n",
    "\n",
    "# ✅ Define vehicle classes to track\n",
    "vehicle_classes = [\"car\", \"bus\", \"truck\", \"motorcycle\"]\n",
    "vehicle_counts = {\"car\": 0, \"bus\": 0, \"truck\": 0, \"motorcycle\": 0}\n",
    "\n",
    "# ✅ Store vehicle IDs that crossed the red line first\n",
    "crossed_red = {}\n",
    "counter_down = []\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    frame = cv2.resize(frame, (1020, 500))\n",
    "\n",
    "    # ✅ YOLO Detection\n",
    "    results = model.predict(frame)\n",
    "    a = results[0].boxes.data.detach().cpu().numpy()\n",
    "    px = pd.DataFrame(a).astype(\"float\")\n",
    "\n",
    "    # ✅ Store detections\n",
    "    detections = []\n",
    "    detected_vehicles = {}\n",
    "\n",
    "    for _, row in px.iterrows():\n",
    "        x1, y1, x2, y2 = int(row[0]), int(row[1]), int(row[2]), int(row[3])\n",
    "        d = int(row[5])\n",
    "        vehicle_type = class_list[d]\n",
    "\n",
    "        if vehicle_type in vehicle_classes:\n",
    "            detections.append([x1, y1, x2, y2])\n",
    "            detected_vehicles[(x1, y1, x2, y2)] = vehicle_type\n",
    "\n",
    "    # ✅ Ensure 'detections' is not empty\n",
    "    bbox_id = tracker.update(np.array(detections)) if detections else []\n",
    "\n",
    "    # ✅ Process ALL detected vehicles\n",
    "    for bbox in bbox_id:\n",
    "        x3, y3, x4, y4, vehicle_id = bbox\n",
    "        cx, cy = (x3 + x4) // 2, (y3 + y4) // 2\n",
    "\n",
    "        vehicle_type = detected_vehicles.get((x3, y3, x4, y4), \"unknown\")\n",
    "\n",
    "        # ✅ Check if the vehicle crosses the RED line first\n",
    "        if red_line_y - offset < cy < red_line_y + offset:\n",
    "            crossed_red[vehicle_id] = (cy, vehicle_type)\n",
    "\n",
    "        # ✅ Only consider vehicles that crossed red before reaching blue\n",
    "        if vehicle_id in crossed_red and blue_line_y - offset < cy < blue_line_y + offset:\n",
    "            _, v_type = crossed_red[vehicle_id]\n",
    "\n",
    "            # ✅ Draw circle at the blue line for valid vehicles\n",
    "            cv2.circle(frame, (cx, cy), 4, (0, 0, 255), -1)\n",
    "            cv2.putText(frame, f\"{v_type}-{vehicle_id}\", (cx, cy), cv2.FONT_HERSHEY_COMPLEX, 0.8, (0, 255, 255), 2)\n",
    "\n",
    "            # ✅ Add to counter only once\n",
    "            if vehicle_id not in counter_down:\n",
    "                counter_down.append(vehicle_id)\n",
    "                vehicle_counts[v_type] += 1\n",
    "\n",
    "    # ✅ Draw reference lines\n",
    "    cv2.line(frame, (260, red_line_y), (724, red_line_y), (0, 0, 255), 3)\n",
    "    cv2.putText(frame, 'red line', (260, red_line_y), cv2.FONT_HERSHEY_COMPLEX, 0.5, (255, 255, 255), 1, cv2.LINE_AA)\n",
    "\n",
    "    cv2.line(frame, (200, blue_line_y), (779, blue_line_y), (255, 0, 0), 3)\n",
    "    cv2.putText(frame, 'blue line', (200, blue_line_y), cv2.FONT_HERSHEY_COMPLEX, 0.5, (255, 255, 255), 1, cv2.LINE_AA)\n",
    "\n",
    "    # ✅ Display vehicle count\n",
    "    cv2.putText(frame, f\"Cars: {vehicle_counts['car']}  Buses: {vehicle_counts['bus']}  Trucks: {vehicle_counts['truck']}  Motorcycles: {vehicle_counts['motorcycle']}\",\n",
    "                (60, 40), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 1, cv2.LINE_AA)\n",
    "\n",
    "    cv2.imshow(\"frames\", frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == 27:\n",
    "        break\n",
    "\n",
    "# ✅ Log the final vehicle count when the video ends\n",
    "timestamp = time.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "number_of_lanes=2\n",
    "# ✅ Calculate light duration using the given formula\n",
    "light_duration = ((vehicle_counts[\"car\"] * 2) + \n",
    "                  (vehicle_counts[\"motorcycle\"] * 1.8) + \n",
    "                  ((vehicle_counts[\"bus\"] + vehicle_counts[\"truck\"]) * 3.5)) / number_of_lanes\n",
    "with open(csv_filename, mode=\"a\", newline=\"\") as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow([timestamp, vehicle_counts[\"car\"], vehicle_counts[\"bus\"], vehicle_counts[\"truck\"], vehicle_counts[\"motorcycle\"], round(light_duration, 2)])\n",
    "\n",
    "print(f\"✅ Final vehicle count saved to CSV: {vehicle_counts}, Light Duration: {round(light_duration, 2)} sec\")\n",
    "\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13482129-58fe-4ac7-99fa-3828606e98bd",
   "metadata": {},
   "source": [
    "# Rain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7422a5b7-9e92-442d-bf1a-75f7a00d35a0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 320x640 4 persons, 6 cars, 3 motorcycles, 3 trucks, 237.9ms\n",
      "Speed: 5.4ms preprocess, 237.9ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 3 persons, 4 cars, 3 motorcycles, 3 trucks, 1 umbrella, 240.7ms\n",
      "Speed: 6.1ms preprocess, 240.7ms inference, 2.8ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 3 persons, 4 cars, 3 motorcycles, 3 trucks, 1 umbrella, 239.6ms\n",
      "Speed: 3.7ms preprocess, 239.6ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 3 persons, 6 cars, 3 motorcycles, 1 bus, 3 trucks, 1 umbrella, 225.2ms\n",
      "Speed: 2.9ms preprocess, 225.2ms inference, 2.4ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 4 persons, 6 cars, 3 motorcycles, 1 bus, 2 trucks, 1 umbrella, 218.0ms\n",
      "Speed: 3.6ms preprocess, 218.0ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 3 persons, 6 cars, 2 motorcycles, 3 trucks, 1 umbrella, 228.0ms\n",
      "Speed: 2.8ms preprocess, 228.0ms inference, 2.3ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 4 persons, 7 cars, 2 motorcycles, 1 bus, 3 trucks, 1 umbrella, 224.7ms\n",
      "Speed: 4.5ms preprocess, 224.7ms inference, 2.1ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 5 persons, 7 cars, 2 motorcycles, 1 bus, 1 truck, 1 umbrella, 225.1ms\n",
      "Speed: 4.0ms preprocess, 225.1ms inference, 2.4ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 4 persons, 7 cars, 2 motorcycles, 1 bus, 2 trucks, 1 umbrella, 218.4ms\n",
      "Speed: 3.4ms preprocess, 218.4ms inference, 2.9ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 4 persons, 6 cars, 3 motorcycles, 2 buss, 1 truck, 369.4ms\n",
      "Speed: 6.0ms preprocess, 369.4ms inference, 2.4ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 5 persons, 6 cars, 3 motorcycles, 3 trucks, 216.6ms\n",
      "Speed: 3.9ms preprocess, 216.6ms inference, 1.6ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 4 persons, 8 cars, 3 motorcycles, 1 truck, 229.9ms\n",
      "Speed: 3.6ms preprocess, 229.9ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 2 persons, 9 cars, 4 motorcycles, 1 bus, 1 truck, 237.0ms\n",
      "Speed: 4.1ms preprocess, 237.0ms inference, 2.8ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 3 persons, 9 cars, 4 motorcycles, 1 bus, 2 trucks, 223.0ms\n",
      "Speed: 3.8ms preprocess, 223.0ms inference, 1.9ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 4 persons, 8 cars, 4 motorcycles, 2 buss, 2 trucks, 213.7ms\n",
      "Speed: 3.7ms preprocess, 213.7ms inference, 2.4ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 4 persons, 8 cars, 2 motorcycles, 1 bus, 2 trucks, 223.7ms\n",
      "Speed: 3.7ms preprocess, 223.7ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 3 persons, 9 cars, 4 motorcycles, 2 buss, 2 trucks, 218.2ms\n",
      "Speed: 2.8ms preprocess, 218.2ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 4 persons, 9 cars, 4 motorcycles, 2 buss, 1 truck, 220.7ms\n",
      "Speed: 4.8ms preprocess, 220.7ms inference, 2.8ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 3 persons, 9 cars, 4 motorcycles, 1 bus, 3 trucks, 237.2ms\n",
      "Speed: 3.7ms preprocess, 237.2ms inference, 2.8ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 4 persons, 8 cars, 4 motorcycles, 1 bus, 1 truck, 272.5ms\n",
      "Speed: 5.4ms preprocess, 272.5ms inference, 2.9ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 4 persons, 8 cars, 4 motorcycles, 1 bus, 3 trucks, 271.2ms\n",
      "Speed: 3.4ms preprocess, 271.2ms inference, 2.8ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 4 persons, 8 cars, 4 motorcycles, 3 trucks, 267.4ms\n",
      "Speed: 9.9ms preprocess, 267.4ms inference, 2.2ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 4 persons, 9 cars, 4 motorcycles, 1 bus, 3 trucks, 229.3ms\n",
      "Speed: 3.9ms preprocess, 229.3ms inference, 2.3ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 4 persons, 8 cars, 4 motorcycles, 1 bus, 3 trucks, 414.2ms\n",
      "Speed: 6.9ms preprocess, 414.2ms inference, 2.9ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 4 persons, 7 cars, 5 motorcycles, 1 bus, 3 trucks, 284.1ms\n",
      "Speed: 4.3ms preprocess, 284.1ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 5 persons, 7 cars, 4 motorcycles, 1 bus, 1 truck, 294.5ms\n",
      "Speed: 3.8ms preprocess, 294.5ms inference, 2.2ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 4 persons, 9 cars, 4 motorcycles, 1 truck, 265.5ms\n",
      "Speed: 6.2ms preprocess, 265.5ms inference, 1.9ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 4 persons, 6 cars, 4 motorcycles, 1 bus, 1 truck, 242.6ms\n",
      "Speed: 3.8ms preprocess, 242.6ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 3 persons, 6 cars, 4 motorcycles, 1 bus, 1 truck, 240.7ms\n",
      "Speed: 3.4ms preprocess, 240.7ms inference, 2.3ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 4 persons, 6 cars, 4 motorcycles, 1 truck, 249.6ms\n",
      "Speed: 3.2ms preprocess, 249.6ms inference, 2.4ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 5 persons, 6 cars, 5 motorcycles, 1 truck, 221.4ms\n",
      "Speed: 3.1ms preprocess, 221.4ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 5 persons, 6 cars, 4 motorcycles, 1 truck, 236.7ms\n",
      "Speed: 6.0ms preprocess, 236.7ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 5 persons, 6 cars, 5 motorcycles, 2 trucks, 237.0ms\n",
      "Speed: 4.8ms preprocess, 237.0ms inference, 2.3ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 4 persons, 7 cars, 5 motorcycles, 2 trucks, 249.6ms\n",
      "Speed: 6.4ms preprocess, 249.6ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 4 persons, 9 cars, 4 motorcycles, 2 trucks, 278.2ms\n",
      "Speed: 6.2ms preprocess, 278.2ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 2 persons, 8 cars, 4 motorcycles, 1 truck, 294.8ms\n",
      "Speed: 4.8ms preprocess, 294.8ms inference, 2.4ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 4 persons, 6 cars, 5 motorcycles, 1 truck, 263.5ms\n",
      "Speed: 5.7ms preprocess, 263.5ms inference, 2.9ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 5 persons, 6 cars, 5 motorcycles, 1 truck, 330.4ms\n",
      "Speed: 7.9ms preprocess, 330.4ms inference, 3.1ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 7 persons, 5 cars, 4 motorcycles, 1 truck, 305.2ms\n",
      "Speed: 13.5ms preprocess, 305.2ms inference, 3.9ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 6 persons, 7 cars, 5 motorcycles, 1 truck, 324.1ms\n",
      "Speed: 9.1ms preprocess, 324.1ms inference, 4.8ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 7 persons, 5 cars, 3 motorcycles, 1 truck, 368.8ms\n",
      "Speed: 6.7ms preprocess, 368.8ms inference, 3.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 8 persons, 6 cars, 4 motorcycles, 1 truck, 302.3ms\n",
      "Speed: 41.6ms preprocess, 302.3ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 6 persons, 6 cars, 3 motorcycles, 1 truck, 317.1ms\n",
      "Speed: 7.4ms preprocess, 317.1ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 5 persons, 6 cars, 5 motorcycles, 1 truck, 239.8ms\n",
      "Speed: 8.0ms preprocess, 239.8ms inference, 2.4ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 4 persons, 8 cars, 3 motorcycles, 1 truck, 289.1ms\n",
      "Speed: 7.3ms preprocess, 289.1ms inference, 4.3ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 6 persons, 7 cars, 3 motorcycles, 1 truck, 308.2ms\n",
      "Speed: 7.7ms preprocess, 308.2ms inference, 3.3ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 4 persons, 6 cars, 3 motorcycles, 1 truck, 302.2ms\n",
      "Speed: 8.5ms preprocess, 302.2ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 3 persons, 8 cars, 2 motorcycles, 1 truck, 239.9ms\n",
      "Speed: 7.4ms preprocess, 239.9ms inference, 2.4ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 5 persons, 7 cars, 2 motorcycles, 2 trucks, 275.6ms\n",
      "Speed: 5.8ms preprocess, 275.6ms inference, 3.2ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 4 persons, 7 cars, 3 motorcycles, 1 truck, 259.4ms\n",
      "Speed: 8.1ms preprocess, 259.4ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 4 persons, 6 cars, 3 motorcycles, 1 truck, 254.3ms\n",
      "Speed: 7.2ms preprocess, 254.3ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 3 persons, 6 cars, 2 motorcycles, 1 truck, 238.6ms\n",
      "Speed: 6.2ms preprocess, 238.6ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 3 persons, 8 cars, 2 motorcycles, 1 truck, 241.0ms\n",
      "Speed: 6.8ms preprocess, 241.0ms inference, 2.4ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 3 persons, 7 cars, 1 motorcycle, 1 truck, 256.3ms\n",
      "Speed: 5.8ms preprocess, 256.3ms inference, 2.9ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 3 persons, 8 cars, 2 motorcycles, 1 truck, 270.5ms\n",
      "Speed: 6.9ms preprocess, 270.5ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 4 persons, 8 cars, 1 motorcycle, 1 truck, 310.9ms\n",
      "Speed: 7.5ms preprocess, 310.9ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 4 persons, 8 cars, 2 motorcycles, 1 truck, 298.2ms\n",
      "Speed: 5.2ms preprocess, 298.2ms inference, 3.4ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 3 persons, 7 cars, 2 motorcycles, 1 truck, 302.4ms\n",
      "Speed: 5.1ms preprocess, 302.4ms inference, 2.8ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 4 persons, 8 cars, 2 motorcycles, 1 truck, 294.3ms\n",
      "Speed: 19.1ms preprocess, 294.3ms inference, 2.4ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 4 persons, 7 cars, 2 motorcycles, 2 trucks, 455.1ms\n",
      "Speed: 4.8ms preprocess, 455.1ms inference, 4.5ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 3 persons, 7 cars, 2 motorcycles, 1 truck, 1 umbrella, 457.7ms\n",
      "Speed: 13.4ms preprocess, 457.7ms inference, 3.5ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 3 persons, 9 cars, 2 motorcycles, 1 truck, 1 umbrella, 241.1ms\n",
      "Speed: 6.0ms preprocess, 241.1ms inference, 2.4ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 3 persons, 8 cars, 2 motorcycles, 1 truck, 1 umbrella, 229.2ms\n",
      "Speed: 5.9ms preprocess, 229.2ms inference, 3.1ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 5 persons, 6 cars, 3 motorcycles, 1 truck, 1 umbrella, 240.1ms\n",
      "Speed: 5.4ms preprocess, 240.1ms inference, 3.3ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 5 persons, 8 cars, 3 motorcycles, 1 truck, 1 umbrella, 235.9ms\n",
      "Speed: 5.5ms preprocess, 235.9ms inference, 2.8ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 4 persons, 7 cars, 2 motorcycles, 1 truck, 1 umbrella, 240.4ms\n",
      "Speed: 5.4ms preprocess, 240.4ms inference, 2.8ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 5 persons, 8 cars, 1 motorcycle, 1 truck, 1 umbrella, 230.6ms\n",
      "Speed: 5.4ms preprocess, 230.6ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 3 persons, 5 cars, 4 motorcycles, 1 truck, 1 umbrella, 247.7ms\n",
      "Speed: 5.4ms preprocess, 247.7ms inference, 3.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 2 persons, 5 cars, 4 motorcycles, 1 truck, 1 umbrella, 258.0ms\n",
      "Speed: 5.2ms preprocess, 258.0ms inference, 2.9ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 4 persons, 7 cars, 4 motorcycles, 2 trucks, 1 umbrella, 228.4ms\n",
      "Speed: 5.5ms preprocess, 228.4ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 2 persons, 6 cars, 3 motorcycles, 1 truck, 237.2ms\n",
      "Speed: 6.0ms preprocess, 237.2ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 3 persons, 6 cars, 3 motorcycles, 1 truck, 1 umbrella, 220.3ms\n",
      "Speed: 5.1ms preprocess, 220.3ms inference, 2.4ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 3 persons, 7 cars, 3 motorcycles, 1 truck, 1 umbrella, 222.3ms\n",
      "Speed: 5.3ms preprocess, 222.3ms inference, 2.4ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 2 persons, 6 cars, 3 motorcycles, 1 truck, 1 umbrella, 238.1ms\n",
      "Speed: 5.4ms preprocess, 238.1ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 3 persons, 6 cars, 3 motorcycles, 2 trucks, 1 umbrella, 385.0ms\n",
      "Speed: 104.4ms preprocess, 385.0ms inference, 3.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 5 persons, 6 cars, 3 motorcycles, 1 bus, 2 trucks, 1 umbrella, 286.5ms\n",
      "Speed: 5.1ms preprocess, 286.5ms inference, 2.9ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 4 persons, 7 cars, 4 motorcycles, 1 bus, 2 trucks, 1 umbrella, 274.1ms\n",
      "Speed: 5.1ms preprocess, 274.1ms inference, 2.9ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 3 persons, 7 cars, 3 motorcycles, 1 bus, 3 trucks, 276.1ms\n",
      "Speed: 5.6ms preprocess, 276.1ms inference, 2.8ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 3 persons, 8 cars, 2 motorcycles, 1 bus, 2 trucks, 286.8ms\n",
      "Speed: 6.1ms preprocess, 286.8ms inference, 2.8ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 4 persons, 8 cars, 2 motorcycles, 1 bus, 2 trucks, 279.4ms\n",
      "Speed: 5.1ms preprocess, 279.4ms inference, 3.4ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 4 persons, 7 cars, 1 motorcycle, 2 trucks, 385.2ms\n",
      "Speed: 7.7ms preprocess, 385.2ms inference, 3.2ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 4 persons, 8 cars, 1 motorcycle, 1 bus, 2 trucks, 302.0ms\n",
      "Speed: 7.0ms preprocess, 302.0ms inference, 2.8ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 4 persons, 6 cars, 1 motorcycle, 1 bus, 2 trucks, 283.6ms\n",
      "Speed: 6.3ms preprocess, 283.6ms inference, 3.3ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 5 persons, 3 cars, 1 motorcycle, 1 bus, 2 trucks, 285.9ms\n",
      "Speed: 7.3ms preprocess, 285.9ms inference, 2.9ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 4 persons, 5 cars, 1 motorcycle, 1 bus, 1 truck, 287.4ms\n",
      "Speed: 8.2ms preprocess, 287.4ms inference, 3.4ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 6 persons, 5 cars, 1 motorcycle, 1 bus, 1 truck, 462.1ms\n",
      "Speed: 3.9ms preprocess, 462.1ms inference, 3.3ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 4 persons, 4 cars, 1 motorcycle, 1 bus, 1 truck, 429.2ms\n",
      "Speed: 7.0ms preprocess, 429.2ms inference, 4.2ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 4 persons, 4 cars, 1 motorcycle, 2 trucks, 524.7ms\n",
      "Speed: 7.0ms preprocess, 524.7ms inference, 3.1ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 5 persons, 4 cars, 1 motorcycle, 1 truck, 412.9ms\n",
      "Speed: 6.8ms preprocess, 412.9ms inference, 4.5ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 5 persons, 4 cars, 1 motorcycle, 1 truck, 347.5ms\n",
      "Speed: 4.2ms preprocess, 347.5ms inference, 3.3ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 5 persons, 4 cars, 1 motorcycle, 2 trucks, 374.9ms\n",
      "Speed: 6.4ms preprocess, 374.9ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 4 persons, 4 cars, 1 motorcycle, 2 trucks, 334.0ms\n",
      "Speed: 6.9ms preprocess, 334.0ms inference, 5.5ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 4 persons, 4 cars, 1 motorcycle, 2 trucks, 297.2ms\n",
      "Speed: 8.4ms preprocess, 297.2ms inference, 3.5ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 4 persons, 5 cars, 1 motorcycle, 2 trucks, 337.6ms\n",
      "Speed: 6.5ms preprocess, 337.6ms inference, 3.2ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 4 persons, 6 cars, 1 motorcycle, 2 trucks, 368.8ms\n",
      "Speed: 5.5ms preprocess, 368.8ms inference, 7.6ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 3 persons, 8 cars, 1 motorcycle, 2 trucks, 362.9ms\n",
      "Speed: 7.1ms preprocess, 362.9ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 4 persons, 7 cars, 1 motorcycle, 2 trucks, 341.8ms\n",
      "Speed: 5.1ms preprocess, 341.8ms inference, 4.1ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 4 persons, 9 cars, 1 motorcycle, 2 trucks, 353.7ms\n",
      "Speed: 5.6ms preprocess, 353.7ms inference, 3.4ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 3 persons, 7 cars, 1 motorcycle, 1 truck, 349.2ms\n",
      "Speed: 10.2ms preprocess, 349.2ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 3 persons, 9 cars, 1 motorcycle, 1 truck, 315.9ms\n",
      "Speed: 6.8ms preprocess, 315.9ms inference, 3.8ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 4 persons, 9 cars, 1 motorcycle, 1 truck, 315.2ms\n",
      "Speed: 5.7ms preprocess, 315.2ms inference, 2.8ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 4 persons, 8 cars, 1 motorcycle, 2 trucks, 329.3ms\n",
      "Speed: 6.3ms preprocess, 329.3ms inference, 3.3ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 5 persons, 7 cars, 2 motorcycles, 1 truck, 294.1ms\n",
      "Speed: 6.3ms preprocess, 294.1ms inference, 2.3ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 6 persons, 8 cars, 1 motorcycle, 2 trucks, 301.1ms\n",
      "Speed: 5.8ms preprocess, 301.1ms inference, 2.4ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 5 persons, 8 cars, 1 motorcycle, 1 truck, 295.4ms\n",
      "Speed: 7.7ms preprocess, 295.4ms inference, 3.1ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 6 persons, 8 cars, 2 motorcycles, 1 truck, 320.2ms\n",
      "Speed: 5.9ms preprocess, 320.2ms inference, 3.1ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 6 persons, 7 cars, 1 motorcycle, 2 trucks, 270.0ms\n",
      "Speed: 5.5ms preprocess, 270.0ms inference, 2.9ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 6 persons, 7 cars, 2 motorcycles, 2 trucks, 312.9ms\n",
      "Speed: 7.0ms preprocess, 312.9ms inference, 2.8ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 6 persons, 7 cars, 2 motorcycles, 2 trucks, 254.2ms\n",
      "Speed: 5.5ms preprocess, 254.2ms inference, 2.8ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 5 persons, 8 cars, 1 motorcycle, 2 trucks, 300.2ms\n",
      "Speed: 6.6ms preprocess, 300.2ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 5 persons, 9 cars, 1 motorcycle, 1 truck, 336.5ms\n",
      "Speed: 6.9ms preprocess, 336.5ms inference, 3.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 4 persons, 8 cars, 1 motorcycle, 1 truck, 276.1ms\n",
      "Speed: 5.9ms preprocess, 276.1ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 5 persons, 9 cars, 2 motorcycles, 2 trucks, 305.1ms\n",
      "Speed: 5.3ms preprocess, 305.1ms inference, 2.8ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 5 persons, 6 cars, 2 motorcycles, 2 trucks, 308.9ms\n",
      "Speed: 6.2ms preprocess, 308.9ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 7 persons, 5 cars, 2 motorcycles, 2 trucks, 298.6ms\n",
      "Speed: 5.7ms preprocess, 298.6ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 5 persons, 5 cars, 2 motorcycles, 2 trucks, 307.9ms\n",
      "Speed: 5.9ms preprocess, 307.9ms inference, 2.8ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 5 persons, 4 cars, 2 motorcycles, 2 trucks, 270.5ms\n",
      "Speed: 7.3ms preprocess, 270.5ms inference, 3.1ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 4 persons, 4 cars, 2 motorcycles, 2 trucks, 249.7ms\n",
      "Speed: 5.0ms preprocess, 249.7ms inference, 2.8ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 5 persons, 5 cars, 2 motorcycles, 1 truck, 257.8ms\n",
      "Speed: 6.4ms preprocess, 257.8ms inference, 4.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 5 persons, 5 cars, 2 motorcycles, 2 trucks, 307.3ms\n",
      "Speed: 7.0ms preprocess, 307.3ms inference, 3.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 4 persons, 4 cars, 2 motorcycles, 2 trucks, 329.1ms\n",
      "Speed: 5.9ms preprocess, 329.1ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 5 persons, 4 cars, 2 motorcycles, 2 trucks, 303.8ms\n",
      "Speed: 5.8ms preprocess, 303.8ms inference, 2.8ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 5 persons, 7 cars, 2 motorcycles, 2 trucks, 603.9ms\n",
      "Speed: 10.2ms preprocess, 603.9ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 5 persons, 8 cars, 2 motorcycles, 1 truck, 479.1ms\n",
      "Speed: 8.0ms preprocess, 479.1ms inference, 3.1ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 5 persons, 6 cars, 2 motorcycles, 3 trucks, 315.7ms\n",
      "Speed: 5.7ms preprocess, 315.7ms inference, 4.4ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 5 persons, 5 cars, 2 motorcycles, 2 trucks, 304.2ms\n",
      "Speed: 6.3ms preprocess, 304.2ms inference, 3.9ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 7 persons, 6 cars, 2 motorcycles, 2 trucks, 278.7ms\n",
      "Speed: 6.0ms preprocess, 278.7ms inference, 2.9ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 4 persons, 8 cars, 3 motorcycles, 1 truck, 269.7ms\n",
      "Speed: 5.2ms preprocess, 269.7ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 5 persons, 9 cars, 3 motorcycles, 1 truck, 280.8ms\n",
      "Speed: 5.0ms preprocess, 280.8ms inference, 3.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 3 persons, 6 cars, 2 motorcycles, 1 truck, 276.7ms\n",
      "Speed: 5.0ms preprocess, 276.7ms inference, 3.3ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 3 persons, 7 cars, 2 motorcycles, 1 truck, 287.2ms\n",
      "Speed: 5.3ms preprocess, 287.2ms inference, 3.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 3 persons, 4 cars, 2 motorcycles, 1 truck, 276.2ms\n",
      "Speed: 6.0ms preprocess, 276.2ms inference, 3.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 2 persons, 4 cars, 2 motorcycles, 1 truck, 273.3ms\n",
      "Speed: 4.9ms preprocess, 273.3ms inference, 2.8ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 4 persons, 3 cars, 2 motorcycles, 1 truck, 317.9ms\n",
      "Speed: 5.0ms preprocess, 317.9ms inference, 4.5ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 3 persons, 5 cars, 2 motorcycles, 1 truck, 332.5ms\n",
      "Speed: 4.5ms preprocess, 332.5ms inference, 3.4ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 4 persons, 7 cars, 2 motorcycles, 1 truck, 493.6ms\n",
      "Speed: 6.1ms preprocess, 493.6ms inference, 3.2ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 3 persons, 6 cars, 1 motorcycle, 1 truck, 315.2ms\n",
      "Speed: 7.2ms preprocess, 315.2ms inference, 3.2ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 3 persons, 7 cars, 1 motorcycle, 1 truck, 291.6ms\n",
      "Speed: 5.3ms preprocess, 291.6ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 2 persons, 6 cars, 2 motorcycles, 1 truck, 229.2ms\n",
      "Speed: 5.3ms preprocess, 229.2ms inference, 3.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 3 persons, 5 cars, 1 motorcycle, 1 truck, 326.5ms\n",
      "Speed: 5.1ms preprocess, 326.5ms inference, 3.2ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 3 persons, 5 cars, 2 motorcycles, 1 truck, 1376.9ms\n",
      "Speed: 8.8ms preprocess, 1376.9ms inference, 18.7ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 2 persons, 5 cars, 2 motorcycles, 1 truck, 2647.6ms\n",
      "Speed: 47.9ms preprocess, 2647.6ms inference, 4.1ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 2 persons, 5 cars, 2 motorcycles, 1 truck, 1373.2ms\n",
      "Speed: 17.5ms preprocess, 1373.2ms inference, 4.9ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 2 persons, 5 cars, 2 motorcycles, 1 truck, 1288.4ms\n",
      "Speed: 6.7ms preprocess, 1288.4ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 2 persons, 5 cars, 3 motorcycles, 1 truck, 1 umbrella, 1090.5ms\n",
      "Speed: 9.1ms preprocess, 1090.5ms inference, 8.8ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 2 persons, 7 cars, 2 motorcycles, 1 truck, 1 umbrella, 813.5ms\n",
      "Speed: 17.0ms preprocess, 813.5ms inference, 3.6ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 2 persons, 6 cars, 2 motorcycles, 1 truck, 1 umbrella, 394.7ms\n",
      "Speed: 6.8ms preprocess, 394.7ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 2 persons, 6 cars, 2 motorcycles, 1 truck, 496.6ms\n",
      "Speed: 5.5ms preprocess, 496.6ms inference, 3.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 2 persons, 6 cars, 1 motorcycle, 2 trucks, 1 umbrella, 360.9ms\n",
      "Speed: 7.2ms preprocess, 360.9ms inference, 4.4ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 2 persons, 6 cars, 1 motorcycle, 1 truck, 1 umbrella, 345.7ms\n",
      "Speed: 11.2ms preprocess, 345.7ms inference, 3.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 2 persons, 8 cars, 1 motorcycle, 1 truck, 301.3ms\n",
      "Speed: 5.2ms preprocess, 301.3ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 2 persons, 8 cars, 1 motorcycle, 1 truck, 283.4ms\n",
      "Speed: 7.3ms preprocess, 283.4ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 2 persons, 6 cars, 1 motorcycle, 1 truck, 1 umbrella, 267.1ms\n",
      "Speed: 4.9ms preprocess, 267.1ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 2 persons, 6 cars, 1 motorcycle, 1 truck, 1 umbrella, 261.9ms\n",
      "Speed: 6.9ms preprocess, 261.9ms inference, 2.8ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 2 persons, 7 cars, 1 motorcycle, 1 truck, 1 umbrella, 241.7ms\n",
      "Speed: 4.9ms preprocess, 241.7ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 2 persons, 7 cars, 1 motorcycle, 1 truck, 1 umbrella, 226.5ms\n",
      "Speed: 4.4ms preprocess, 226.5ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 2 persons, 7 cars, 1 motorcycle, 1 truck, 1 umbrella, 222.0ms\n",
      "Speed: 5.3ms preprocess, 222.0ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 2 persons, 7 cars, 1 motorcycle, 1 truck, 1 umbrella, 220.9ms\n",
      "Speed: 4.1ms preprocess, 220.9ms inference, 3.1ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 2 persons, 8 cars, 2 motorcycles, 1 truck, 1 umbrella, 228.9ms\n",
      "Speed: 4.1ms preprocess, 228.9ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 person, 7 cars, 2 motorcycles, 1 truck, 1 umbrella, 220.6ms\n",
      "Speed: 4.9ms preprocess, 220.6ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 person, 5 cars, 2 motorcycles, 1 truck, 1 umbrella, 231.4ms\n",
      "Speed: 4.3ms preprocess, 231.4ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 person, 6 cars, 2 motorcycles, 1 truck, 1 umbrella, 222.7ms\n",
      "Speed: 4.8ms preprocess, 222.7ms inference, 2.4ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 person, 6 cars, 2 motorcycles, 1 truck, 1 umbrella, 232.3ms\n",
      "Speed: 4.6ms preprocess, 232.3ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 person, 4 cars, 1 motorcycle, 1 truck, 1 umbrella, 244.7ms\n",
      "Speed: 4.7ms preprocess, 244.7ms inference, 2.4ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 person, 5 cars, 1 motorcycle, 1 truck, 1 umbrella, 221.5ms\n",
      "Speed: 4.4ms preprocess, 221.5ms inference, 2.8ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 person, 4 cars, 1 motorcycle, 1 truck, 1 umbrella, 222.7ms\n",
      "Speed: 5.1ms preprocess, 222.7ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 person, 4 cars, 2 motorcycles, 2 trucks, 1 umbrella, 233.7ms\n",
      "Speed: 5.4ms preprocess, 233.7ms inference, 2.3ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 2 persons, 5 cars, 2 motorcycles, 1 truck, 284.3ms\n",
      "Speed: 4.6ms preprocess, 284.3ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 person, 5 cars, 2 motorcycles, 2 trucks, 307.7ms\n",
      "Speed: 4.6ms preprocess, 307.7ms inference, 2.4ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 person, 6 cars, 2 motorcycles, 1 truck, 318.0ms\n",
      "Speed: 3.5ms preprocess, 318.0ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 person, 6 cars, 2 motorcycles, 1 truck, 292.4ms\n",
      "Speed: 5.6ms preprocess, 292.4ms inference, 3.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 person, 5 cars, 2 motorcycles, 3 trucks, 232.7ms\n",
      "Speed: 5.4ms preprocess, 232.7ms inference, 2.4ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 person, 4 cars, 2 motorcycles, 3 trucks, 254.8ms\n",
      "Speed: 9.0ms preprocess, 254.8ms inference, 2.8ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 person, 4 cars, 2 motorcycles, 3 trucks, 287.2ms\n",
      "Speed: 6.1ms preprocess, 287.2ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 person, 5 cars, 2 motorcycles, 4 trucks, 297.3ms\n",
      "Speed: 11.8ms preprocess, 297.3ms inference, 2.9ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 person, 5 cars, 2 motorcycles, 1 bus, 2 trucks, 316.8ms\n",
      "Speed: 8.7ms preprocess, 316.8ms inference, 3.2ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 person, 6 cars, 1 motorcycle, 1 bus, 1 truck, 259.5ms\n",
      "Speed: 5.8ms preprocess, 259.5ms inference, 2.4ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 person, 6 cars, 1 motorcycle, 1 bus, 1 truck, 339.4ms\n",
      "Speed: 5.2ms preprocess, 339.4ms inference, 2.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 2 persons, 6 cars, 2 motorcycles, 1 bus, 2 trucks, 417.1ms\n",
      "Speed: 9.3ms preprocess, 417.1ms inference, 5.1ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 person, 7 cars, 1 motorcycle, 1 bus, 2 trucks, 504.4ms\n",
      "Speed: 7.4ms preprocess, 504.4ms inference, 5.7ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 2 persons, 5 cars, 1 motorcycle, 1 bus, 2 trucks, 412.1ms\n",
      "Speed: 16.6ms preprocess, 412.1ms inference, 3.2ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 2 persons, 6 cars, 1 motorcycle, 2 trucks, 356.6ms\n",
      "Speed: 7.4ms preprocess, 356.6ms inference, 3.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 person, 6 cars, 1 motorcycle, 2 trucks, 304.2ms\n",
      "Speed: 5.9ms preprocess, 304.2ms inference, 2.8ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 person, 7 cars, 1 motorcycle, 2 trucks, 331.7ms\n",
      "Speed: 6.4ms preprocess, 331.7ms inference, 3.2ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 person, 9 cars, 1 motorcycle, 2 trucks, 302.3ms\n",
      "Speed: 7.7ms preprocess, 302.3ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 person, 9 cars, 1 motorcycle, 1 bus, 3 trucks, 380.7ms\n",
      "Speed: 5.7ms preprocess, 380.7ms inference, 3.5ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 2 persons, 8 cars, 1 motorcycle, 1 bus, 2 trucks, 311.5ms\n",
      "Speed: 5.8ms preprocess, 311.5ms inference, 3.4ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 2 persons, 7 cars, 1 motorcycle, 3 trucks, 260.8ms\n",
      "Speed: 7.7ms preprocess, 260.8ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 person, 7 cars, 2 motorcycles, 3 trucks, 294.4ms\n",
      "Speed: 6.3ms preprocess, 294.4ms inference, 4.6ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 person, 4 cars, 2 motorcycles, 3 trucks, 311.7ms\n",
      "Speed: 5.4ms preprocess, 311.7ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 person, 7 cars, 2 motorcycles, 4 trucks, 285.6ms\n",
      "Speed: 5.4ms preprocess, 285.6ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 person, 7 cars, 2 motorcycles, 3 trucks, 321.2ms\n",
      "Speed: 9.7ms preprocess, 321.2ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 person, 7 cars, 2 motorcycles, 3 trucks, 1 umbrella, 270.9ms\n",
      "Speed: 5.2ms preprocess, 270.9ms inference, 2.4ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 person, 7 cars, 2 motorcycles, 3 trucks, 256.7ms\n",
      "Speed: 6.4ms preprocess, 256.7ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 person, 6 cars, 2 motorcycles, 2 trucks, 261.6ms\n",
      "Speed: 7.3ms preprocess, 261.6ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 person, 7 cars, 2 motorcycles, 3 trucks, 382.2ms\n",
      "Speed: 5.9ms preprocess, 382.2ms inference, 4.1ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 2 persons, 7 cars, 2 motorcycles, 2 trucks, 578.8ms\n",
      "Speed: 57.4ms preprocess, 578.8ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 2 persons, 6 cars, 3 motorcycles, 1 truck, 327.4ms\n",
      "Speed: 5.3ms preprocess, 327.4ms inference, 2.8ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 2 persons, 6 cars, 3 motorcycles, 2 trucks, 360.1ms\n",
      "Speed: 6.1ms preprocess, 360.1ms inference, 2.9ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 2 persons, 7 cars, 3 motorcycles, 3 trucks, 313.9ms\n",
      "Speed: 5.3ms preprocess, 313.9ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 2 persons, 6 cars, 3 motorcycles, 2 trucks, 334.9ms\n",
      "Speed: 7.7ms preprocess, 334.9ms inference, 3.1ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 2 persons, 7 cars, 2 motorcycles, 2 trucks, 340.4ms\n",
      "Speed: 7.4ms preprocess, 340.4ms inference, 2.9ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 2 persons, 5 cars, 2 motorcycles, 1 truck, 360.2ms\n",
      "Speed: 7.6ms preprocess, 360.2ms inference, 2.8ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 person, 7 cars, 3 motorcycles, 1 truck, 278.4ms\n",
      "Speed: 5.8ms preprocess, 278.4ms inference, 3.1ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 2 persons, 8 cars, 4 motorcycles, 1 truck, 423.8ms\n",
      "Speed: 5.2ms preprocess, 423.8ms inference, 3.2ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 3 persons, 6 cars, 3 motorcycles, 1 truck, 299.6ms\n",
      "Speed: 7.3ms preprocess, 299.6ms inference, 3.2ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 3 persons, 5 cars, 3 motorcycles, 1 truck, 298.1ms\n",
      "Speed: 5.1ms preprocess, 298.1ms inference, 3.2ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 3 persons, 5 cars, 3 motorcycles, 2 trucks, 298.4ms\n",
      "Speed: 6.6ms preprocess, 298.4ms inference, 3.3ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 3 persons, 6 cars, 5 motorcycles, 1 truck, 311.9ms\n",
      "Speed: 5.7ms preprocess, 311.9ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 3 persons, 7 cars, 3 motorcycles, 1 truck, 271.9ms\n",
      "Speed: 7.5ms preprocess, 271.9ms inference, 3.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 3 persons, 9 cars, 3 motorcycles, 1 truck, 379.1ms\n",
      "Speed: 7.0ms preprocess, 379.1ms inference, 3.4ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 3 persons, 8 cars, 3 motorcycles, 1 truck, 311.1ms\n",
      "Speed: 7.4ms preprocess, 311.1ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 4 persons, 7 cars, 4 motorcycles, 1 truck, 297.5ms\n",
      "Speed: 9.3ms preprocess, 297.5ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 4 persons, 7 cars, 4 motorcycles, 1 truck, 304.0ms\n",
      "Speed: 8.5ms preprocess, 304.0ms inference, 4.2ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 3 persons, 7 cars, 5 motorcycles, 2 trucks, 327.9ms\n",
      "Speed: 17.9ms preprocess, 327.9ms inference, 3.2ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 3 persons, 7 cars, 5 motorcycles, 2 trucks, 296.0ms\n",
      "Speed: 11.4ms preprocess, 296.0ms inference, 3.8ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 3 persons, 8 cars, 5 motorcycles, 2 trucks, 284.2ms\n",
      "Speed: 5.8ms preprocess, 284.2ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 3 persons, 8 cars, 4 motorcycles, 1 truck, 265.1ms\n",
      "Speed: 6.3ms preprocess, 265.1ms inference, 2.8ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 3 persons, 7 cars, 4 motorcycles, 1 truck, 247.8ms\n",
      "Speed: 5.5ms preprocess, 247.8ms inference, 3.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 4 persons, 6 cars, 4 motorcycles, 1 truck, 248.3ms\n",
      "Speed: 4.7ms preprocess, 248.3ms inference, 2.4ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 3 persons, 7 cars, 4 motorcycles, 3 trucks, 1 umbrella, 258.1ms\n",
      "Speed: 6.9ms preprocess, 258.1ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 3 persons, 7 cars, 4 motorcycles, 2 trucks, 260.6ms\n",
      "Speed: 7.4ms preprocess, 260.6ms inference, 2.8ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 3 persons, 7 cars, 4 motorcycles, 2 trucks, 233.0ms\n",
      "Speed: 6.3ms preprocess, 233.0ms inference, 2.4ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 3 persons, 7 cars, 4 motorcycles, 2 trucks, 246.8ms\n",
      "Speed: 6.2ms preprocess, 246.8ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 3 persons, 8 cars, 4 motorcycles, 1 truck, 269.3ms\n",
      "Speed: 6.8ms preprocess, 269.3ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 3 persons, 6 cars, 4 motorcycles, 1 truck, 256.6ms\n",
      "Speed: 5.4ms preprocess, 256.6ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 3 persons, 7 cars, 4 motorcycles, 2 trucks, 292.8ms\n",
      "Speed: 4.9ms preprocess, 292.8ms inference, 2.8ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 3 persons, 8 cars, 4 motorcycles, 2 trucks, 343.1ms\n",
      "Speed: 5.2ms preprocess, 343.1ms inference, 2.8ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 3 persons, 5 cars, 4 motorcycles, 2 trucks, 274.8ms\n",
      "Speed: 5.7ms preprocess, 274.8ms inference, 2.9ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 3 persons, 6 cars, 3 motorcycles, 4 trucks, 373.8ms\n",
      "Speed: 9.0ms preprocess, 373.8ms inference, 3.2ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 3 persons, 6 cars, 4 motorcycles, 1 bus, 3 trucks, 392.0ms\n",
      "Speed: 7.3ms preprocess, 392.0ms inference, 3.4ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 5 persons, 8 cars, 3 motorcycles, 1 bus, 3 trucks, 284.5ms\n",
      "Speed: 6.5ms preprocess, 284.5ms inference, 3.6ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 4 persons, 6 cars, 4 motorcycles, 1 bus, 3 trucks, 304.5ms\n",
      "Speed: 6.7ms preprocess, 304.5ms inference, 2.9ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 2 persons, 7 cars, 4 motorcycles, 1 bus, 3 trucks, 390.7ms\n",
      "Speed: 7.7ms preprocess, 390.7ms inference, 3.2ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 2 persons, 6 cars, 4 motorcycles, 1 bus, 3 trucks, 534.6ms\n",
      "Speed: 5.3ms preprocess, 534.6ms inference, 4.9ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 61\u001b[0m\n\u001b[0;32m     58\u001b[0m frame \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mresize(frame, (\u001b[38;5;241m1020\u001b[39m, \u001b[38;5;241m500\u001b[39m))\n\u001b[0;32m     60\u001b[0m \u001b[38;5;66;03m# ✅ YOLO Detection\u001b[39;00m\n\u001b[1;32m---> 61\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     62\u001b[0m a \u001b[38;5;241m=\u001b[39m results[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mboxes\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[0;32m     63\u001b[0m px \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(a)\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfloat\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\ultralytics\\engine\\model.py:560\u001b[0m, in \u001b[0;36mModel.predict\u001b[1;34m(self, source, stream, predictor, **kwargs)\u001b[0m\n\u001b[0;32m    558\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m prompts \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictor, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mset_prompts\u001b[39m\u001b[38;5;124m\"\u001b[39m):  \u001b[38;5;66;03m# for SAM-type models\u001b[39;00m\n\u001b[0;32m    559\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictor\u001b[38;5;241m.\u001b[39mset_prompts(prompts)\n\u001b[1;32m--> 560\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictor\u001b[38;5;241m.\u001b[39mpredict_cli(source\u001b[38;5;241m=\u001b[39msource) \u001b[38;5;28;01mif\u001b[39;00m is_cli \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredictor\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\ultralytics\\engine\\predictor.py:175\u001b[0m, in \u001b[0;36mBasePredictor.__call__\u001b[1;34m(self, source, model, stream, *args, **kwargs)\u001b[0m\n\u001b[0;32m    173\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream_inference(source, model, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    174\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 175\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstream_inference\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\utils\\_contextlib.py:36\u001b[0m, in \u001b[0;36m_wrap_generator.<locals>.generator_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     34\u001b[0m     \u001b[38;5;66;03m# Issuing `None` to a generator fires it up\u001b[39;00m\n\u001b[0;32m     35\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[1;32m---> 36\u001b[0m         response \u001b[38;5;241m=\u001b[39m \u001b[43mgen\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     38\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m     39\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     40\u001b[0m             \u001b[38;5;66;03m# Forward the response to our caller and get its next request\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\ultralytics\\engine\\predictor.py:261\u001b[0m, in \u001b[0;36mBasePredictor.stream_inference\u001b[1;34m(self, source, model, *args, **kwargs)\u001b[0m\n\u001b[0;32m    259\u001b[0m \u001b[38;5;66;03m# Inference\u001b[39;00m\n\u001b[0;32m    260\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m profilers[\u001b[38;5;241m1\u001b[39m]:\n\u001b[1;32m--> 261\u001b[0m     preds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minference\u001b[49m\u001b[43m(\u001b[49m\u001b[43mim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    262\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39membed:\n\u001b[0;32m    263\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m [preds] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(preds, torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;28;01melse\u001b[39;00m preds  \u001b[38;5;66;03m# yield embedding tensors\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\ultralytics\\engine\\predictor.py:145\u001b[0m, in \u001b[0;36mBasePredictor.inference\u001b[1;34m(self, im, *args, **kwargs)\u001b[0m\n\u001b[0;32m    139\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Runs inference on a given image using the specified model and arguments.\"\"\"\u001b[39;00m\n\u001b[0;32m    140\u001b[0m visualize \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    141\u001b[0m     increment_path(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave_dir \u001b[38;5;241m/\u001b[39m Path(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m])\u001b[38;5;241m.\u001b[39mstem, mkdir\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    142\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mvisualize \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msource_type\u001b[38;5;241m.\u001b[39mtensor)\n\u001b[0;32m    143\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    144\u001b[0m )\n\u001b[1;32m--> 145\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maugment\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maugment\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvisualize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvisualize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\ultralytics\\nn\\autobackend.py:557\u001b[0m, in \u001b[0;36mAutoBackend.forward\u001b[1;34m(self, im, augment, visualize, embed)\u001b[0m\n\u001b[0;32m    555\u001b[0m \u001b[38;5;66;03m# PyTorch\u001b[39;00m\n\u001b[0;32m    556\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpt \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnn_module:\n\u001b[1;32m--> 557\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maugment\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maugment\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvisualize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvisualize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43membed\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    559\u001b[0m \u001b[38;5;66;03m# TorchScript\u001b[39;00m\n\u001b[0;32m    560\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjit:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\ultralytics\\nn\\tasks.py:114\u001b[0m, in \u001b[0;36mBaseModel.forward\u001b[1;34m(self, x, *args, **kwargs)\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mdict\u001b[39m):  \u001b[38;5;66;03m# for cases of training and validating while training.\u001b[39;00m\n\u001b[0;32m    113\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss(x, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m--> 114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\ultralytics\\nn\\tasks.py:132\u001b[0m, in \u001b[0;36mBaseModel.predict\u001b[1;34m(self, x, profile, visualize, augment, embed)\u001b[0m\n\u001b[0;32m    130\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m augment:\n\u001b[0;32m    131\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_predict_augment(x)\n\u001b[1;32m--> 132\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_predict_once\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprofile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvisualize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membed\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\ultralytics\\nn\\tasks.py:153\u001b[0m, in \u001b[0;36mBaseModel._predict_once\u001b[1;34m(self, x, profile, visualize, embed)\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m profile:\n\u001b[0;32m    152\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_profile_one_layer(m, x, dt)\n\u001b[1;32m--> 153\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# run\u001b[39;00m\n\u001b[0;32m    154\u001b[0m y\u001b[38;5;241m.\u001b[39mappend(x \u001b[38;5;28;01mif\u001b[39;00m m\u001b[38;5;241m.\u001b[39mi \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)  \u001b[38;5;66;03m# save output\u001b[39;00m\n\u001b[0;32m    155\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m visualize:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\ultralytics\\nn\\modules\\conv.py:55\u001b[0m, in \u001b[0;36mConv.forward_fuse\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward_fuse\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m     54\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Apply convolution and activation without batch normalization.\"\"\"\u001b[39;00m\n\u001b[1;32m---> 55\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mact(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:554\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    553\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 554\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:549\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    537\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    538\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(\n\u001b[0;32m    539\u001b[0m         F\u001b[38;5;241m.\u001b[39mpad(\n\u001b[0;32m    540\u001b[0m             \u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    547\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups,\n\u001b[0;32m    548\u001b[0m     )\n\u001b[1;32m--> 549\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    550\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\n\u001b[0;32m    551\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import pandas as pd\n",
    "from ultralytics import YOLO\n",
    "from tracker import *\n",
    "import numpy as np\n",
    "import csv\n",
    "import os\n",
    "import time\n",
    "\n",
    "# ✅ Load YOLO model\n",
    "model = YOLO('yolov8s.pt')\n",
    "\n",
    "# ✅ Object classes\n",
    "class_list = [\n",
    "    \"person\", \"bicycle\", \"car\", \"motorcycle\", \"airplane\", \"bus\", \"train\", \"truck\", \"boat\",\n",
    "    \"traffic light\", \"fire hydrant\", \"stop sign\", \"parking meter\", \"bench\", \"bird\", \"cat\",\n",
    "    \"dog\", \"horse\", \"sheep\", \"cow\", \"elephant\", \"bear\", \"zebra\", \"giraffe\", \"backpack\",\n",
    "    \"umbrella\", \"handbag\", \"tie\", \"suitcase\", \"frisbee\", \"skis\", \"snowboard\", \"sports ball\",\n",
    "    \"kite\", \"baseball bat\", \"baseball glove\", \"skateboard\", \"surfboard\", \"tennis racket\",\n",
    "    \"bottle\", \"wine glass\", \"cup\", \"fork\", \"knife\", \"spoon\", \"bowl\", \"banana\", \"apple\",\n",
    "    \"sandwich\", \"orange\", \"broccoli\", \"carrot\", \"hot dog\", \"pizza\", \"donut\", \"cake\",\n",
    "    \"chair\", \"couch\", \"potted plant\", \"bed\", \"dining table\", \"toilet\", \"TV\", \"laptop\",\n",
    "    \"mouse\", \"remote\", \"keyboard\", \"cell phone\", \"microwave\", \"oven\", \"toaster\", \"sink\",\n",
    "    \"refrigerator\", \"book\", \"clock\", \"vase\", \"scissors\", \"teddy bear\", \"hair drier\", \"toothbrush\"\n",
    "]\n",
    "\n",
    "# ✅ Initialize tracker\n",
    "tracker = Tracker()\n",
    "cap = cv2.VideoCapture('camp3_rain_noon.mp4')\n",
    "\n",
    "# ✅ CSV File Setup\n",
    "csv_filename = \"vehicles_summary.csv\"\n",
    "\n",
    "# ✅ Create CSV file if it doesn't exist\n",
    "if not os.path.exists(csv_filename):\n",
    "    with open(csv_filename, mode=\"w\", newline=\"\") as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow([\"Timestamp\", \"Cars\", \"Buses\", \"Trucks\", \"Motorcycles\"])\n",
    "\n",
    "# ✅ Define reference lines\n",
    "red_line_y = 340\n",
    "blue_line_y = 370\n",
    "offset = 7  # Allow slight variation due to tracking jitter\n",
    "\n",
    "# ✅ Define vehicle classes to track\n",
    "vehicle_classes = [\"car\", \"bus\", \"truck\", \"motorcycle\"]\n",
    "vehicle_counts = {\"car\": 0, \"bus\": 0, \"truck\": 0, \"motorcycle\": 0}\n",
    "\n",
    "# ✅ Store vehicle IDs that crossed the red line first\n",
    "crossed_red = {}\n",
    "counter_down = []\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    frame = cv2.resize(frame, (1020, 500))\n",
    "\n",
    "    # ✅ YOLO Detection\n",
    "    results = model.predict(frame)\n",
    "    a = results[0].boxes.data.detach().cpu().numpy()\n",
    "    px = pd.DataFrame(a).astype(\"float\")\n",
    "\n",
    "    # ✅ Store detections\n",
    "    detections = []\n",
    "    detected_vehicles = {}\n",
    "\n",
    "    for _, row in px.iterrows():\n",
    "        x1, y1, x2, y2 = int(row[0]), int(row[1]), int(row[2]), int(row[3])\n",
    "        d = int(row[5])\n",
    "        vehicle_type = class_list[d]\n",
    "\n",
    "        if vehicle_type in vehicle_classes:\n",
    "            detections.append([x1, y1, x2, y2])\n",
    "            detected_vehicles[(x1, y1, x2, y2)] = vehicle_type\n",
    "\n",
    "    # ✅ Ensure 'detections' is not empty\n",
    "    bbox_id = tracker.update(np.array(detections)) if detections else []\n",
    "\n",
    "    # ✅ Process ALL detected vehicles\n",
    "    for bbox in bbox_id:\n",
    "        x3, y3, x4, y4, vehicle_id = bbox\n",
    "        cx, cy = (x3 + x4) // 2, (y3 + y4) // 2\n",
    "\n",
    "        vehicle_type = detected_vehicles.get((x3, y3, x4, y4), \"unknown\")\n",
    "\n",
    "        # ✅ Check if the vehicle crosses the RED line first\n",
    "        if red_line_y - offset < cy < red_line_y + offset:\n",
    "            crossed_red[vehicle_id] = (cy, vehicle_type)\n",
    "\n",
    "        # ✅ Only consider vehicles that crossed red before reaching blue\n",
    "        if vehicle_id in crossed_red and blue_line_y - offset < cy < blue_line_y + offset:\n",
    "            _, v_type = crossed_red[vehicle_id]\n",
    "\n",
    "            # ✅ Draw circle at the blue line for valid vehicles\n",
    "            cv2.circle(frame, (cx, cy), 4, (0, 0, 255), -1)\n",
    "            cv2.putText(frame, f\"{v_type}-{vehicle_id}\", (cx, cy), cv2.FONT_HERSHEY_COMPLEX, 0.8, (0, 255, 255), 2)\n",
    "\n",
    "            # ✅ Add to counter only once\n",
    "            if vehicle_id not in counter_down:\n",
    "                counter_down.append(vehicle_id)\n",
    "                vehicle_counts[v_type] += 1\n",
    "\n",
    "    # ✅ Draw reference lines\n",
    "    cv2.line(frame, (260, red_line_y), (724, red_line_y), (0, 0, 255), 3)\n",
    "    cv2.putText(frame, 'red line', (260, red_line_y), cv2.FONT_HERSHEY_COMPLEX, 0.5, (255, 255, 255), 1, cv2.LINE_AA)\n",
    "\n",
    "    cv2.line(frame, (200, blue_line_y), (779, blue_line_y), (255, 0, 0), 3)\n",
    "    cv2.putText(frame, 'blue line', (200, blue_line_y), cv2.FONT_HERSHEY_COMPLEX, 0.5, (255, 255, 255), 1, cv2.LINE_AA)\n",
    "\n",
    "    # ✅ Display vehicle count\n",
    "    cv2.putText(frame, f\"Cars: {vehicle_counts['car']}  Buses: {vehicle_counts['bus']}  Trucks: {vehicle_counts['truck']}  Motorcycles: {vehicle_counts['motorcycle']}\",\n",
    "                (60, 40), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 1, cv2.LINE_AA)\n",
    "\n",
    "    cv2.imshow(\"frames\", frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == 27:\n",
    "        break\n",
    "\n",
    "# ✅ Log the final vehicle count when the video ends\n",
    "timestamp = time.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "number_of_lanes=2\n",
    "# ✅ Calculate light duration using the given formula\n",
    "light_duration = ((vehicle_counts[\"car\"] * 2) + \n",
    "                  (vehicle_counts[\"motorcycle\"] * 1.8) + \n",
    "                  ((vehicle_counts[\"bus\"] + vehicle_counts[\"truck\"]) * 3.5)) / number_of_lanes\n",
    "with open(csv_filename, mode=\"a\", newline=\"\") as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow([timestamp, vehicle_counts[\"car\"], vehicle_counts[\"bus\"], vehicle_counts[\"truck\"], vehicle_counts[\"motorcycle\"], round(light_duration, 2)])\n",
    "\n",
    "print(f\"✅ Final vehicle count saved to CSV: {vehicle_counts}, Light Duration: {round(light_duration, 2)} sec\")\n",
    "\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "387c6e05-15dd-44b5-9b36-a308d9a22ad9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
